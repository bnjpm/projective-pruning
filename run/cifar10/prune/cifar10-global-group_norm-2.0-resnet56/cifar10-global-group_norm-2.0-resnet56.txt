[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: mode: prune
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: model: resnet56
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: verbose: False
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: dataset: cifar10
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: dataroot: data
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: batch_size: 128
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: total_epochs: 100
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: lr: 0.01
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: restore: run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: output_dir: run/cifar10/prune/cifar10-global-group_norm-2.0-resnet56
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: finetune: True
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: last_epochs: 100
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: reps: 1
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: method: group_norm
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: speed_up: 2.0
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: reg: 1e-05
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: seed: 1
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: global_pruning: True
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: sl_restore: None
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: iterative_steps: 400
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: logger: <Logger cifar10-global-group_norm-2.0-resnet56 (DEBUG)>
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: device: cuda
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: num_classes: 10
[02/21 02:34:10] cifar10-global-group_norm-2.0-resnet56 INFO: Loading model from run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 02:34:14] cifar10-global-group_norm-2.0-resnet56 INFO: Pruning...
[02/21 02:34:30] cifar10-global-group_norm-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(12, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(12, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(12, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(12, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(12, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(12, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(12, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(12, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(25, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(12, 31, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(31, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(24, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(31, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(31, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(20, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(31, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(19, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(31, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(31, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(31, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(31, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(6, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(31, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(31, 61, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(61, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(61, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(61, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(47, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(61, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(61, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(46, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(61, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(40, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(61, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(29, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(61, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=61, out_features=10, bias=True)
)
[02/21 02:34:33] cifar10-global-group_norm-2.0-resnet56 INFO: Params: 0.86 M => 0.56 M (64.90%)
[02/21 02:34:33] cifar10-global-group_norm-2.0-resnet56 INFO: FLOPs: 127.12 M => 63.06 M (49.61%, 2.02X )
[02/21 02:34:33] cifar10-global-group_norm-2.0-resnet56 INFO: Acc: 0.9392 => 0.2899
[02/21 02:34:33] cifar10-global-group_norm-2.0-resnet56 INFO: Val Loss: 0.2587 => 4.5965
[02/21 02:34:33] cifar10-global-group_norm-2.0-resnet56 INFO: Finetuning...
[02/21 02:35:07] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 0/100, Acc=0.8889, Val Loss=0.3436, lr=0.0100
[02/21 02:35:40] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 1/100, Acc=0.8804, Val Loss=0.3984, lr=0.0100
[02/21 02:36:13] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 2/100, Acc=0.8994, Val Loss=0.3246, lr=0.0100
[02/21 02:36:46] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 3/100, Acc=0.9037, Val Loss=0.3113, lr=0.0100
[02/21 02:37:19] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 4/100, Acc=0.8933, Val Loss=0.3433, lr=0.0100
[02/21 02:37:51] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 5/100, Acc=0.8915, Val Loss=0.3698, lr=0.0100
[02/21 02:38:24] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 6/100, Acc=0.8783, Val Loss=0.4101, lr=0.0100
[02/21 02:38:57] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 7/100, Acc=0.9100, Val Loss=0.2995, lr=0.0100
[02/21 02:39:30] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 8/100, Acc=0.8999, Val Loss=0.3243, lr=0.0100
[02/21 02:40:03] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 9/100, Acc=0.8903, Val Loss=0.3750, lr=0.0100
[02/21 02:40:35] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 10/100, Acc=0.8975, Val Loss=0.3445, lr=0.0100
[02/21 02:41:08] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 11/100, Acc=0.8974, Val Loss=0.3425, lr=0.0100
[02/21 02:41:41] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 12/100, Acc=0.9075, Val Loss=0.3028, lr=0.0100
[02/21 02:42:14] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 13/100, Acc=0.9002, Val Loss=0.3390, lr=0.0100
[02/21 02:42:47] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 14/100, Acc=0.9065, Val Loss=0.3183, lr=0.0100
[02/21 02:43:20] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 15/100, Acc=0.9070, Val Loss=0.3196, lr=0.0100
[02/21 02:43:53] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 16/100, Acc=0.9056, Val Loss=0.3202, lr=0.0100
[02/21 02:44:26] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 17/100, Acc=0.9036, Val Loss=0.3320, lr=0.0100
[02/21 02:44:59] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 18/100, Acc=0.9052, Val Loss=0.3161, lr=0.0100
[02/21 02:45:32] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 19/100, Acc=0.8986, Val Loss=0.3397, lr=0.0100
[02/21 02:46:04] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 20/100, Acc=0.8994, Val Loss=0.3348, lr=0.0100
[02/21 02:46:37] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 21/100, Acc=0.9115, Val Loss=0.2954, lr=0.0100
[02/21 02:47:09] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 22/100, Acc=0.9068, Val Loss=0.3191, lr=0.0100
[02/21 02:47:42] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 23/100, Acc=0.9061, Val Loss=0.3204, lr=0.0100
[02/21 02:48:15] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 24/100, Acc=0.8998, Val Loss=0.3405, lr=0.0100
[02/21 02:48:48] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 25/100, Acc=0.9050, Val Loss=0.3286, lr=0.0100
[02/21 02:49:21] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 26/100, Acc=0.8927, Val Loss=0.3846, lr=0.0100
[02/21 02:49:54] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 27/100, Acc=0.9028, Val Loss=0.3303, lr=0.0100
[02/21 02:50:27] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 28/100, Acc=0.9021, Val Loss=0.3380, lr=0.0100
[02/21 02:50:59] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 29/100, Acc=0.9010, Val Loss=0.3326, lr=0.0100
[02/21 02:51:32] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 30/100, Acc=0.8977, Val Loss=0.3599, lr=0.0100
[02/21 02:52:05] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 31/100, Acc=0.9058, Val Loss=0.3229, lr=0.0100
[02/21 02:52:42] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 32/100, Acc=0.9072, Val Loss=0.3378, lr=0.0100
[02/21 02:53:16] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 33/100, Acc=0.9139, Val Loss=0.2972, lr=0.0100
[02/21 02:53:53] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 34/100, Acc=0.9047, Val Loss=0.3259, lr=0.0100
[02/21 02:54:26] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 35/100, Acc=0.9017, Val Loss=0.3388, lr=0.0100
[02/21 02:54:59] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 36/100, Acc=0.9100, Val Loss=0.2985, lr=0.0100
[02/21 02:55:33] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 37/100, Acc=0.9054, Val Loss=0.3392, lr=0.0100
[02/21 02:56:06] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 38/100, Acc=0.8929, Val Loss=0.3858, lr=0.0100
[02/21 02:56:39] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 39/100, Acc=0.9052, Val Loss=0.3336, lr=0.0100
[02/21 02:57:12] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 40/100, Acc=0.9044, Val Loss=0.3298, lr=0.0100
[02/21 02:57:49] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 41/100, Acc=0.8970, Val Loss=0.3575, lr=0.0100
[02/21 02:58:22] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 42/100, Acc=0.9001, Val Loss=0.3392, lr=0.0100
[02/21 02:58:55] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 43/100, Acc=0.9081, Val Loss=0.3315, lr=0.0100
[02/21 02:59:28] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 44/100, Acc=0.9062, Val Loss=0.3207, lr=0.0100
[02/21 03:00:05] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 45/100, Acc=0.9022, Val Loss=0.3488, lr=0.0100
[02/21 03:00:38] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 46/100, Acc=0.8970, Val Loss=0.3478, lr=0.0100
[02/21 03:01:10] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 47/100, Acc=0.9020, Val Loss=0.3443, lr=0.0100
[02/21 03:01:43] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 48/100, Acc=0.9020, Val Loss=0.3464, lr=0.0100
[02/21 03:02:16] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 49/100, Acc=0.9012, Val Loss=0.3275, lr=0.0100
[02/21 03:02:48] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 50/100, Acc=0.9025, Val Loss=0.3302, lr=0.0100
[02/21 03:03:22] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 51/100, Acc=0.9109, Val Loss=0.3174, lr=0.0100
[02/21 03:03:55] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 52/100, Acc=0.9024, Val Loss=0.3560, lr=0.0100
[02/21 03:04:28] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 53/100, Acc=0.9051, Val Loss=0.3350, lr=0.0100
[02/21 03:05:01] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 54/100, Acc=0.9057, Val Loss=0.3203, lr=0.0100
[02/21 03:05:35] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 55/100, Acc=0.9064, Val Loss=0.3220, lr=0.0100
[02/21 03:06:08] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 56/100, Acc=0.9056, Val Loss=0.3321, lr=0.0100
[02/21 03:06:40] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 57/100, Acc=0.9079, Val Loss=0.3267, lr=0.0100
[02/21 03:07:13] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 58/100, Acc=0.9036, Val Loss=0.3573, lr=0.0100
[02/21 03:07:46] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 59/100, Acc=0.9086, Val Loss=0.3134, lr=0.0100
[02/21 03:08:19] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 60/100, Acc=0.9305, Val Loss=0.2374, lr=0.0010
[02/21 03:08:52] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 61/100, Acc=0.9320, Val Loss=0.2415, lr=0.0010
[02/21 03:09:27] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 62/100, Acc=0.9344, Val Loss=0.2422, lr=0.0010
[02/21 03:09:59] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 63/100, Acc=0.9339, Val Loss=0.2425, lr=0.0010
[02/21 03:10:33] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 64/100, Acc=0.9342, Val Loss=0.2462, lr=0.0010
[02/21 03:11:07] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 65/100, Acc=0.9355, Val Loss=0.2476, lr=0.0010
[02/21 03:11:42] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 66/100, Acc=0.9345, Val Loss=0.2464, lr=0.0010
[02/21 03:12:18] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 67/100, Acc=0.9342, Val Loss=0.2500, lr=0.0010
[02/21 03:12:51] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 68/100, Acc=0.9342, Val Loss=0.2520, lr=0.0010
[02/21 03:13:23] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 69/100, Acc=0.9352, Val Loss=0.2498, lr=0.0010
[02/21 03:13:57] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 70/100, Acc=0.9348, Val Loss=0.2534, lr=0.0010
[02/21 03:14:30] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 71/100, Acc=0.9351, Val Loss=0.2540, lr=0.0010
[02/21 03:15:03] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 72/100, Acc=0.9359, Val Loss=0.2576, lr=0.0010
[02/21 03:15:36] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 73/100, Acc=0.9355, Val Loss=0.2588, lr=0.0010
[02/21 03:16:09] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 74/100, Acc=0.9355, Val Loss=0.2621, lr=0.0010
[02/21 03:16:42] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 75/100, Acc=0.9357, Val Loss=0.2592, lr=0.0010
[02/21 03:17:15] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 76/100, Acc=0.9352, Val Loss=0.2610, lr=0.0010
[02/21 03:17:48] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 77/100, Acc=0.9353, Val Loss=0.2589, lr=0.0010
[02/21 03:18:21] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 78/100, Acc=0.9350, Val Loss=0.2594, lr=0.0010
[02/21 03:18:55] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 79/100, Acc=0.9344, Val Loss=0.2630, lr=0.0010
[02/21 03:19:28] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 80/100, Acc=0.9343, Val Loss=0.2626, lr=0.0001
[02/21 03:20:01] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 81/100, Acc=0.9350, Val Loss=0.2612, lr=0.0001
[02/21 03:20:34] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 82/100, Acc=0.9355, Val Loss=0.2605, lr=0.0001
[02/21 03:21:07] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 83/100, Acc=0.9352, Val Loss=0.2623, lr=0.0001
[02/21 03:21:42] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 84/100, Acc=0.9347, Val Loss=0.2615, lr=0.0001
[02/21 03:22:15] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 85/100, Acc=0.9350, Val Loss=0.2623, lr=0.0001
[02/21 03:22:50] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 86/100, Acc=0.9353, Val Loss=0.2608, lr=0.0001
[02/21 03:23:23] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 87/100, Acc=0.9350, Val Loss=0.2619, lr=0.0001
[02/21 03:23:56] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 88/100, Acc=0.9356, Val Loss=0.2593, lr=0.0001
[02/21 03:24:30] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 89/100, Acc=0.9362, Val Loss=0.2602, lr=0.0001
[02/21 03:25:03] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 90/100, Acc=0.9354, Val Loss=0.2619, lr=0.0001
[02/21 03:25:36] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 91/100, Acc=0.9355, Val Loss=0.2622, lr=0.0001
[02/21 03:26:12] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 92/100, Acc=0.9357, Val Loss=0.2616, lr=0.0001
[02/21 03:26:47] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 93/100, Acc=0.9360, Val Loss=0.2610, lr=0.0001
[02/21 03:27:20] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 94/100, Acc=0.9360, Val Loss=0.2617, lr=0.0001
[02/21 03:27:55] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 95/100, Acc=0.9349, Val Loss=0.2622, lr=0.0001
[02/21 03:28:28] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 96/100, Acc=0.9350, Val Loss=0.2617, lr=0.0001
[02/21 03:29:00] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 97/100, Acc=0.9355, Val Loss=0.2611, lr=0.0001
[02/21 03:29:33] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 98/100, Acc=0.9348, Val Loss=0.2625, lr=0.0001
[02/21 03:30:06] cifar10-global-group_norm-2.0-resnet56 INFO: Epoch 99/100, Acc=0.9353, Val Loss=0.2632, lr=0.0001
[02/21 03:30:06] cifar10-global-group_norm-2.0-resnet56 INFO: Best Acc=0.9362
[02/21 03:30:06] cifar10-global-group_norm-2.0-resnet56 INFO: Params: 0.56 M
[02/21 03:30:06] cifar10-global-group_norm-2.0-resnet56 INFO: ops: 63.06 M
[02/21 03:30:09] cifar10-global-group_norm-2.0-resnet56 INFO: Acc: 0.9353 Val Loss: 0.2632

