[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: mode: prune
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: verbose: False
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: dataset: cifar10
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: dataroot: data
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: batch_size: 128
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: total_epochs: 100
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: lr: 0.01
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: restore: run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: output_dir: run/cifar10/prune/cifar10-global-lamp-2.0-mobilenetv2
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: finetune: True
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: last_epochs: 100
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: reps: 1
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: method: lamp
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: reg: 1e-05
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: seed: 1
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: global_pruning: True
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: sl_restore: None
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: logger: <Logger cifar10-global-lamp-2.0-mobilenetv2 (DEBUG)>
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: device: cuda
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: num_classes: 10
[02/23 20:30:59] cifar10-global-lamp-2.0-mobilenetv2 INFO: Loading model from run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 20:31:04] cifar10-global-lamp-2.0-mobilenetv2 INFO: Pruning...
[02/23 20:31:36] cifar10-global-lamp-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(8, 17, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(17, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=17)
      (4): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(17, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 73, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(73, 73, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=73)
        (4): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(73, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 86, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(86, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=86)
        (4): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(86, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 62, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=62)
        (4): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(62, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 88, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88)
        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 55, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55)
        (4): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(55, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 51, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(51, 51, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=51)
        (4): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(51, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 99, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=99)
        (4): BatchNorm2d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 61, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(61, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=61)
        (4): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(61, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 40, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40)
        (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 97, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=97)
        (4): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(97, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 568, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(568, 568, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=568)
        (4): BatchNorm2d(568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(568, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 231, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(231, 231, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=231)
        (4): BatchNorm2d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(231, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 16, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 5, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)
        (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(5, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 615, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(615, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(615, 615, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=615)
      (4): BatchNorm2d(615, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(615, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 10, kernel_size=(1, 1), stride=(1, 1))
)
[02/23 20:31:39] cifar10-global-lamp-2.0-mobilenetv2 INFO: Params: 2.25 M => 1.12 M (49.63%)
[02/23 20:31:39] cifar10-global-lamp-2.0-mobilenetv2 INFO: FLOPs: 68.29 M => 34.00 M (49.78%, 2.01X )
[02/23 20:31:39] cifar10-global-lamp-2.0-mobilenetv2 INFO: Acc: 0.8936 => 0.8936
[02/23 20:31:39] cifar10-global-lamp-2.0-mobilenetv2 INFO: Val Loss: 0.3202 => 0.3202
[02/23 20:31:39] cifar10-global-lamp-2.0-mobilenetv2 INFO: Finetuning...
[02/23 20:32:06] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.8529, Val Loss=0.4331, lr=0.0100
[02/23 20:32:33] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.8522, Val Loss=0.4362, lr=0.0100
[02/23 20:33:00] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.8429, Val Loss=0.4692, lr=0.0100
[02/23 20:33:28] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.8597, Val Loss=0.4127, lr=0.0100
[02/23 20:33:55] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.8600, Val Loss=0.4115, lr=0.0100
[02/23 20:34:22] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.8452, Val Loss=0.4555, lr=0.0100
[02/23 20:34:50] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.8477, Val Loss=0.4438, lr=0.0100
[02/23 20:35:17] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.8433, Val Loss=0.4604, lr=0.0100
[02/23 20:35:45] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.8611, Val Loss=0.4190, lr=0.0100
[02/23 20:36:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.8491, Val Loss=0.4560, lr=0.0100
[02/23 20:36:40] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.8553, Val Loss=0.4331, lr=0.0100
[02/23 20:37:09] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.8502, Val Loss=0.4409, lr=0.0100
[02/23 20:37:36] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.8603, Val Loss=0.4098, lr=0.0100
[02/23 20:38:04] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.8518, Val Loss=0.4318, lr=0.0100
[02/23 20:38:32] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.8334, Val Loss=0.4820, lr=0.0100
[02/23 20:39:00] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.8508, Val Loss=0.4347, lr=0.0100
[02/23 20:39:28] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.8510, Val Loss=0.4372, lr=0.0100
[02/23 20:39:56] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.8565, Val Loss=0.4276, lr=0.0100
[02/23 20:40:24] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.8562, Val Loss=0.4331, lr=0.0100
[02/23 20:40:52] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.8434, Val Loss=0.4532, lr=0.0100
[02/23 20:41:20] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.8309, Val Loss=0.5055, lr=0.0100
[02/23 20:41:48] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.8582, Val Loss=0.4137, lr=0.0100
[02/23 20:42:16] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.8605, Val Loss=0.4024, lr=0.0100
[02/23 20:42:45] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.8570, Val Loss=0.4264, lr=0.0100
[02/23 20:43:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.8628, Val Loss=0.3996, lr=0.0100
[02/23 20:43:41] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.8675, Val Loss=0.3975, lr=0.0100
[02/23 20:44:09] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.8479, Val Loss=0.4465, lr=0.0100
[02/23 20:44:38] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.8574, Val Loss=0.4242, lr=0.0100
[02/23 20:45:06] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.8535, Val Loss=0.4369, lr=0.0100
[02/23 20:45:34] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.8464, Val Loss=0.4550, lr=0.0100
[02/23 20:46:02] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.8556, Val Loss=0.4149, lr=0.0100
[02/23 20:46:29] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.8489, Val Loss=0.4482, lr=0.0100
[02/23 20:46:57] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.8406, Val Loss=0.4617, lr=0.0100
[02/23 20:47:26] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.8580, Val Loss=0.4167, lr=0.0100
[02/23 20:47:54] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.8573, Val Loss=0.4197, lr=0.0100
[02/23 20:48:22] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.8592, Val Loss=0.4129, lr=0.0100
[02/23 20:48:50] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.8419, Val Loss=0.4681, lr=0.0100
[02/23 20:49:18] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.8579, Val Loss=0.4165, lr=0.0100
[02/23 20:49:46] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.8613, Val Loss=0.4118, lr=0.0100
[02/23 20:50:15] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.8561, Val Loss=0.4180, lr=0.0100
[02/23 20:50:42] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.8530, Val Loss=0.4394, lr=0.0100
[02/23 20:51:10] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.8500, Val Loss=0.4504, lr=0.0100
[02/23 20:51:37] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.8619, Val Loss=0.4126, lr=0.0100
[02/23 20:52:05] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.8470, Val Loss=0.4581, lr=0.0100
[02/23 20:52:32] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.8475, Val Loss=0.4464, lr=0.0100
[02/23 20:53:00] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.8627, Val Loss=0.4075, lr=0.0100
[02/23 20:53:28] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.8595, Val Loss=0.4139, lr=0.0100
[02/23 20:53:55] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.8575, Val Loss=0.4184, lr=0.0100
[02/23 20:54:23] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.8412, Val Loss=0.4784, lr=0.0100
[02/23 20:54:51] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.8549, Val Loss=0.4401, lr=0.0100
[02/23 20:55:18] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.8597, Val Loss=0.4228, lr=0.0100
[02/23 20:55:46] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.8596, Val Loss=0.4188, lr=0.0100
[02/23 20:56:14] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.8660, Val Loss=0.3970, lr=0.0100
[02/23 20:56:41] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.8588, Val Loss=0.4242, lr=0.0100
[02/23 20:57:09] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.8511, Val Loss=0.4415, lr=0.0100
[02/23 20:57:37] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.8618, Val Loss=0.4153, lr=0.0100
[02/23 20:58:05] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.8658, Val Loss=0.4043, lr=0.0100
[02/23 20:58:32] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.8663, Val Loss=0.3967, lr=0.0100
[02/23 20:59:00] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.8587, Val Loss=0.4191, lr=0.0100
[02/23 20:59:28] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.8446, Val Loss=0.4529, lr=0.0100
[02/23 20:59:56] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.8902, Val Loss=0.3215, lr=0.0010
[02/23 21:00:24] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.8956, Val Loss=0.3113, lr=0.0010
[02/23 21:00:52] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.8955, Val Loss=0.3115, lr=0.0010
[02/23 21:01:20] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.8965, Val Loss=0.3099, lr=0.0010
[02/23 21:01:48] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.8981, Val Loss=0.3067, lr=0.0010
[02/23 21:02:17] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.8978, Val Loss=0.3092, lr=0.0010
[02/23 21:02:45] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.9003, Val Loss=0.3054, lr=0.0010
[02/23 21:03:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.8962, Val Loss=0.3061, lr=0.0010
[02/23 21:03:41] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.9001, Val Loss=0.3063, lr=0.0010
[02/23 21:04:09] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.8976, Val Loss=0.3066, lr=0.0010
[02/23 21:04:38] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.8971, Val Loss=0.3090, lr=0.0010
[02/23 21:05:06] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.8974, Val Loss=0.3074, lr=0.0010
[02/23 21:05:33] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.8992, Val Loss=0.3039, lr=0.0010
[02/23 21:06:01] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.8987, Val Loss=0.3044, lr=0.0010
[02/23 21:06:29] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.9012, Val Loss=0.3031, lr=0.0010
[02/23 21:06:57] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.8996, Val Loss=0.3065, lr=0.0010
[02/23 21:07:25] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.8976, Val Loss=0.3104, lr=0.0010
[02/23 21:07:52] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.8999, Val Loss=0.3096, lr=0.0010
[02/23 21:08:20] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.8980, Val Loss=0.3100, lr=0.0010
[02/23 21:08:48] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.8983, Val Loss=0.3116, lr=0.0010
[02/23 21:09:16] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.9005, Val Loss=0.3054, lr=0.0001
[02/23 21:09:44] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.8983, Val Loss=0.3051, lr=0.0001
[02/23 21:10:12] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.9001, Val Loss=0.3063, lr=0.0001
[02/23 21:10:40] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.8993, Val Loss=0.3049, lr=0.0001
[02/23 21:11:08] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.8999, Val Loss=0.3043, lr=0.0001
[02/23 21:11:36] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.8992, Val Loss=0.3052, lr=0.0001
[02/23 21:12:04] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.9005, Val Loss=0.3046, lr=0.0001
[02/23 21:12:33] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.8989, Val Loss=0.3022, lr=0.0001
[02/23 21:13:01] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.9006, Val Loss=0.3026, lr=0.0001
[02/23 21:13:30] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.9005, Val Loss=0.3029, lr=0.0001
[02/23 21:13:58] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.8995, Val Loss=0.3039, lr=0.0001
[02/23 21:14:26] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.8994, Val Loss=0.3027, lr=0.0001
[02/23 21:14:55] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.8999, Val Loss=0.3006, lr=0.0001
[02/23 21:15:23] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.9009, Val Loss=0.3028, lr=0.0001
[02/23 21:15:52] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.9018, Val Loss=0.3021, lr=0.0001
[02/23 21:16:20] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.9019, Val Loss=0.3025, lr=0.0001
[02/23 21:16:48] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.9009, Val Loss=0.3022, lr=0.0001
[02/23 21:17:17] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.9009, Val Loss=0.3018, lr=0.0001
[02/23 21:17:45] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.9004, Val Loss=0.3017, lr=0.0001
[02/23 21:18:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.9010, Val Loss=0.3016, lr=0.0001
[02/23 21:18:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Best Acc=0.9019
[02/23 21:18:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: Params: 1.12 M
[02/23 21:18:13] cifar10-global-lamp-2.0-mobilenetv2 INFO: ops: 34.00 M
[02/23 21:18:16] cifar10-global-lamp-2.0-mobilenetv2 INFO: Acc: 0.9010 Val Loss: 0.3016

