[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: mode: prune
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: verbose: False
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: dataset: cifar10
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: dataroot: data
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: batch_size: 128
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: total_epochs: 100
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: lr: 0.01
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: restore: run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: output_dir: run/cifar10/prune/cifar10-global-random-2.0-mobilenetv2
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: finetune: True
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: last_epochs: 100
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: reps: 1
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: method: random
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: reg: 1e-05
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: seed: 1
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: global_pruning: True
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: sl_restore: None
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: logger: <Logger cifar10-global-random-2.0-mobilenetv2 (DEBUG)>
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: device: cuda
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: num_classes: 10
[02/23 18:05:41] cifar10-global-random-2.0-mobilenetv2 INFO: Loading model from run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 18:05:44] cifar10-global-random-2.0-mobilenetv2 INFO: Pruning...
[02/23 18:05:51] cifar10-global-random-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 38, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(38, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=38)
        (4): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(38, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 86, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(86, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=86)
        (4): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(86, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 86, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(86, 86, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=86)
        (4): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(86, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 134, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(134, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=134)
        (4): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(134, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 134, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(134, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=134)
        (4): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(134, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 134, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(134, 134, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=134)
        (4): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(134, 6, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(6, 326, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(326, 326, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=326)
        (4): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(326, 6, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(6, 326, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(326, 326, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=326)
        (4): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(326, 6, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(6, 326, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(326, 326, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=326)
        (4): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(326, 6, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(6, 326, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(326, 326, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=326)
        (4): BatchNorm2d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(326, 38, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(38, 518, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(518, 518, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=518)
        (4): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(518, 38, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(38, 518, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(518, 518, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=518)
        (4): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(518, 38, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(38, 518, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(518, 518, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=518)
        (4): BatchNorm2d(518, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(518, 102, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(102, 902, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(902, 902, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=902)
        (4): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(902, 102, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(102, 902, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(902, 902, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=902)
        (4): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(902, 102, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(102, 902, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(902, 902, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=902)
      (4): BatchNorm2d(902, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(902, 262, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(262, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(262, 1222, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1222, 10, kernel_size=(1, 1), stride=(1, 1))
)
[02/23 18:05:54] cifar10-global-random-2.0-mobilenetv2 INFO: Params: 2.25 M => 1.31 M (57.96%)
[02/23 18:05:54] cifar10-global-random-2.0-mobilenetv2 INFO: FLOPs: 68.29 M => 34.03 M (49.84%, 2.01X )
[02/23 18:05:54] cifar10-global-random-2.0-mobilenetv2 INFO: Acc: 0.8936 => 0.1000
[02/23 18:05:54] cifar10-global-random-2.0-mobilenetv2 INFO: Val Loss: 0.3202 => 2.7348
[02/23 18:05:54] cifar10-global-random-2.0-mobilenetv2 INFO: Finetuning...
[02/23 18:06:23] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.4219, Val Loss=2.0734, lr=0.0100
[02/23 18:06:51] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.4748, Val Loss=2.0115, lr=0.0100
[02/23 18:07:19] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5085, Val Loss=1.8921, lr=0.0100
[02/23 18:07:48] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.5503, Val Loss=1.7813, lr=0.0100
[02/23 18:08:17] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5798, Val Loss=1.7324, lr=0.0100
[02/23 18:08:45] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.5827, Val Loss=1.7173, lr=0.0100
[02/23 18:09:14] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.5861, Val Loss=1.7132, lr=0.0100
[02/23 18:09:42] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6014, Val Loss=1.7226, lr=0.0100
[02/23 18:10:11] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.6098, Val Loss=1.6431, lr=0.0100
[02/23 18:10:39] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6589, Val Loss=1.5444, lr=0.0100
[02/23 18:11:08] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6254, Val Loss=1.6373, lr=0.0100
[02/23 18:11:36] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.5776, Val Loss=1.8506, lr=0.0100
[02/23 18:12:05] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.6833, Val Loss=1.4841, lr=0.0100
[02/23 18:12:33] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.6535, Val Loss=1.6054, lr=0.0100
[02/23 18:13:02] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.6718, Val Loss=1.5329, lr=0.0100
[02/23 18:13:30] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.6958, Val Loss=1.4232, lr=0.0100
[02/23 18:13:59] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.7076, Val Loss=1.4189, lr=0.0100
[02/23 18:14:27] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.7008, Val Loss=1.4134, lr=0.0100
[02/23 18:14:56] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6903, Val Loss=1.4682, lr=0.0100
[02/23 18:15:24] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.7212, Val Loss=1.3894, lr=0.0100
[02/23 18:15:53] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.7112, Val Loss=1.4348, lr=0.0100
[02/23 18:16:22] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.7389, Val Loss=1.3362, lr=0.0100
[02/23 18:16:50] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.6455, Val Loss=1.7302, lr=0.0100
[02/23 18:17:19] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.7381, Val Loss=1.3211, lr=0.0100
[02/23 18:17:48] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.6916, Val Loss=1.5821, lr=0.0100
[02/23 18:18:17] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.7501, Val Loss=1.3321, lr=0.0100
[02/23 18:18:45] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.7579, Val Loss=1.2888, lr=0.0100
[02/23 18:19:14] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.7489, Val Loss=1.3210, lr=0.0100
[02/23 18:19:43] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.7707, Val Loss=1.2642, lr=0.0100
[02/23 18:20:11] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.7598, Val Loss=1.2926, lr=0.0100
[02/23 18:20:40] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.7660, Val Loss=1.2796, lr=0.0100
[02/23 18:21:10] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.7755, Val Loss=1.2440, lr=0.0100
[02/23 18:21:39] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.7642, Val Loss=1.2718, lr=0.0100
[02/23 18:22:08] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.7719, Val Loss=1.2545, lr=0.0100
[02/23 18:22:37] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.7787, Val Loss=1.2322, lr=0.0100
[02/23 18:23:06] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.7413, Val Loss=1.3730, lr=0.0100
[02/23 18:23:35] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.7767, Val Loss=1.2348, lr=0.0100
[02/23 18:24:05] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.7813, Val Loss=1.2351, lr=0.0100
[02/23 18:24:34] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.7714, Val Loss=1.2910, lr=0.0100
[02/23 18:25:03] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.7686, Val Loss=1.2755, lr=0.0100
[02/23 18:25:31] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.7878, Val Loss=1.2135, lr=0.0100
[02/23 18:26:00] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.7975, Val Loss=1.1963, lr=0.0100
[02/23 18:26:29] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.8006, Val Loss=1.1916, lr=0.0100
[02/23 18:26:58] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.7543, Val Loss=1.3181, lr=0.0100
[02/23 18:27:27] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.7891, Val Loss=1.2182, lr=0.0100
[02/23 18:27:56] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.7826, Val Loss=1.2365, lr=0.0100
[02/23 18:28:25] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.7969, Val Loss=1.1920, lr=0.0100
[02/23 18:28:54] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.7322, Val Loss=1.4447, lr=0.0100
[02/23 18:29:22] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.7967, Val Loss=1.1933, lr=0.0100
[02/23 18:29:51] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.7814, Val Loss=1.2232, lr=0.0100
[02/23 18:30:20] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.7987, Val Loss=1.2036, lr=0.0100
[02/23 18:30:49] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.7928, Val Loss=1.2189, lr=0.0100
[02/23 18:31:18] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.8029, Val Loss=1.1823, lr=0.0100
[02/23 18:31:47] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.7916, Val Loss=1.2168, lr=0.0100
[02/23 18:32:16] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.8164, Val Loss=1.1410, lr=0.0100
[02/23 18:32:46] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.8091, Val Loss=1.1745, lr=0.0100
[02/23 18:33:15] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.8101, Val Loss=1.1576, lr=0.0100
[02/23 18:33:43] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.8059, Val Loss=1.1708, lr=0.0100
[02/23 18:34:12] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.8047, Val Loss=1.1780, lr=0.0100
[02/23 18:34:41] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.8036, Val Loss=1.1914, lr=0.0100
[02/23 18:35:11] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.8472, Val Loss=1.0621, lr=0.0010
[02/23 18:35:39] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.8425, Val Loss=1.0600, lr=0.0010
[02/23 18:36:08] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.8488, Val Loss=1.0522, lr=0.0010
[02/23 18:36:38] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.8446, Val Loss=1.0516, lr=0.0010
[02/23 18:37:06] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.8470, Val Loss=1.0523, lr=0.0010
[02/23 18:37:36] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.8480, Val Loss=1.0504, lr=0.0010
[02/23 18:38:05] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.8486, Val Loss=1.0467, lr=0.0010
[02/23 18:38:34] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.8512, Val Loss=1.0513, lr=0.0010
[02/23 18:39:02] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.8500, Val Loss=1.0616, lr=0.0010
[02/23 18:39:31] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.8548, Val Loss=1.0437, lr=0.0010
[02/23 18:40:00] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.8520, Val Loss=1.0525, lr=0.0010
[02/23 18:40:29] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.8545, Val Loss=1.0619, lr=0.0010
[02/23 18:40:58] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.8495, Val Loss=1.0651, lr=0.0010
[02/23 18:41:27] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.8502, Val Loss=1.0658, lr=0.0010
[02/23 18:41:57] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.8463, Val Loss=1.0712, lr=0.0010
[02/23 18:42:26] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.8515, Val Loss=1.0707, lr=0.0010
[02/23 18:42:54] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.8496, Val Loss=1.0721, lr=0.0010
[02/23 18:43:23] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.8506, Val Loss=1.0721, lr=0.0010
[02/23 18:43:52] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.8488, Val Loss=1.0737, lr=0.0010
[02/23 18:44:21] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.8517, Val Loss=1.0722, lr=0.0010
[02/23 18:44:49] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.8547, Val Loss=1.0631, lr=0.0001
[02/23 18:45:18] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.8535, Val Loss=1.0642, lr=0.0001
[02/23 18:45:46] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.8548, Val Loss=1.0642, lr=0.0001
[02/23 18:46:15] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.8540, Val Loss=1.0636, lr=0.0001
[02/23 18:46:44] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.8540, Val Loss=1.0628, lr=0.0001
[02/23 18:47:12] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.8531, Val Loss=1.0647, lr=0.0001
[02/23 18:47:41] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.8554, Val Loss=1.0644, lr=0.0001
[02/23 18:48:10] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.8556, Val Loss=1.0630, lr=0.0001
[02/23 18:48:39] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.8546, Val Loss=1.0657, lr=0.0001
[02/23 18:49:08] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.8534, Val Loss=1.0656, lr=0.0001
[02/23 18:49:37] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.8535, Val Loss=1.0661, lr=0.0001
[02/23 18:50:07] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.8561, Val Loss=1.0689, lr=0.0001
[02/23 18:50:36] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.8552, Val Loss=1.0709, lr=0.0001
[02/23 18:51:05] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.8542, Val Loss=1.0705, lr=0.0001
[02/23 18:51:34] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.8544, Val Loss=1.0702, lr=0.0001
[02/23 18:52:03] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.8544, Val Loss=1.0719, lr=0.0001
[02/23 18:52:32] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.8546, Val Loss=1.0712, lr=0.0001
[02/23 18:53:00] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.8519, Val Loss=1.0715, lr=0.0001
[02/23 18:53:30] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.8539, Val Loss=1.0685, lr=0.0001
[02/23 18:53:59] cifar10-global-random-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.8527, Val Loss=1.0731, lr=0.0001
[02/23 18:53:59] cifar10-global-random-2.0-mobilenetv2 INFO: Best Acc=0.8561
[02/23 18:53:59] cifar10-global-random-2.0-mobilenetv2 INFO: Params: 1.31 M
[02/23 18:53:59] cifar10-global-random-2.0-mobilenetv2 INFO: ops: 34.03 M
[02/23 18:54:02] cifar10-global-random-2.0-mobilenetv2 INFO: Acc: 0.8527 Val Loss: 1.0731

