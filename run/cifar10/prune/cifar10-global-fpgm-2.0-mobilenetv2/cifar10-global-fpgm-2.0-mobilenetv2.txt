[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: mode: prune
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: verbose: False
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: dataset: cifar10
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: dataroot: data
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: batch_size: 128
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: total_epochs: 100
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: lr: 0.01
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: restore: run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: output_dir: run/cifar10/prune/cifar10-global-fpgm-2.0-mobilenetv2
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: finetune: True
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: last_epochs: 100
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: reps: 1
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: method: fpgm
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: reg: 1e-05
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: seed: 1
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: global_pruning: True
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: sl_restore: None
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: logger: <Logger cifar10-global-fpgm-2.0-mobilenetv2 (DEBUG)>
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: device: cuda
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: num_classes: 10
[02/23 19:43:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Loading model from run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 19:43:38] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Pruning...
[02/23 19:44:00] cifar10-global-fpgm-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 7, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(7, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 45, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45)
        (4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(45, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 46, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(46, 46, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=46)
        (4): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(46, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 86, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(86, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=86)
        (4): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(86, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 46, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(46, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=46)
        (4): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(46, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 30, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=30)
        (4): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(30, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 89, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=89)
        (4): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(89, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 5, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)
        (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(5, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)
        (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 206, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(206, 206, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=206)
        (4): BatchNorm2d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(206, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 16, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 5, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)
        (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(5, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 564, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(564, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(564, 564, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=564)
      (4): BatchNorm2d(564, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(564, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 10, kernel_size=(1, 1), stride=(1, 1))
)
[02/23 19:44:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Params: 2.25 M => 0.86 M (38.31%)
[02/23 19:44:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: FLOPs: 68.29 M => 31.19 M (45.67%, 2.19X )
[02/23 19:44:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Acc: 0.8936 => 0.8935
[02/23 19:44:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Val Loss: 0.3202 => 0.3202
[02/23 19:44:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Finetuning...
[02/23 19:44:31] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.8566, Val Loss=0.4284, lr=0.0100
[02/23 19:44:59] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.8397, Val Loss=0.4808, lr=0.0100
[02/23 19:45:28] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.8372, Val Loss=0.4797, lr=0.0100
[02/23 19:45:56] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.8574, Val Loss=0.4162, lr=0.0100
[02/23 19:46:25] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.8564, Val Loss=0.4166, lr=0.0100
[02/23 19:46:53] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.8424, Val Loss=0.4558, lr=0.0100
[02/23 19:47:21] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.8538, Val Loss=0.4312, lr=0.0100
[02/23 19:47:50] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.8404, Val Loss=0.4670, lr=0.0100
[02/23 19:48:19] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.8600, Val Loss=0.4249, lr=0.0100
[02/23 19:48:47] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.8516, Val Loss=0.4296, lr=0.0100
[02/23 19:49:16] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.8464, Val Loss=0.4587, lr=0.0100
[02/23 19:49:44] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.8572, Val Loss=0.4243, lr=0.0100
[02/23 19:50:12] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.8551, Val Loss=0.4225, lr=0.0100
[02/23 19:50:41] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.8388, Val Loss=0.4787, lr=0.0100
[02/23 19:51:10] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.8389, Val Loss=0.4766, lr=0.0100
[02/23 19:51:39] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.8245, Val Loss=0.5357, lr=0.0100
[02/23 19:52:08] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.8146, Val Loss=0.5544, lr=0.0100
[02/23 19:52:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.8572, Val Loss=0.4186, lr=0.0100
[02/23 19:53:05] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.8494, Val Loss=0.4332, lr=0.0100
[02/23 19:53:34] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.8410, Val Loss=0.4630, lr=0.0100
[02/23 19:54:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.8474, Val Loss=0.4557, lr=0.0100
[02/23 19:54:31] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.8552, Val Loss=0.4270, lr=0.0100
[02/23 19:55:00] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.8568, Val Loss=0.4361, lr=0.0100
[02/23 19:55:29] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.8566, Val Loss=0.4201, lr=0.0100
[02/23 19:55:57] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.8583, Val Loss=0.4202, lr=0.0100
[02/23 19:56:26] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.8552, Val Loss=0.4312, lr=0.0100
[02/23 19:56:54] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.8553, Val Loss=0.4229, lr=0.0100
[02/23 19:57:22] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.8500, Val Loss=0.4549, lr=0.0100
[02/23 19:57:50] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.8548, Val Loss=0.4364, lr=0.0100
[02/23 19:58:19] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.8633, Val Loss=0.3958, lr=0.0100
[02/23 19:58:47] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.8512, Val Loss=0.4350, lr=0.0100
[02/23 19:59:16] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.8478, Val Loss=0.4461, lr=0.0100
[02/23 19:59:44] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.8250, Val Loss=0.5389, lr=0.0100
[02/23 20:00:12] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.8593, Val Loss=0.4287, lr=0.0100
[02/23 20:00:41] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.8554, Val Loss=0.4344, lr=0.0100
[02/23 20:01:10] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.8452, Val Loss=0.4531, lr=0.0100
[02/23 20:01:39] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.8519, Val Loss=0.4348, lr=0.0100
[02/23 20:02:08] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.8514, Val Loss=0.4508, lr=0.0100
[02/23 20:02:37] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.8663, Val Loss=0.4082, lr=0.0100
[02/23 20:03:06] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.8606, Val Loss=0.4140, lr=0.0100
[02/23 20:03:35] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.8643, Val Loss=0.4128, lr=0.0100
[02/23 20:04:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.8595, Val Loss=0.4155, lr=0.0100
[02/23 20:04:32] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.8415, Val Loss=0.4739, lr=0.0100
[02/23 20:05:01] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.8473, Val Loss=0.4490, lr=0.0100
[02/23 20:05:30] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.8600, Val Loss=0.4105, lr=0.0100
[02/23 20:05:58] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.8409, Val Loss=0.4790, lr=0.0100
[02/23 20:06:27] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.8516, Val Loss=0.4418, lr=0.0100
[02/23 20:06:53] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.8574, Val Loss=0.4279, lr=0.0100
[02/23 20:07:20] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.8317, Val Loss=0.4977, lr=0.0100
[02/23 20:07:47] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.8517, Val Loss=0.4319, lr=0.0100
[02/23 20:08:14] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.8636, Val Loss=0.4029, lr=0.0100
[02/23 20:08:41] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.8601, Val Loss=0.4200, lr=0.0100
[02/23 20:09:08] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.8587, Val Loss=0.4118, lr=0.0100
[02/23 20:09:35] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.8599, Val Loss=0.4066, lr=0.0100
[02/23 20:10:02] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.8529, Val Loss=0.4307, lr=0.0100
[02/23 20:10:30] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.8420, Val Loss=0.4596, lr=0.0100
[02/23 20:10:57] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.8456, Val Loss=0.4491, lr=0.0100
[02/23 20:11:24] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.8513, Val Loss=0.4329, lr=0.0100
[02/23 20:11:52] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.8625, Val Loss=0.4026, lr=0.0100
[02/23 20:12:19] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.8577, Val Loss=0.4218, lr=0.0100
[02/23 20:12:46] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.8899, Val Loss=0.3209, lr=0.0010
[02/23 20:13:13] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.8932, Val Loss=0.3132, lr=0.0010
[02/23 20:13:41] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.8958, Val Loss=0.3078, lr=0.0010
[02/23 20:14:08] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.8965, Val Loss=0.3089, lr=0.0010
[02/23 20:14:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.8950, Val Loss=0.3062, lr=0.0010
[02/23 20:15:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.8988, Val Loss=0.3074, lr=0.0010
[02/23 20:15:31] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.8974, Val Loss=0.3066, lr=0.0010
[02/23 20:15:58] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.8987, Val Loss=0.3051, lr=0.0010
[02/23 20:16:26] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.8993, Val Loss=0.3103, lr=0.0010
[02/23 20:16:53] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.8970, Val Loss=0.3094, lr=0.0010
[02/23 20:17:21] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.8992, Val Loss=0.3090, lr=0.0010
[02/23 20:17:49] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.8986, Val Loss=0.3091, lr=0.0010
[02/23 20:18:16] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.8987, Val Loss=0.3050, lr=0.0010
[02/23 20:18:44] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.9002, Val Loss=0.3073, lr=0.0010
[02/23 20:19:12] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.9008, Val Loss=0.3050, lr=0.0010
[02/23 20:19:40] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.9000, Val Loss=0.3066, lr=0.0010
[02/23 20:20:07] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.8987, Val Loss=0.3091, lr=0.0010
[02/23 20:20:35] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.8995, Val Loss=0.3068, lr=0.0010
[02/23 20:21:03] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.8985, Val Loss=0.3075, lr=0.0010
[02/23 20:21:30] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.8975, Val Loss=0.3089, lr=0.0010
[02/23 20:21:58] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.8998, Val Loss=0.3043, lr=0.0001
[02/23 20:22:25] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.9006, Val Loss=0.3033, lr=0.0001
[02/23 20:22:53] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.9021, Val Loss=0.3041, lr=0.0001
[02/23 20:23:21] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.9003, Val Loss=0.3037, lr=0.0001
[02/23 20:23:48] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.9018, Val Loss=0.3029, lr=0.0001
[02/23 20:24:15] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.9004, Val Loss=0.3033, lr=0.0001
[02/23 20:24:43] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.9011, Val Loss=0.3034, lr=0.0001
[02/23 20:25:10] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.9002, Val Loss=0.3027, lr=0.0001
[02/23 20:25:38] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.9019, Val Loss=0.3023, lr=0.0001
[02/23 20:26:05] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.9011, Val Loss=0.3029, lr=0.0001
[02/23 20:26:32] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.9001, Val Loss=0.3048, lr=0.0001
[02/23 20:26:59] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.9021, Val Loss=0.3026, lr=0.0001
[02/23 20:27:26] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.9025, Val Loss=0.3013, lr=0.0001
[02/23 20:27:54] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.9009, Val Loss=0.3033, lr=0.0001
[02/23 20:28:21] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.9020, Val Loss=0.3026, lr=0.0001
[02/23 20:28:48] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.9012, Val Loss=0.3037, lr=0.0001
[02/23 20:29:15] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.9024, Val Loss=0.3020, lr=0.0001
[02/23 20:29:42] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.9019, Val Loss=0.3026, lr=0.0001
[02/23 20:30:09] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.9009, Val Loss=0.3020, lr=0.0001
[02/23 20:30:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.9017, Val Loss=0.3023, lr=0.0001
[02/23 20:30:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Best Acc=0.9025
[02/23 20:30:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Params: 0.86 M
[02/23 20:30:36] cifar10-global-fpgm-2.0-mobilenetv2 INFO: ops: 31.19 M
[02/23 20:30:39] cifar10-global-fpgm-2.0-mobilenetv2 INFO: Acc: 0.9017 Val Loss: 0.3023

