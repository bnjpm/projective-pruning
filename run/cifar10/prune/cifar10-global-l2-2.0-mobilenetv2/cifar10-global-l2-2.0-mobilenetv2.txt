[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: mode: prune
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: verbose: False
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: dataset: cifar10
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: dataroot: data
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: batch_size: 128
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: total_epochs: 100
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: lr: 0.01
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: restore: run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: output_dir: run/cifar10/prune/cifar10-global-l2-2.0-mobilenetv2
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: finetune: True
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: last_epochs: 100
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: reps: 1
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: method: l2
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: reg: 1e-05
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: seed: 1
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: global_pruning: True
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: sl_restore: None
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: logger: <Logger cifar10-global-l2-2.0-mobilenetv2 (DEBUG)>
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: device: cuda
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: num_classes: 10
[02/23 18:54:09] cifar10-global-l2-2.0-mobilenetv2 INFO: Loading model from run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/23 18:54:13] cifar10-global-l2-2.0-mobilenetv2 INFO: Pruning...
[02/23 18:54:36] cifar10-global-l2-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 7, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(7, 17, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(17, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=17)
      (4): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(17, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 73, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(73, 73, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=73)
        (4): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(73, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 86, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(86, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=86)
        (4): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(86, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 60, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(60, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=60)
        (4): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(60, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 88, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88)
        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 52, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=52)
        (4): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(52, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 50, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(50, 50, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=50)
        (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(50, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 54, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
        (4): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(54, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 36, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36)
        (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 95, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=95)
        (4): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(95, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 232, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232)
        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(232, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 16, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 5, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)
        (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(5, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 629, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(629, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(629, 629, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=629)
      (4): BatchNorm2d(629, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(629, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 10, kernel_size=(1, 1), stride=(1, 1))
)
[02/23 18:54:39] cifar10-global-l2-2.0-mobilenetv2 INFO: Params: 2.25 M => 1.12 M (49.90%)
[02/23 18:54:39] cifar10-global-l2-2.0-mobilenetv2 INFO: FLOPs: 68.29 M => 34.08 M (49.91%, 2.00X )
[02/23 18:54:39] cifar10-global-l2-2.0-mobilenetv2 INFO: Acc: 0.8936 => 0.8936
[02/23 18:54:39] cifar10-global-l2-2.0-mobilenetv2 INFO: Val Loss: 0.3202 => 0.3202
[02/23 18:54:39] cifar10-global-l2-2.0-mobilenetv2 INFO: Finetuning...
[02/23 18:55:08] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.8502, Val Loss=0.4397, lr=0.0100
[02/23 18:55:37] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.8431, Val Loss=0.4663, lr=0.0100
[02/23 18:56:06] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.8510, Val Loss=0.4422, lr=0.0100
[02/23 18:56:35] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.8649, Val Loss=0.3960, lr=0.0100
[02/23 18:57:04] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.8572, Val Loss=0.4133, lr=0.0100
[02/23 18:57:32] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.8293, Val Loss=0.4998, lr=0.0100
[02/23 18:58:01] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.8295, Val Loss=0.5050, lr=0.0100
[02/23 18:58:30] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.8528, Val Loss=0.4424, lr=0.0100
[02/23 18:58:59] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.8572, Val Loss=0.4162, lr=0.0100
[02/23 18:59:28] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.8579, Val Loss=0.4249, lr=0.0100
[02/23 18:59:57] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.8544, Val Loss=0.4273, lr=0.0100
[02/23 19:00:26] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.8564, Val Loss=0.4244, lr=0.0100
[02/23 19:00:55] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.8535, Val Loss=0.4261, lr=0.0100
[02/23 19:01:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.8602, Val Loss=0.4119, lr=0.0100
[02/23 19:01:53] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.8597, Val Loss=0.4136, lr=0.0100
[02/23 19:02:22] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.8368, Val Loss=0.4849, lr=0.0100
[02/23 19:02:52] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.8525, Val Loss=0.4344, lr=0.0100
[02/23 19:03:21] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.8555, Val Loss=0.4301, lr=0.0100
[02/23 19:03:50] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.8498, Val Loss=0.4489, lr=0.0100
[02/23 19:04:19] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.8135, Val Loss=0.5638, lr=0.0100
[02/23 19:04:48] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.8328, Val Loss=0.4842, lr=0.0100
[02/23 19:05:18] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.8551, Val Loss=0.4260, lr=0.0100
[02/23 19:05:47] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.8510, Val Loss=0.4326, lr=0.0100
[02/23 19:06:16] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.8605, Val Loss=0.4163, lr=0.0100
[02/23 19:06:45] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.8503, Val Loss=0.4544, lr=0.0100
[02/23 19:07:14] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.8560, Val Loss=0.4197, lr=0.0100
[02/23 19:07:43] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.8506, Val Loss=0.4439, lr=0.0100
[02/23 19:08:12] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.8476, Val Loss=0.4499, lr=0.0100
[02/23 19:08:41] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.8606, Val Loss=0.4194, lr=0.0100
[02/23 19:09:10] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.8440, Val Loss=0.4624, lr=0.0100
[02/23 19:09:39] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.8560, Val Loss=0.4238, lr=0.0100
[02/23 19:10:08] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.8417, Val Loss=0.4631, lr=0.0100
[02/23 19:10:38] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.8563, Val Loss=0.4386, lr=0.0100
[02/23 19:11:07] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.8581, Val Loss=0.4184, lr=0.0100
[02/23 19:11:36] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.8616, Val Loss=0.4125, lr=0.0100
[02/23 19:12:05] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.8651, Val Loss=0.3979, lr=0.0100
[02/23 19:12:33] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.8646, Val Loss=0.4110, lr=0.0100
[02/23 19:13:02] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.8727, Val Loss=0.3864, lr=0.0100
[02/23 19:13:31] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.8626, Val Loss=0.4113, lr=0.0100
[02/23 19:13:59] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.8539, Val Loss=0.4399, lr=0.0100
[02/23 19:14:29] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.8516, Val Loss=0.4440, lr=0.0100
[02/23 19:14:58] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.8625, Val Loss=0.4003, lr=0.0100
[02/23 19:15:27] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.8620, Val Loss=0.4095, lr=0.0100
[02/23 19:15:56] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.8441, Val Loss=0.4649, lr=0.0100
[02/23 19:16:25] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.8543, Val Loss=0.4338, lr=0.0100
[02/23 19:16:54] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.8496, Val Loss=0.4518, lr=0.0100
[02/23 19:17:22] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.8498, Val Loss=0.4426, lr=0.0100
[02/23 19:17:51] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.8509, Val Loss=0.4458, lr=0.0100
[02/23 19:18:21] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.8458, Val Loss=0.4473, lr=0.0100
[02/23 19:18:49] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.8631, Val Loss=0.4075, lr=0.0100
[02/23 19:19:18] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.8682, Val Loss=0.3900, lr=0.0100
[02/23 19:19:47] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.8532, Val Loss=0.4418, lr=0.0100
[02/23 19:20:16] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.8505, Val Loss=0.4498, lr=0.0100
[02/23 19:20:45] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.8565, Val Loss=0.4262, lr=0.0100
[02/23 19:21:14] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.8646, Val Loss=0.3985, lr=0.0100
[02/23 19:21:43] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.8628, Val Loss=0.4008, lr=0.0100
[02/23 19:22:12] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.8682, Val Loss=0.4013, lr=0.0100
[02/23 19:22:40] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.8496, Val Loss=0.4527, lr=0.0100
[02/23 19:23:09] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.8559, Val Loss=0.4342, lr=0.0100
[02/23 19:23:38] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.8625, Val Loss=0.4098, lr=0.0100
[02/23 19:24:07] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.8920, Val Loss=0.3223, lr=0.0010
[02/23 19:24:37] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.8933, Val Loss=0.3159, lr=0.0010
[02/23 19:25:06] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.8931, Val Loss=0.3114, lr=0.0010
[02/23 19:25:36] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.8942, Val Loss=0.3116, lr=0.0010
[02/23 19:26:06] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.8956, Val Loss=0.3097, lr=0.0010
[02/23 19:26:36] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.8948, Val Loss=0.3097, lr=0.0010
[02/23 19:27:06] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.8954, Val Loss=0.3113, lr=0.0010
[02/23 19:27:35] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.8951, Val Loss=0.3102, lr=0.0010
[02/23 19:28:05] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.8951, Val Loss=0.3111, lr=0.0010
[02/23 19:28:34] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.8961, Val Loss=0.3115, lr=0.0010
[02/23 19:29:04] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.8970, Val Loss=0.3107, lr=0.0010
[02/23 19:29:34] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.8955, Val Loss=0.3071, lr=0.0010
[02/23 19:30:04] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.8970, Val Loss=0.3124, lr=0.0010
[02/23 19:30:33] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.8969, Val Loss=0.3116, lr=0.0010
[02/23 19:31:03] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.8966, Val Loss=0.3102, lr=0.0010
[02/23 19:31:33] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.8977, Val Loss=0.3099, lr=0.0010
[02/23 19:32:02] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.8957, Val Loss=0.3094, lr=0.0010
[02/23 19:32:32] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.8969, Val Loss=0.3104, lr=0.0010
[02/23 19:33:01] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.8988, Val Loss=0.3086, lr=0.0010
[02/23 19:33:31] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.8953, Val Loss=0.3128, lr=0.0010
[02/23 19:34:00] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.8963, Val Loss=0.3071, lr=0.0001
[02/23 19:34:30] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.8968, Val Loss=0.3069, lr=0.0001
[02/23 19:34:59] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.8990, Val Loss=0.3078, lr=0.0001
[02/23 19:35:29] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.8983, Val Loss=0.3071, lr=0.0001
[02/23 19:35:58] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.8978, Val Loss=0.3058, lr=0.0001
[02/23 19:36:27] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.8981, Val Loss=0.3056, lr=0.0001
[02/23 19:36:56] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.8971, Val Loss=0.3079, lr=0.0001
[02/23 19:37:26] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.8997, Val Loss=0.3051, lr=0.0001
[02/23 19:37:56] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.8975, Val Loss=0.3059, lr=0.0001
[02/23 19:38:26] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.8994, Val Loss=0.3062, lr=0.0001
[02/23 19:38:55] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.8977, Val Loss=0.3080, lr=0.0001
[02/23 19:39:25] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.8970, Val Loss=0.3064, lr=0.0001
[02/23 19:39:55] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.8993, Val Loss=0.3040, lr=0.0001
[02/23 19:40:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.8977, Val Loss=0.3069, lr=0.0001
[02/23 19:40:54] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.8994, Val Loss=0.3051, lr=0.0001
[02/23 19:41:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.8989, Val Loss=0.3055, lr=0.0001
[02/23 19:41:54] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.8989, Val Loss=0.3050, lr=0.0001
[02/23 19:42:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.8969, Val Loss=0.3053, lr=0.0001
[02/23 19:42:54] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.8984, Val Loss=0.3057, lr=0.0001
[02/23 19:43:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.8992, Val Loss=0.3056, lr=0.0001
[02/23 19:43:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Best Acc=0.8997
[02/23 19:43:24] cifar10-global-l2-2.0-mobilenetv2 INFO: Params: 1.12 M
[02/23 19:43:24] cifar10-global-l2-2.0-mobilenetv2 INFO: ops: 34.08 M
[02/23 19:43:27] cifar10-global-l2-2.0-mobilenetv2 INFO: Acc: 0.8992 Val Loss: 0.3056

