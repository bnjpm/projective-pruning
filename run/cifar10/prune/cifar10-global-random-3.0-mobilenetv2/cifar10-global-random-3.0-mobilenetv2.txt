[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: mode: prune
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: model: mobilenetv2
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: verbose: False
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: dataset: cifar10
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: dataroot: data
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: batch_size: 128
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: total_epochs: 100
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: lr: 0.01
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: restore: run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: output_dir: run/cifar10/prune/cifar10-global-random-3.0-mobilenetv2
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: finetune: True
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: last_epochs: 100
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: reps: 1
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: method: random
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: speed_up: 3.0
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: reg: 1e-05
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: seed: 1
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: global_pruning: True
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: sl_lr: 0.01
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: sl_restore: None
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: iterative_steps: 400
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: logger: <Logger cifar10-global-random-3.0-mobilenetv2 (DEBUG)>
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: device: cuda
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: num_classes: 10
[02/26 03:20:55] cifar10-global-random-3.0-mobilenetv2 INFO: Loading model from run/cifar10/pretrain/cifar10_mobilenetv2.pth
[02/26 03:20:59] cifar10-global-random-3.0-mobilenetv2 INFO: Pruning...
[02/26 03:21:10] cifar10-global-random-3.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 49, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(49, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=49)
        (4): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 49, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(49, 49, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=49)
        (4): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 97, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=97)
        (4): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(97, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 97, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=97)
        (4): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(97, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 97, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(97, 97, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=97)
        (4): BatchNorm2d(97, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(97, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 289, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(289, 289, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=289)
        (4): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(289, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 289, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(289, 289, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=289)
        (4): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(289, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 289, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(289, 289, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=289)
        (4): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(289, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 289, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(289, 289, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=289)
        (4): BatchNorm2d(289, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(289, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 481, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(481, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=481)
        (4): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(481, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 481, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(481, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=481)
        (4): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(481, 1, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(1, 481, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(481, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=481)
        (4): BatchNorm2d(481, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(481, 65, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(65, 865, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(865, 865, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=865)
        (4): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(865, 65, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(65, 865, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(865, 865, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=865)
        (4): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(865, 65, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(65, 865, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(865, 865, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=865)
      (4): BatchNorm2d(865, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(865, 225, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(225, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(225, 1185, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1185, 10, kernel_size=(1, 1), stride=(1, 1))
)
[02/26 03:21:13] cifar10-global-random-3.0-mobilenetv2 INFO: Params: 2.25 M => 0.88 M (39.02%)
[02/26 03:21:13] cifar10-global-random-3.0-mobilenetv2 INFO: FLOPs: 68.29 M => 22.64 M (33.16%, 3.02X )
[02/26 03:21:13] cifar10-global-random-3.0-mobilenetv2 INFO: Acc: 0.8936 => 0.1000
[02/26 03:21:13] cifar10-global-random-3.0-mobilenetv2 INFO: Val Loss: 0.3202 => 2.8661
[02/26 03:21:13] cifar10-global-random-3.0-mobilenetv2 INFO: Finetuning...
[02/26 03:21:39] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.4542, Val Loss=2.0359, lr=0.0100
[02/26 03:22:06] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.5071, Val Loss=2.0377, lr=0.0100
[02/26 03:22:33] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5408, Val Loss=1.8546, lr=0.0100
[02/26 03:22:59] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.5826, Val Loss=1.7438, lr=0.0100
[02/26 03:23:26] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.6121, Val Loss=1.6949, lr=0.0100
[02/26 03:23:53] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.6150, Val Loss=1.6798, lr=0.0100
[02/26 03:24:20] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.6184, Val Loss=1.6757, lr=0.0100
[02/26 03:24:46] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6337, Val Loss=1.6851, lr=0.0100
[02/26 03:25:13] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.6421, Val Loss=1.6056, lr=0.0100
[02/26 03:25:40] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6912, Val Loss=1.5069, lr=0.0100
[02/26 03:26:07] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6577, Val Loss=1.5998, lr=0.0100
[02/26 03:26:33] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6099, Val Loss=1.8131, lr=0.0100
[02/26 03:27:00] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.7156, Val Loss=1.4466, lr=0.0100
[02/26 03:27:26] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.6858, Val Loss=1.5679, lr=0.0100
[02/26 03:27:53] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.7041, Val Loss=1.4954, lr=0.0100
[02/26 03:28:20] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.7281, Val Loss=1.3857, lr=0.0100
[02/26 03:28:47] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.7399, Val Loss=1.3814, lr=0.0100
[02/26 03:29:14] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.7331, Val Loss=1.3759, lr=0.0100
[02/26 03:29:41] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.7226, Val Loss=1.4307, lr=0.0100
[02/26 03:30:08] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.7535, Val Loss=1.3519, lr=0.0100
[02/26 03:30:36] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.7435, Val Loss=1.3973, lr=0.0100
[02/26 03:31:03] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.7712, Val Loss=1.2987, lr=0.0100
[02/26 03:31:30] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.6778, Val Loss=1.6927, lr=0.0100
[02/26 03:31:57] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.7704, Val Loss=1.2836, lr=0.0100
[02/26 03:32:24] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.7239, Val Loss=1.5446, lr=0.0100
[02/26 03:32:51] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.7824, Val Loss=1.2946, lr=0.0100
[02/26 03:33:18] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.7902, Val Loss=1.2513, lr=0.0100
[02/26 03:33:45] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.7812, Val Loss=1.2835, lr=0.0100
[02/26 03:34:13] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.8030, Val Loss=1.2267, lr=0.0100
[02/26 03:34:40] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.7921, Val Loss=1.2551, lr=0.0100
[02/26 03:35:07] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.7983, Val Loss=1.2421, lr=0.0100
[02/26 03:35:34] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.8078, Val Loss=1.2065, lr=0.0100
[02/26 03:36:01] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.7965, Val Loss=1.2343, lr=0.0100
[02/26 03:36:28] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.8042, Val Loss=1.2170, lr=0.0100
[02/26 03:36:55] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.8110, Val Loss=1.1947, lr=0.0100
[02/26 03:37:22] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.7736, Val Loss=1.3355, lr=0.0100
[02/26 03:37:50] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.8090, Val Loss=1.1973, lr=0.0100
[02/26 03:38:17] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.8136, Val Loss=1.1976, lr=0.0100
[02/26 03:38:44] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.8037, Val Loss=1.2535, lr=0.0100
[02/26 03:39:11] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.8009, Val Loss=1.2380, lr=0.0100
[02/26 03:39:38] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.8201, Val Loss=1.1760, lr=0.0100
[02/26 03:40:05] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.8298, Val Loss=1.1588, lr=0.0100
[02/26 03:40:32] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.8329, Val Loss=1.1541, lr=0.0100
[02/26 03:40:59] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.7866, Val Loss=1.2806, lr=0.0100
[02/26 03:41:26] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.8214, Val Loss=1.1807, lr=0.0100
[02/26 03:41:53] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.8149, Val Loss=1.1990, lr=0.0100
[02/26 03:42:20] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.8292, Val Loss=1.1545, lr=0.0100
[02/26 03:42:47] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.7645, Val Loss=1.4072, lr=0.0100
[02/26 03:43:14] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.8290, Val Loss=1.1558, lr=0.0100
[02/26 03:43:41] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.8137, Val Loss=1.1857, lr=0.0100
[02/26 03:44:08] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.8310, Val Loss=1.1661, lr=0.0100
[02/26 03:44:35] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.8251, Val Loss=1.1814, lr=0.0100
[02/26 03:45:02] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.8352, Val Loss=1.1448, lr=0.0100
[02/26 03:45:29] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.8239, Val Loss=1.1793, lr=0.0100
[02/26 03:45:56] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.8487, Val Loss=1.1035, lr=0.0100
[02/26 03:46:23] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.8414, Val Loss=1.1370, lr=0.0100
[02/26 03:46:50] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.8424, Val Loss=1.1201, lr=0.0100
[02/26 03:47:17] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.8382, Val Loss=1.1333, lr=0.0100
[02/26 03:47:44] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.8370, Val Loss=1.1405, lr=0.0100
[02/26 03:48:11] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.8359, Val Loss=1.1539, lr=0.0100
[02/26 03:48:38] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.8795, Val Loss=1.1246, lr=0.0010
[02/26 03:49:05] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.8748, Val Loss=1.1225, lr=0.0010
[02/26 03:49:32] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.8811, Val Loss=1.1625, lr=0.0010
[02/26 03:49:59] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.8769, Val Loss=1.1621, lr=0.0010
[02/26 03:50:26] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.8793, Val Loss=1.1626, lr=0.0010
[02/26 03:50:52] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.8803, Val Loss=1.1607, lr=0.0010
[02/26 03:51:19] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.8809, Val Loss=1.1572, lr=0.0010
[02/26 03:51:46] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.8835, Val Loss=1.1616, lr=0.0010
[02/26 03:52:13] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.8823, Val Loss=1.0241, lr=0.0010
[02/26 03:52:40] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.8871, Val Loss=1.0650, lr=0.0010
[02/26 03:53:07] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.8843, Val Loss=1.0736, lr=0.0010
[02/26 03:53:34] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.8868, Val Loss=1.0244, lr=0.0010
[02/26 03:54:01] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.8818, Val Loss=1.0276, lr=0.0010
[02/26 03:54:28] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.8825, Val Loss=1.0283, lr=0.0010
[02/26 03:54:55] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.8786, Val Loss=1.0337, lr=0.0010
[02/26 03:55:22] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.8838, Val Loss=1.0332, lr=0.0010
[02/26 03:55:49] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.8819, Val Loss=1.0346, lr=0.0010
[02/26 03:56:16] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.8829, Val Loss=1.0346, lr=0.0010
[02/26 03:56:43] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.8811, Val Loss=1.0362, lr=0.0010
[02/26 03:57:10] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.8840, Val Loss=1.0347, lr=0.0010
[02/26 03:57:37] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.8870, Val Loss=1.0256, lr=0.0001
[02/26 03:58:04] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.8858, Val Loss=1.0267, lr=0.0001
[02/26 03:58:31] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.8871, Val Loss=1.0267, lr=0.0001
[02/26 03:58:58] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.8863, Val Loss=1.0261, lr=0.0001
[02/26 03:59:25] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.8863, Val Loss=1.0253, lr=0.0001
[02/26 03:59:53] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.8854, Val Loss=1.0272, lr=0.0001
[02/26 04:00:20] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.8877, Val Loss=1.0269, lr=0.0001
[02/26 04:00:48] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.8879, Val Loss=1.0255, lr=0.0001
[02/26 04:01:15] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.8869, Val Loss=1.0282, lr=0.0001
[02/26 04:01:42] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.8857, Val Loss=1.0281, lr=0.0001
[02/26 04:02:09] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.8858, Val Loss=1.0286, lr=0.0001
[02/26 04:02:36] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.8884, Val Loss=1.0314, lr=0.0001
[02/26 04:03:04] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.8875, Val Loss=1.0334, lr=0.0001
[02/26 04:03:31] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.8865, Val Loss=1.0330, lr=0.0001
[02/26 04:03:58] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.8867, Val Loss=1.0327, lr=0.0001
[02/26 04:04:25] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.8867, Val Loss=1.0344, lr=0.0001
[02/26 04:04:52] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.8869, Val Loss=1.0337, lr=0.0001
[02/26 04:05:20] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.8842, Val Loss=1.0340, lr=0.0001
[02/26 04:05:47] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.8862, Val Loss=1.0310, lr=0.0001
[02/26 04:06:14] cifar10-global-random-3.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.8850, Val Loss=1.0356, lr=0.0001
[02/26 04:06:14] cifar10-global-random-3.0-mobilenetv2 INFO: Best Acc=0.8884
[02/26 04:06:14] cifar10-global-random-3.0-mobilenetv2 INFO: Params: 0.88 M
[02/26 04:06:14] cifar10-global-random-3.0-mobilenetv2 INFO: ops: 22.64 M
[02/26 04:06:17] cifar10-global-random-3.0-mobilenetv2 INFO: Acc: 0.8850 Val Loss: 1.0356

