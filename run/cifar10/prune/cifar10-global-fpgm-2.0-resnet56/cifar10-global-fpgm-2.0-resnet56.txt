[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: mode: prune
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: model: resnet56
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: verbose: False
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: dataset: cifar10
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: dataroot: data
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: batch_size: 128
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: total_epochs: 100
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: lr: 0.01
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: restore: run/cifar10/pretrain/cifar10_resnet56.pth
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: output_dir: run/cifar10/prune/cifar10-global-fpgm-2.0-resnet56
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: finetune: True
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: last_epochs: 100
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: reps: 1
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: method: fpgm
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: speed_up: 2.0
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: reg: 1e-05
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: delta_reg: 0.0001
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: weight_decay: 0.0005
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: seed: 1
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: global_pruning: True
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: sl_total_epochs: 100
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: sl_lr: 0.01
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: sl_restore: None
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: iterative_steps: 400
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: logger: <Logger cifar10-global-fpgm-2.0-resnet56 (DEBUG)>
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: device: cuda
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: num_classes: 10
[02/20 22:43:52] cifar10-global-fpgm-2.0-resnet56 INFO: Loading model from run/cifar10/pretrain/cifar10_resnet56.pth
[02/20 22:43:56] cifar10-global-fpgm-2.0-resnet56 INFO: Pruning...
[02/20 22:44:11] cifar10-global-fpgm-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(15, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(15, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(15, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(15, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(15, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(15, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(15, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(13, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(15, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(13, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(15, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(15, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(25, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(15, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(24, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(21, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(24, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(28, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(24, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(24, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(20, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(24, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(24, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(24, 36, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(36, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(60, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(36, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(57, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(36, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(36, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(53, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(36, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(36, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(53, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(36, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(45, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=36, out_features=10, bias=True)
)
[02/20 22:44:14] cifar10-global-fpgm-2.0-resnet56 INFO: Params: 0.86 M => 0.40 M (46.84%)
[02/20 22:44:14] cifar10-global-fpgm-2.0-resnet56 INFO: FLOPs: 127.12 M => 62.99 M (49.55%, 2.02X )
[02/20 22:44:14] cifar10-global-fpgm-2.0-resnet56 INFO: Acc: 0.9392 => 0.3201
[02/20 22:44:14] cifar10-global-fpgm-2.0-resnet56 INFO: Val Loss: 0.2587 => 2.3332
[02/20 22:44:14] cifar10-global-fpgm-2.0-resnet56 INFO: Finetuning...
[02/20 22:44:48] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 0/100, Acc=0.8561, Val Loss=0.4425, lr=0.0100
[02/20 22:45:22] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 1/100, Acc=0.8901, Val Loss=0.3474, lr=0.0100
[02/20 22:45:56] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 2/100, Acc=0.8949, Val Loss=0.3222, lr=0.0100
[02/20 22:46:30] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 3/100, Acc=0.8796, Val Loss=0.3746, lr=0.0100
[02/20 22:47:04] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 4/100, Acc=0.8852, Val Loss=0.3478, lr=0.0100
[02/20 22:47:38] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 5/100, Acc=0.8762, Val Loss=0.4083, lr=0.0100
[02/20 22:48:12] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 6/100, Acc=0.8921, Val Loss=0.3394, lr=0.0100
[02/20 22:48:46] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 7/100, Acc=0.8734, Val Loss=0.4232, lr=0.0100
[02/20 22:49:20] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 8/100, Acc=0.9035, Val Loss=0.3097, lr=0.0100
[02/20 22:49:55] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 9/100, Acc=0.8818, Val Loss=0.3888, lr=0.0100
[02/20 22:50:29] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 10/100, Acc=0.8875, Val Loss=0.3550, lr=0.0100
[02/20 22:51:03] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 11/100, Acc=0.9024, Val Loss=0.3128, lr=0.0100
[02/20 22:51:37] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 12/100, Acc=0.8916, Val Loss=0.3534, lr=0.0100
[02/20 22:52:11] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 13/100, Acc=0.8927, Val Loss=0.3279, lr=0.0100
[02/20 22:52:45] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 14/100, Acc=0.9030, Val Loss=0.3099, lr=0.0100
[02/20 22:53:18] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 15/100, Acc=0.8990, Val Loss=0.3364, lr=0.0100
[02/20 22:53:51] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 16/100, Acc=0.8956, Val Loss=0.3406, lr=0.0100
[02/20 22:54:24] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 17/100, Acc=0.8972, Val Loss=0.3317, lr=0.0100
[02/20 22:54:58] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 18/100, Acc=0.8972, Val Loss=0.3289, lr=0.0100
[02/20 22:55:31] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 19/100, Acc=0.8922, Val Loss=0.3331, lr=0.0100
[02/20 22:56:04] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 20/100, Acc=0.8923, Val Loss=0.3465, lr=0.0100
[02/20 22:56:38] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 21/100, Acc=0.9020, Val Loss=0.3158, lr=0.0100
[02/20 22:57:11] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 22/100, Acc=0.9016, Val Loss=0.3234, lr=0.0100
[02/20 22:57:44] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 23/100, Acc=0.8905, Val Loss=0.3600, lr=0.0100
[02/20 22:58:18] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 24/100, Acc=0.8996, Val Loss=0.3312, lr=0.0100
[02/20 22:58:51] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 25/100, Acc=0.8957, Val Loss=0.3408, lr=0.0100
[02/20 22:59:24] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 26/100, Acc=0.9024, Val Loss=0.3214, lr=0.0100
[02/20 22:59:58] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 27/100, Acc=0.8885, Val Loss=0.3652, lr=0.0100
[02/20 23:00:32] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 28/100, Acc=0.8973, Val Loss=0.3518, lr=0.0100
[02/20 23:01:05] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 29/100, Acc=0.9020, Val Loss=0.3255, lr=0.0100
[02/20 23:01:39] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 30/100, Acc=0.8887, Val Loss=0.3743, lr=0.0100
[02/20 23:02:13] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 31/100, Acc=0.9033, Val Loss=0.3107, lr=0.0100
[02/20 23:02:46] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 32/100, Acc=0.8991, Val Loss=0.3316, lr=0.0100
[02/20 23:03:19] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 33/100, Acc=0.8973, Val Loss=0.3329, lr=0.0100
[02/20 23:03:53] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 34/100, Acc=0.8996, Val Loss=0.3480, lr=0.0100
[02/20 23:04:26] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 35/100, Acc=0.8861, Val Loss=0.3927, lr=0.0100
[02/20 23:05:00] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 36/100, Acc=0.8932, Val Loss=0.3708, lr=0.0100
[02/20 23:05:34] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 37/100, Acc=0.8768, Val Loss=0.4395, lr=0.0100
[02/20 23:06:08] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 38/100, Acc=0.9017, Val Loss=0.3369, lr=0.0100
[02/20 23:06:43] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 39/100, Acc=0.8985, Val Loss=0.3527, lr=0.0100
[02/20 23:07:23] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 40/100, Acc=0.8894, Val Loss=0.3811, lr=0.0100
[02/20 23:07:57] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 41/100, Acc=0.9023, Val Loss=0.3334, lr=0.0100
[02/20 23:08:31] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 42/100, Acc=0.8924, Val Loss=0.3703, lr=0.0100
[02/20 23:09:04] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 43/100, Acc=0.9001, Val Loss=0.3417, lr=0.0100
[02/20 23:09:38] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 44/100, Acc=0.9055, Val Loss=0.3194, lr=0.0100
[02/20 23:10:11] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 45/100, Acc=0.9013, Val Loss=0.3476, lr=0.0100
[02/20 23:10:45] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 46/100, Acc=0.9037, Val Loss=0.3135, lr=0.0100
[02/20 23:11:18] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 47/100, Acc=0.9025, Val Loss=0.3438, lr=0.0100
[02/20 23:11:52] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 48/100, Acc=0.9015, Val Loss=0.3380, lr=0.0100
[02/20 23:12:25] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 49/100, Acc=0.8990, Val Loss=0.3390, lr=0.0100
[02/20 23:12:59] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 50/100, Acc=0.8952, Val Loss=0.3585, lr=0.0100
[02/20 23:13:32] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 51/100, Acc=0.9007, Val Loss=0.3325, lr=0.0100
[02/20 23:14:06] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 52/100, Acc=0.8906, Val Loss=0.3857, lr=0.0100
[02/20 23:14:40] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 53/100, Acc=0.8960, Val Loss=0.3437, lr=0.0100
[02/20 23:15:14] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 54/100, Acc=0.8941, Val Loss=0.3425, lr=0.0100
[02/20 23:15:47] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 55/100, Acc=0.8978, Val Loss=0.3602, lr=0.0100
[02/20 23:16:21] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 56/100, Acc=0.9013, Val Loss=0.3373, lr=0.0100
[02/20 23:16:55] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 57/100, Acc=0.9072, Val Loss=0.3273, lr=0.0100
[02/20 23:17:29] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 58/100, Acc=0.8891, Val Loss=0.3910, lr=0.0100
[02/20 23:18:02] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 59/100, Acc=0.9106, Val Loss=0.3176, lr=0.0100
[02/20 23:18:36] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 60/100, Acc=0.9259, Val Loss=0.2560, lr=0.0010
[02/20 23:19:10] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 61/100, Acc=0.9288, Val Loss=0.2580, lr=0.0010
[02/20 23:19:43] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 62/100, Acc=0.9289, Val Loss=0.2608, lr=0.0010
[02/20 23:20:17] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 63/100, Acc=0.9302, Val Loss=0.2578, lr=0.0010
[02/20 23:20:50] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 64/100, Acc=0.9299, Val Loss=0.2581, lr=0.0010
[02/20 23:21:24] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 65/100, Acc=0.9306, Val Loss=0.2582, lr=0.0010
[02/20 23:21:58] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 66/100, Acc=0.9305, Val Loss=0.2589, lr=0.0010
[02/20 23:22:31] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 67/100, Acc=0.9302, Val Loss=0.2631, lr=0.0010
[02/20 23:23:05] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 68/100, Acc=0.9307, Val Loss=0.2619, lr=0.0010
[02/20 23:23:39] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 69/100, Acc=0.9326, Val Loss=0.2632, lr=0.0010
[02/20 23:24:12] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 70/100, Acc=0.9310, Val Loss=0.2668, lr=0.0010
[02/20 23:24:46] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 71/100, Acc=0.9322, Val Loss=0.2657, lr=0.0010
[02/20 23:25:20] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 72/100, Acc=0.9330, Val Loss=0.2681, lr=0.0010
[02/20 23:25:53] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 73/100, Acc=0.9323, Val Loss=0.2701, lr=0.0010
[02/20 23:26:26] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 74/100, Acc=0.9319, Val Loss=0.2718, lr=0.0010
[02/20 23:26:59] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 75/100, Acc=0.9321, Val Loss=0.2742, lr=0.0010
[02/20 23:27:33] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 76/100, Acc=0.9318, Val Loss=0.2742, lr=0.0010
[02/20 23:28:07] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 77/100, Acc=0.9311, Val Loss=0.2734, lr=0.0010
[02/20 23:28:46] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 78/100, Acc=0.9322, Val Loss=0.2748, lr=0.0010
[02/20 23:29:25] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 79/100, Acc=0.9307, Val Loss=0.2798, lr=0.0010
[02/20 23:29:59] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 80/100, Acc=0.9339, Val Loss=0.2796, lr=0.0001
[02/20 23:30:32] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 81/100, Acc=0.9325, Val Loss=0.2767, lr=0.0001
[02/20 23:31:05] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 82/100, Acc=0.9326, Val Loss=0.2770, lr=0.0001
[02/20 23:31:39] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 83/100, Acc=0.9331, Val Loss=0.2788, lr=0.0001
[02/20 23:32:12] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 84/100, Acc=0.9332, Val Loss=0.2781, lr=0.0001
[02/20 23:32:45] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 85/100, Acc=0.9329, Val Loss=0.2787, lr=0.0001
[02/20 23:33:19] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 86/100, Acc=0.9332, Val Loss=0.2772, lr=0.0001
[02/20 23:33:52] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 87/100, Acc=0.9319, Val Loss=0.2786, lr=0.0001
[02/20 23:34:26] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 88/100, Acc=0.9328, Val Loss=0.2750, lr=0.0001
[02/20 23:35:00] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 89/100, Acc=0.9339, Val Loss=0.2769, lr=0.0001
[02/20 23:35:34] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 90/100, Acc=0.9314, Val Loss=0.2777, lr=0.0001
[02/20 23:36:07] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 91/100, Acc=0.9335, Val Loss=0.2768, lr=0.0001
[02/20 23:36:41] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 92/100, Acc=0.9328, Val Loss=0.2770, lr=0.0001
[02/20 23:37:14] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 93/100, Acc=0.9324, Val Loss=0.2767, lr=0.0001
[02/20 23:37:48] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 94/100, Acc=0.9331, Val Loss=0.2780, lr=0.0001
[02/20 23:38:21] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 95/100, Acc=0.9340, Val Loss=0.2782, lr=0.0001
[02/20 23:38:54] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 96/100, Acc=0.9327, Val Loss=0.2766, lr=0.0001
[02/20 23:39:27] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 97/100, Acc=0.9329, Val Loss=0.2777, lr=0.0001
[02/20 23:40:00] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 98/100, Acc=0.9339, Val Loss=0.2770, lr=0.0001
[02/20 23:40:33] cifar10-global-fpgm-2.0-resnet56 INFO: Epoch 99/100, Acc=0.9317, Val Loss=0.2790, lr=0.0001
[02/20 23:40:33] cifar10-global-fpgm-2.0-resnet56 INFO: Best Acc=0.9340
[02/20 23:40:33] cifar10-global-fpgm-2.0-resnet56 INFO: Params: 0.40 M
[02/20 23:40:33] cifar10-global-fpgm-2.0-resnet56 INFO: ops: 62.99 M
[02/20 23:40:36] cifar10-global-fpgm-2.0-resnet56 INFO: Acc: 0.9317 Val Loss: 0.2790

