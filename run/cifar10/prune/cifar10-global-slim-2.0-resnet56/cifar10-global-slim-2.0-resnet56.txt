[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: mode: prune
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: model: resnet56
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: verbose: False
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: dataset: cifar10
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: dataroot: data
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: batch_size: 128
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: total_epochs: 100
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: lr: 0.01
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: restore: run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: output_dir: run/cifar10/prune/cifar10-global-slim-2.0-resnet56
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: finetune: True
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: last_epochs: 100
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: reps: 1
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: method: slim
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: speed_up: 2.0
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: reg: 1e-05
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: seed: 1
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: global_pruning: True
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: sl_restore: None
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: iterative_steps: 400
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: logger: <Logger cifar10-global-slim-2.0-resnet56 (DEBUG)>
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: device: cuda
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: num_classes: 10
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: Loading model from run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 00:38:54] cifar10-global-slim-2.0-resnet56 INFO: Regularizing...
[02/21 00:39:29] cifar10-global-slim-2.0-resnet56 INFO: Epoch 0/100, Acc=0.9048, Val Loss=0.3422, lr=0.0100
[02/21 00:40:03] cifar10-global-slim-2.0-resnet56 INFO: Epoch 1/100, Acc=0.9129, Val Loss=0.3065, lr=0.0100
[02/21 00:40:39] cifar10-global-slim-2.0-resnet56 INFO: Epoch 2/100, Acc=0.9126, Val Loss=0.3092, lr=0.0100
[02/21 00:41:14] cifar10-global-slim-2.0-resnet56 INFO: Epoch 3/100, Acc=0.9123, Val Loss=0.3083, lr=0.0100
[02/21 00:41:49] cifar10-global-slim-2.0-resnet56 INFO: Epoch 4/100, Acc=0.9096, Val Loss=0.3242, lr=0.0100
[02/21 00:42:24] cifar10-global-slim-2.0-resnet56 INFO: Epoch 5/100, Acc=0.9151, Val Loss=0.3038, lr=0.0100
[02/21 00:42:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 6/100, Acc=0.9155, Val Loss=0.3136, lr=0.0100
[02/21 00:43:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 7/100, Acc=0.9241, Val Loss=0.2801, lr=0.0100
[02/21 00:44:10] cifar10-global-slim-2.0-resnet56 INFO: Epoch 8/100, Acc=0.9178, Val Loss=0.3120, lr=0.0100
[02/21 00:44:45] cifar10-global-slim-2.0-resnet56 INFO: Epoch 9/100, Acc=0.9146, Val Loss=0.3428, lr=0.0100
[02/21 00:45:20] cifar10-global-slim-2.0-resnet56 INFO: Epoch 10/100, Acc=0.9110, Val Loss=0.3453, lr=0.0100
[02/21 00:45:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 11/100, Acc=0.9214, Val Loss=0.3052, lr=0.0100
[02/21 00:46:30] cifar10-global-slim-2.0-resnet56 INFO: Epoch 12/100, Acc=0.9215, Val Loss=0.3105, lr=0.0100
[02/21 00:47:05] cifar10-global-slim-2.0-resnet56 INFO: Epoch 13/100, Acc=0.9234, Val Loss=0.3057, lr=0.0100
[02/21 00:47:40] cifar10-global-slim-2.0-resnet56 INFO: Epoch 14/100, Acc=0.9237, Val Loss=0.3017, lr=0.0100
[02/21 00:48:15] cifar10-global-slim-2.0-resnet56 INFO: Epoch 15/100, Acc=0.9201, Val Loss=0.3234, lr=0.0100
[02/21 00:48:50] cifar10-global-slim-2.0-resnet56 INFO: Epoch 16/100, Acc=0.9277, Val Loss=0.3000, lr=0.0100
[02/21 00:49:24] cifar10-global-slim-2.0-resnet56 INFO: Epoch 17/100, Acc=0.9264, Val Loss=0.2970, lr=0.0100
[02/21 00:49:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 18/100, Acc=0.9224, Val Loss=0.3260, lr=0.0100
[02/21 00:50:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 19/100, Acc=0.9158, Val Loss=0.3495, lr=0.0100
[02/21 00:51:09] cifar10-global-slim-2.0-resnet56 INFO: Epoch 20/100, Acc=0.9237, Val Loss=0.3149, lr=0.0100
[02/21 00:51:44] cifar10-global-slim-2.0-resnet56 INFO: Epoch 21/100, Acc=0.9254, Val Loss=0.3062, lr=0.0100
[02/21 00:52:19] cifar10-global-slim-2.0-resnet56 INFO: Epoch 22/100, Acc=0.9243, Val Loss=0.3206, lr=0.0100
[02/21 00:52:54] cifar10-global-slim-2.0-resnet56 INFO: Epoch 23/100, Acc=0.9221, Val Loss=0.3576, lr=0.0100
[02/21 00:53:29] cifar10-global-slim-2.0-resnet56 INFO: Epoch 24/100, Acc=0.9265, Val Loss=0.3115, lr=0.0100
[02/21 00:54:04] cifar10-global-slim-2.0-resnet56 INFO: Epoch 25/100, Acc=0.9220, Val Loss=0.3290, lr=0.0100
[02/21 00:54:40] cifar10-global-slim-2.0-resnet56 INFO: Epoch 26/100, Acc=0.9218, Val Loss=0.3218, lr=0.0100
[02/21 00:55:15] cifar10-global-slim-2.0-resnet56 INFO: Epoch 27/100, Acc=0.9232, Val Loss=0.3344, lr=0.0100
[02/21 00:55:50] cifar10-global-slim-2.0-resnet56 INFO: Epoch 28/100, Acc=0.9198, Val Loss=0.3718, lr=0.0100
[02/21 00:56:25] cifar10-global-slim-2.0-resnet56 INFO: Epoch 29/100, Acc=0.9256, Val Loss=0.3340, lr=0.0100
[02/21 00:57:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 30/100, Acc=0.9225, Val Loss=0.3387, lr=0.0100
[02/21 00:57:36] cifar10-global-slim-2.0-resnet56 INFO: Epoch 31/100, Acc=0.9274, Val Loss=0.3251, lr=0.0100
[02/21 00:58:11] cifar10-global-slim-2.0-resnet56 INFO: Epoch 32/100, Acc=0.9251, Val Loss=0.3201, lr=0.0100
[02/21 00:58:46] cifar10-global-slim-2.0-resnet56 INFO: Epoch 33/100, Acc=0.9258, Val Loss=0.3435, lr=0.0100
[02/21 00:59:21] cifar10-global-slim-2.0-resnet56 INFO: Epoch 34/100, Acc=0.9264, Val Loss=0.3211, lr=0.0100
[02/21 00:59:57] cifar10-global-slim-2.0-resnet56 INFO: Epoch 35/100, Acc=0.9253, Val Loss=0.3498, lr=0.0100
[02/21 01:00:32] cifar10-global-slim-2.0-resnet56 INFO: Epoch 36/100, Acc=0.9317, Val Loss=0.3196, lr=0.0100
[02/21 01:01:07] cifar10-global-slim-2.0-resnet56 INFO: Epoch 37/100, Acc=0.9286, Val Loss=0.3221, lr=0.0100
[02/21 01:01:42] cifar10-global-slim-2.0-resnet56 INFO: Epoch 38/100, Acc=0.9284, Val Loss=0.3370, lr=0.0100
[02/21 01:02:17] cifar10-global-slim-2.0-resnet56 INFO: Epoch 39/100, Acc=0.9291, Val Loss=0.3299, lr=0.0100
[02/21 01:02:52] cifar10-global-slim-2.0-resnet56 INFO: Epoch 40/100, Acc=0.9245, Val Loss=0.3467, lr=0.0100
[02/21 01:03:27] cifar10-global-slim-2.0-resnet56 INFO: Epoch 41/100, Acc=0.9305, Val Loss=0.3275, lr=0.0100
[02/21 01:04:02] cifar10-global-slim-2.0-resnet56 INFO: Epoch 42/100, Acc=0.9299, Val Loss=0.3394, lr=0.0100
[02/21 01:04:37] cifar10-global-slim-2.0-resnet56 INFO: Epoch 43/100, Acc=0.9329, Val Loss=0.3332, lr=0.0100
[02/21 01:05:13] cifar10-global-slim-2.0-resnet56 INFO: Epoch 44/100, Acc=0.9316, Val Loss=0.3257, lr=0.0100
[02/21 01:05:48] cifar10-global-slim-2.0-resnet56 INFO: Epoch 45/100, Acc=0.9320, Val Loss=0.3154, lr=0.0100
[02/21 01:06:23] cifar10-global-slim-2.0-resnet56 INFO: Epoch 46/100, Acc=0.9319, Val Loss=0.3291, lr=0.0100
[02/21 01:06:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 47/100, Acc=0.9240, Val Loss=0.3435, lr=0.0100
[02/21 01:07:36] cifar10-global-slim-2.0-resnet56 INFO: Epoch 48/100, Acc=0.9306, Val Loss=0.3467, lr=0.0100
[02/21 01:08:14] cifar10-global-slim-2.0-resnet56 INFO: Epoch 49/100, Acc=0.9300, Val Loss=0.3305, lr=0.0100
[02/21 01:08:49] cifar10-global-slim-2.0-resnet56 INFO: Epoch 50/100, Acc=0.9285, Val Loss=0.3482, lr=0.0100
[02/21 01:09:25] cifar10-global-slim-2.0-resnet56 INFO: Epoch 51/100, Acc=0.9291, Val Loss=0.3495, lr=0.0100
[02/21 01:09:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 52/100, Acc=0.9283, Val Loss=0.3311, lr=0.0100
[02/21 01:10:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 53/100, Acc=0.9303, Val Loss=0.3333, lr=0.0100
[02/21 01:11:15] cifar10-global-slim-2.0-resnet56 INFO: Epoch 54/100, Acc=0.9300, Val Loss=0.3407, lr=0.0100
[02/21 01:11:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 55/100, Acc=0.9297, Val Loss=0.3534, lr=0.0100
[02/21 01:12:32] cifar10-global-slim-2.0-resnet56 INFO: Epoch 56/100, Acc=0.9327, Val Loss=0.3385, lr=0.0100
[02/21 01:13:07] cifar10-global-slim-2.0-resnet56 INFO: Epoch 57/100, Acc=0.9282, Val Loss=0.3603, lr=0.0100
[02/21 01:13:42] cifar10-global-slim-2.0-resnet56 INFO: Epoch 58/100, Acc=0.9291, Val Loss=0.3438, lr=0.0100
[02/21 01:14:17] cifar10-global-slim-2.0-resnet56 INFO: Epoch 59/100, Acc=0.9284, Val Loss=0.3639, lr=0.0100
[02/21 01:14:52] cifar10-global-slim-2.0-resnet56 INFO: Epoch 60/100, Acc=0.9338, Val Loss=0.3292, lr=0.0010
[02/21 01:15:27] cifar10-global-slim-2.0-resnet56 INFO: Epoch 61/100, Acc=0.9355, Val Loss=0.3222, lr=0.0010
[02/21 01:16:03] cifar10-global-slim-2.0-resnet56 INFO: Epoch 62/100, Acc=0.9354, Val Loss=0.3214, lr=0.0010
[02/21 01:16:38] cifar10-global-slim-2.0-resnet56 INFO: Epoch 63/100, Acc=0.9379, Val Loss=0.3217, lr=0.0010
[02/21 01:17:15] cifar10-global-slim-2.0-resnet56 INFO: Epoch 64/100, Acc=0.9376, Val Loss=0.3216, lr=0.0010
[02/21 01:17:52] cifar10-global-slim-2.0-resnet56 INFO: Epoch 65/100, Acc=0.9382, Val Loss=0.3210, lr=0.0010
[02/21 01:18:27] cifar10-global-slim-2.0-resnet56 INFO: Epoch 66/100, Acc=0.9378, Val Loss=0.3220, lr=0.0010
[02/21 01:19:02] cifar10-global-slim-2.0-resnet56 INFO: Epoch 67/100, Acc=0.9390, Val Loss=0.3154, lr=0.0010
[02/21 01:19:37] cifar10-global-slim-2.0-resnet56 INFO: Epoch 68/100, Acc=0.9394, Val Loss=0.3197, lr=0.0010
[02/21 01:20:13] cifar10-global-slim-2.0-resnet56 INFO: Epoch 69/100, Acc=0.9383, Val Loss=0.3177, lr=0.0010
[02/21 01:20:49] cifar10-global-slim-2.0-resnet56 INFO: Epoch 70/100, Acc=0.9384, Val Loss=0.3205, lr=0.0010
[02/21 01:21:25] cifar10-global-slim-2.0-resnet56 INFO: Epoch 71/100, Acc=0.9395, Val Loss=0.3209, lr=0.0010
[02/21 01:22:00] cifar10-global-slim-2.0-resnet56 INFO: Epoch 72/100, Acc=0.9408, Val Loss=0.3180, lr=0.0010
[02/21 01:22:35] cifar10-global-slim-2.0-resnet56 INFO: Epoch 73/100, Acc=0.9395, Val Loss=0.3224, lr=0.0010
[02/21 01:23:11] cifar10-global-slim-2.0-resnet56 INFO: Epoch 74/100, Acc=0.9385, Val Loss=0.3196, lr=0.0010
[02/21 01:23:46] cifar10-global-slim-2.0-resnet56 INFO: Epoch 75/100, Acc=0.9394, Val Loss=0.3227, lr=0.0010
[02/21 01:24:21] cifar10-global-slim-2.0-resnet56 INFO: Epoch 76/100, Acc=0.9389, Val Loss=0.3181, lr=0.0010
[02/21 01:24:56] cifar10-global-slim-2.0-resnet56 INFO: Epoch 77/100, Acc=0.9396, Val Loss=0.3218, lr=0.0010
[02/21 01:25:31] cifar10-global-slim-2.0-resnet56 INFO: Epoch 78/100, Acc=0.9398, Val Loss=0.3184, lr=0.0010
[02/21 01:26:07] cifar10-global-slim-2.0-resnet56 INFO: Epoch 79/100, Acc=0.9404, Val Loss=0.3213, lr=0.0010
[02/21 01:26:42] cifar10-global-slim-2.0-resnet56 INFO: Epoch 80/100, Acc=0.9395, Val Loss=0.3226, lr=0.0001
[02/21 01:27:18] cifar10-global-slim-2.0-resnet56 INFO: Epoch 81/100, Acc=0.9392, Val Loss=0.3245, lr=0.0001
[02/21 01:27:53] cifar10-global-slim-2.0-resnet56 INFO: Epoch 82/100, Acc=0.9384, Val Loss=0.3224, lr=0.0001
[02/21 01:28:28] cifar10-global-slim-2.0-resnet56 INFO: Epoch 83/100, Acc=0.9393, Val Loss=0.3211, lr=0.0001
[02/21 01:29:03] cifar10-global-slim-2.0-resnet56 INFO: Epoch 84/100, Acc=0.9390, Val Loss=0.3224, lr=0.0001
[02/21 01:29:39] cifar10-global-slim-2.0-resnet56 INFO: Epoch 85/100, Acc=0.9395, Val Loss=0.3237, lr=0.0001
[02/21 01:30:14] cifar10-global-slim-2.0-resnet56 INFO: Epoch 86/100, Acc=0.9391, Val Loss=0.3231, lr=0.0001
[02/21 01:30:50] cifar10-global-slim-2.0-resnet56 INFO: Epoch 87/100, Acc=0.9394, Val Loss=0.3232, lr=0.0001
[02/21 01:31:25] cifar10-global-slim-2.0-resnet56 INFO: Epoch 88/100, Acc=0.9394, Val Loss=0.3236, lr=0.0001
[02/21 01:32:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 89/100, Acc=0.9394, Val Loss=0.3233, lr=0.0001
[02/21 01:32:37] cifar10-global-slim-2.0-resnet56 INFO: Epoch 90/100, Acc=0.9392, Val Loss=0.3254, lr=0.0001
[02/21 01:33:12] cifar10-global-slim-2.0-resnet56 INFO: Epoch 91/100, Acc=0.9394, Val Loss=0.3254, lr=0.0001
[02/21 01:33:47] cifar10-global-slim-2.0-resnet56 INFO: Epoch 92/100, Acc=0.9392, Val Loss=0.3206, lr=0.0001
[02/21 01:34:22] cifar10-global-slim-2.0-resnet56 INFO: Epoch 93/100, Acc=0.9397, Val Loss=0.3188, lr=0.0001
[02/21 01:34:58] cifar10-global-slim-2.0-resnet56 INFO: Epoch 94/100, Acc=0.9401, Val Loss=0.3220, lr=0.0001
[02/21 01:35:33] cifar10-global-slim-2.0-resnet56 INFO: Epoch 95/100, Acc=0.9393, Val Loss=0.3226, lr=0.0001
[02/21 01:36:08] cifar10-global-slim-2.0-resnet56 INFO: Epoch 96/100, Acc=0.9404, Val Loss=0.3201, lr=0.0001
[02/21 01:36:44] cifar10-global-slim-2.0-resnet56 INFO: Epoch 97/100, Acc=0.9392, Val Loss=0.3229, lr=0.0001
[02/21 01:37:19] cifar10-global-slim-2.0-resnet56 INFO: Epoch 98/100, Acc=0.9394, Val Loss=0.3236, lr=0.0001
[02/21 01:37:54] cifar10-global-slim-2.0-resnet56 INFO: Epoch 99/100, Acc=0.9393, Val Loss=0.3240, lr=0.0001
[02/21 01:37:54] cifar10-global-slim-2.0-resnet56 INFO: Best Acc=0.9408
[02/21 01:37:54] cifar10-global-slim-2.0-resnet56 INFO: Loading the sparse model from run/cifar10/prune/cifar10-global-slim-2.0-resnet56/reg_cifar10_resnet56_slim_1e-05.pth...
[02/21 01:37:57] cifar10-global-slim-2.0-resnet56 INFO: Pruning...
[02/21 01:38:08] cifar10-global-slim-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(10, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(10, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(10, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(10, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(10, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(13, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(10, 22, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(22, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(10, 28, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(28, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(26, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(28, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(27, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(28, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(30, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(28, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(29, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(28, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(19, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(28, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(28, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(28, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(28, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(62, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(28, 50, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(50, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(57, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(50, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(50, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(57, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(50, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(50, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(54, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(50, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(49, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(50, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(51, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=50, out_features=10, bias=True)
)
[02/21 01:38:11] cifar10-global-slim-2.0-resnet56 INFO: Params: 0.86 M => 0.54 M (62.77%)
[02/21 01:38:11] cifar10-global-slim-2.0-resnet56 INFO: FLOPs: 127.12 M => 63.21 M (49.73%, 2.01X )
[02/21 01:38:11] cifar10-global-slim-2.0-resnet56 INFO: Acc: 0.9408 => 0.1000
[02/21 01:38:11] cifar10-global-slim-2.0-resnet56 INFO: Val Loss: 0.3180 => 2.8136
[02/21 01:38:11] cifar10-global-slim-2.0-resnet56 INFO: Finetuning...
[02/21 01:38:44] cifar10-global-slim-2.0-resnet56 INFO: Epoch 0/100, Acc=0.8690, Val Loss=0.4178, lr=0.0100
[02/21 01:39:17] cifar10-global-slim-2.0-resnet56 INFO: Epoch 1/100, Acc=0.8869, Val Loss=0.3776, lr=0.0100
[02/21 01:39:50] cifar10-global-slim-2.0-resnet56 INFO: Epoch 2/100, Acc=0.8898, Val Loss=0.3690, lr=0.0100
[02/21 01:40:23] cifar10-global-slim-2.0-resnet56 INFO: Epoch 3/100, Acc=0.8981, Val Loss=0.3646, lr=0.0100
[02/21 01:40:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 4/100, Acc=0.8952, Val Loss=0.3674, lr=0.0100
[02/21 01:41:28] cifar10-global-slim-2.0-resnet56 INFO: Epoch 5/100, Acc=0.8990, Val Loss=0.3427, lr=0.0100
[02/21 01:42:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 6/100, Acc=0.8985, Val Loss=0.3594, lr=0.0100
[02/21 01:42:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 7/100, Acc=0.9013, Val Loss=0.3530, lr=0.0100
[02/21 01:43:09] cifar10-global-slim-2.0-resnet56 INFO: Epoch 8/100, Acc=0.8870, Val Loss=0.4108, lr=0.0100
[02/21 01:43:48] cifar10-global-slim-2.0-resnet56 INFO: Epoch 9/100, Acc=0.8995, Val Loss=0.3358, lr=0.0100
[02/21 01:44:22] cifar10-global-slim-2.0-resnet56 INFO: Epoch 10/100, Acc=0.8954, Val Loss=0.3681, lr=0.0100
[02/21 01:44:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 11/100, Acc=0.8915, Val Loss=0.3971, lr=0.0100
[02/21 01:45:28] cifar10-global-slim-2.0-resnet56 INFO: Epoch 12/100, Acc=0.8894, Val Loss=0.4130, lr=0.0100
[02/21 01:46:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 13/100, Acc=0.9045, Val Loss=0.3287, lr=0.0100
[02/21 01:46:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 14/100, Acc=0.8993, Val Loss=0.3581, lr=0.0100
[02/21 01:47:07] cifar10-global-slim-2.0-resnet56 INFO: Epoch 15/100, Acc=0.8898, Val Loss=0.4108, lr=0.0100
[02/21 01:47:40] cifar10-global-slim-2.0-resnet56 INFO: Epoch 16/100, Acc=0.8957, Val Loss=0.3658, lr=0.0100
[02/21 01:48:12] cifar10-global-slim-2.0-resnet56 INFO: Epoch 17/100, Acc=0.9080, Val Loss=0.3387, lr=0.0100
[02/21 01:48:45] cifar10-global-slim-2.0-resnet56 INFO: Epoch 18/100, Acc=0.8999, Val Loss=0.3688, lr=0.0100
[02/21 01:49:18] cifar10-global-slim-2.0-resnet56 INFO: Epoch 19/100, Acc=0.8902, Val Loss=0.3859, lr=0.0100
[02/21 01:49:51] cifar10-global-slim-2.0-resnet56 INFO: Epoch 20/100, Acc=0.8971, Val Loss=0.3757, lr=0.0100
[02/21 01:50:24] cifar10-global-slim-2.0-resnet56 INFO: Epoch 21/100, Acc=0.8998, Val Loss=0.3509, lr=0.0100
[02/21 01:50:57] cifar10-global-slim-2.0-resnet56 INFO: Epoch 22/100, Acc=0.9092, Val Loss=0.3096, lr=0.0100
[02/21 01:51:31] cifar10-global-slim-2.0-resnet56 INFO: Epoch 23/100, Acc=0.9020, Val Loss=0.3577, lr=0.0100
[02/21 01:52:04] cifar10-global-slim-2.0-resnet56 INFO: Epoch 24/100, Acc=0.8966, Val Loss=0.3679, lr=0.0100
[02/21 01:52:37] cifar10-global-slim-2.0-resnet56 INFO: Epoch 25/100, Acc=0.9052, Val Loss=0.3188, lr=0.0100
[02/21 01:53:10] cifar10-global-slim-2.0-resnet56 INFO: Epoch 26/100, Acc=0.9007, Val Loss=0.3712, lr=0.0100
[02/21 01:53:45] cifar10-global-slim-2.0-resnet56 INFO: Epoch 27/100, Acc=0.9067, Val Loss=0.3471, lr=0.0100
[02/21 01:54:19] cifar10-global-slim-2.0-resnet56 INFO: Epoch 28/100, Acc=0.9027, Val Loss=0.3409, lr=0.0100
[02/21 01:54:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 29/100, Acc=0.9011, Val Loss=0.3630, lr=0.0100
[02/21 01:55:28] cifar10-global-slim-2.0-resnet56 INFO: Epoch 30/100, Acc=0.8959, Val Loss=0.3746, lr=0.0100
[02/21 01:56:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 31/100, Acc=0.9011, Val Loss=0.3405, lr=0.0100
[02/21 01:56:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 32/100, Acc=0.8851, Val Loss=0.4026, lr=0.0100
[02/21 01:57:07] cifar10-global-slim-2.0-resnet56 INFO: Epoch 33/100, Acc=0.9060, Val Loss=0.3301, lr=0.0100
[02/21 01:57:43] cifar10-global-slim-2.0-resnet56 INFO: Epoch 34/100, Acc=0.8991, Val Loss=0.3603, lr=0.0100
[02/21 01:58:16] cifar10-global-slim-2.0-resnet56 INFO: Epoch 35/100, Acc=0.9093, Val Loss=0.3189, lr=0.0100
[02/21 01:58:49] cifar10-global-slim-2.0-resnet56 INFO: Epoch 36/100, Acc=0.8973, Val Loss=0.3549, lr=0.0100
[02/21 01:59:22] cifar10-global-slim-2.0-resnet56 INFO: Epoch 37/100, Acc=0.8900, Val Loss=0.3840, lr=0.0100
[02/21 01:59:54] cifar10-global-slim-2.0-resnet56 INFO: Epoch 38/100, Acc=0.8921, Val Loss=0.3907, lr=0.0100
[02/21 02:00:27] cifar10-global-slim-2.0-resnet56 INFO: Epoch 39/100, Acc=0.9026, Val Loss=0.3683, lr=0.0100
[02/21 02:01:00] cifar10-global-slim-2.0-resnet56 INFO: Epoch 40/100, Acc=0.9065, Val Loss=0.3311, lr=0.0100
[02/21 02:01:33] cifar10-global-slim-2.0-resnet56 INFO: Epoch 41/100, Acc=0.8895, Val Loss=0.3985, lr=0.0100
[02/21 02:02:06] cifar10-global-slim-2.0-resnet56 INFO: Epoch 42/100, Acc=0.8943, Val Loss=0.3894, lr=0.0100
[02/21 02:02:39] cifar10-global-slim-2.0-resnet56 INFO: Epoch 43/100, Acc=0.8957, Val Loss=0.3529, lr=0.0100
[02/21 02:03:12] cifar10-global-slim-2.0-resnet56 INFO: Epoch 44/100, Acc=0.9036, Val Loss=0.3309, lr=0.0100
[02/21 02:03:45] cifar10-global-slim-2.0-resnet56 INFO: Epoch 45/100, Acc=0.9017, Val Loss=0.3568, lr=0.0100
[02/21 02:04:18] cifar10-global-slim-2.0-resnet56 INFO: Epoch 46/100, Acc=0.8787, Val Loss=0.4523, lr=0.0100
[02/21 02:04:51] cifar10-global-slim-2.0-resnet56 INFO: Epoch 47/100, Acc=0.8808, Val Loss=0.4552, lr=0.0100
[02/21 02:05:25] cifar10-global-slim-2.0-resnet56 INFO: Epoch 48/100, Acc=0.9093, Val Loss=0.3157, lr=0.0100
[02/21 02:05:57] cifar10-global-slim-2.0-resnet56 INFO: Epoch 49/100, Acc=0.9056, Val Loss=0.3380, lr=0.0100
[02/21 02:06:31] cifar10-global-slim-2.0-resnet56 INFO: Epoch 50/100, Acc=0.8927, Val Loss=0.3769, lr=0.0100
[02/21 02:07:04] cifar10-global-slim-2.0-resnet56 INFO: Epoch 51/100, Acc=0.8970, Val Loss=0.3619, lr=0.0100
[02/21 02:07:38] cifar10-global-slim-2.0-resnet56 INFO: Epoch 52/100, Acc=0.8896, Val Loss=0.3977, lr=0.0100
[02/21 02:08:12] cifar10-global-slim-2.0-resnet56 INFO: Epoch 53/100, Acc=0.9020, Val Loss=0.3508, lr=0.0100
[02/21 02:08:45] cifar10-global-slim-2.0-resnet56 INFO: Epoch 54/100, Acc=0.9017, Val Loss=0.3543, lr=0.0100
[02/21 02:09:18] cifar10-global-slim-2.0-resnet56 INFO: Epoch 55/100, Acc=0.8985, Val Loss=0.3652, lr=0.0100
[02/21 02:09:51] cifar10-global-slim-2.0-resnet56 INFO: Epoch 56/100, Acc=0.9005, Val Loss=0.3599, lr=0.0100
[02/21 02:10:24] cifar10-global-slim-2.0-resnet56 INFO: Epoch 57/100, Acc=0.8943, Val Loss=0.3754, lr=0.0100
[02/21 02:10:57] cifar10-global-slim-2.0-resnet56 INFO: Epoch 58/100, Acc=0.9000, Val Loss=0.3499, lr=0.0100
[02/21 02:11:31] cifar10-global-slim-2.0-resnet56 INFO: Epoch 59/100, Acc=0.8996, Val Loss=0.3577, lr=0.0100
[02/21 02:12:04] cifar10-global-slim-2.0-resnet56 INFO: Epoch 60/100, Acc=0.9264, Val Loss=0.2659, lr=0.0010
[02/21 02:12:38] cifar10-global-slim-2.0-resnet56 INFO: Epoch 61/100, Acc=0.9300, Val Loss=0.2595, lr=0.0010
[02/21 02:13:11] cifar10-global-slim-2.0-resnet56 INFO: Epoch 62/100, Acc=0.9320, Val Loss=0.2672, lr=0.0010
[02/21 02:13:44] cifar10-global-slim-2.0-resnet56 INFO: Epoch 63/100, Acc=0.9325, Val Loss=0.2623, lr=0.0010
[02/21 02:14:17] cifar10-global-slim-2.0-resnet56 INFO: Epoch 64/100, Acc=0.9323, Val Loss=0.2638, lr=0.0010
[02/21 02:14:50] cifar10-global-slim-2.0-resnet56 INFO: Epoch 65/100, Acc=0.9329, Val Loss=0.2640, lr=0.0010
[02/21 02:15:23] cifar10-global-slim-2.0-resnet56 INFO: Epoch 66/100, Acc=0.9320, Val Loss=0.2682, lr=0.0010
[02/21 02:15:56] cifar10-global-slim-2.0-resnet56 INFO: Epoch 67/100, Acc=0.9317, Val Loss=0.2656, lr=0.0010
[02/21 02:16:29] cifar10-global-slim-2.0-resnet56 INFO: Epoch 68/100, Acc=0.9325, Val Loss=0.2660, lr=0.0010
[02/21 02:17:02] cifar10-global-slim-2.0-resnet56 INFO: Epoch 69/100, Acc=0.9330, Val Loss=0.2701, lr=0.0010
[02/21 02:17:35] cifar10-global-slim-2.0-resnet56 INFO: Epoch 70/100, Acc=0.9330, Val Loss=0.2682, lr=0.0010
[02/21 02:18:08] cifar10-global-slim-2.0-resnet56 INFO: Epoch 71/100, Acc=0.9332, Val Loss=0.2663, lr=0.0010
[02/21 02:18:41] cifar10-global-slim-2.0-resnet56 INFO: Epoch 72/100, Acc=0.9330, Val Loss=0.2688, lr=0.0010
[02/21 02:19:14] cifar10-global-slim-2.0-resnet56 INFO: Epoch 73/100, Acc=0.9334, Val Loss=0.2705, lr=0.0010
[02/21 02:19:47] cifar10-global-slim-2.0-resnet56 INFO: Epoch 74/100, Acc=0.9338, Val Loss=0.2712, lr=0.0010
[02/21 02:20:20] cifar10-global-slim-2.0-resnet56 INFO: Epoch 75/100, Acc=0.9347, Val Loss=0.2710, lr=0.0010
[02/21 02:20:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 76/100, Acc=0.9344, Val Loss=0.2719, lr=0.0010
[02/21 02:21:38] cifar10-global-slim-2.0-resnet56 INFO: Epoch 77/100, Acc=0.9344, Val Loss=0.2735, lr=0.0010
[02/21 02:22:18] cifar10-global-slim-2.0-resnet56 INFO: Epoch 78/100, Acc=0.9322, Val Loss=0.2766, lr=0.0010
[02/21 02:22:58] cifar10-global-slim-2.0-resnet56 INFO: Epoch 79/100, Acc=0.9342, Val Loss=0.2756, lr=0.0010
[02/21 02:23:31] cifar10-global-slim-2.0-resnet56 INFO: Epoch 80/100, Acc=0.9340, Val Loss=0.2740, lr=0.0001
[02/21 02:24:04] cifar10-global-slim-2.0-resnet56 INFO: Epoch 81/100, Acc=0.9346, Val Loss=0.2738, lr=0.0001
[02/21 02:24:37] cifar10-global-slim-2.0-resnet56 INFO: Epoch 82/100, Acc=0.9338, Val Loss=0.2753, lr=0.0001
[02/21 02:25:10] cifar10-global-slim-2.0-resnet56 INFO: Epoch 83/100, Acc=0.9347, Val Loss=0.2742, lr=0.0001
[02/21 02:25:43] cifar10-global-slim-2.0-resnet56 INFO: Epoch 84/100, Acc=0.9341, Val Loss=0.2750, lr=0.0001
[02/21 02:26:16] cifar10-global-slim-2.0-resnet56 INFO: Epoch 85/100, Acc=0.9341, Val Loss=0.2740, lr=0.0001
[02/21 02:26:49] cifar10-global-slim-2.0-resnet56 INFO: Epoch 86/100, Acc=0.9345, Val Loss=0.2742, lr=0.0001
[02/21 02:27:22] cifar10-global-slim-2.0-resnet56 INFO: Epoch 87/100, Acc=0.9348, Val Loss=0.2716, lr=0.0001
[02/21 02:27:55] cifar10-global-slim-2.0-resnet56 INFO: Epoch 88/100, Acc=0.9348, Val Loss=0.2717, lr=0.0001
[02/21 02:28:28] cifar10-global-slim-2.0-resnet56 INFO: Epoch 89/100, Acc=0.9349, Val Loss=0.2748, lr=0.0001
[02/21 02:29:01] cifar10-global-slim-2.0-resnet56 INFO: Epoch 90/100, Acc=0.9348, Val Loss=0.2731, lr=0.0001
[02/21 02:29:34] cifar10-global-slim-2.0-resnet56 INFO: Epoch 91/100, Acc=0.9351, Val Loss=0.2733, lr=0.0001
[02/21 02:30:08] cifar10-global-slim-2.0-resnet56 INFO: Epoch 92/100, Acc=0.9349, Val Loss=0.2719, lr=0.0001
[02/21 02:30:41] cifar10-global-slim-2.0-resnet56 INFO: Epoch 93/100, Acc=0.9346, Val Loss=0.2732, lr=0.0001
[02/21 02:31:14] cifar10-global-slim-2.0-resnet56 INFO: Epoch 94/100, Acc=0.9349, Val Loss=0.2757, lr=0.0001
[02/21 02:31:47] cifar10-global-slim-2.0-resnet56 INFO: Epoch 95/100, Acc=0.9345, Val Loss=0.2743, lr=0.0001
[02/21 02:32:20] cifar10-global-slim-2.0-resnet56 INFO: Epoch 96/100, Acc=0.9341, Val Loss=0.2732, lr=0.0001
[02/21 02:32:53] cifar10-global-slim-2.0-resnet56 INFO: Epoch 97/100, Acc=0.9348, Val Loss=0.2742, lr=0.0001
[02/21 02:33:26] cifar10-global-slim-2.0-resnet56 INFO: Epoch 98/100, Acc=0.9345, Val Loss=0.2721, lr=0.0001
[02/21 02:33:59] cifar10-global-slim-2.0-resnet56 INFO: Epoch 99/100, Acc=0.9345, Val Loss=0.2757, lr=0.0001
[02/21 02:33:59] cifar10-global-slim-2.0-resnet56 INFO: Best Acc=0.9351
[02/21 02:33:59] cifar10-global-slim-2.0-resnet56 INFO: Params: 0.54 M
[02/21 02:33:59] cifar10-global-slim-2.0-resnet56 INFO: ops: 63.21 M
[02/21 02:34:02] cifar10-global-slim-2.0-resnet56 INFO: Acc: 0.9345 Val Loss: 0.2757

