[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: mode: prune
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: model: resnet56
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: verbose: False
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: dataset: cifar10
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: dataroot: data
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: batch_size: 128
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: total_epochs: 100
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: lr: 0.01
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: restore: run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: output_dir: run/cifar10/prune/cifar10-global-proj-3.0-resnet56
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: finetune: True
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: last_epochs: 100
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: reps: 1
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: method: proj
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: speed_up: 3.0
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: reg: 1e-05
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: seed: 1
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: global_pruning: True
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: sl_restore: None
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: iterative_steps: 400
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: logger: <Logger cifar10-global-proj-3.0-resnet56 (DEBUG)>
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: device: cuda
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: num_classes: 10
[02/21 08:53:51] cifar10-global-proj-3.0-resnet56 INFO: Loading model from run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 08:53:55] cifar10-global-proj-3.0-resnet56 INFO: Pruning...
[02/21 08:56:56] cifar10-global-proj-3.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(8, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(8, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(8, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(6, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(8, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(8, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(8, 19, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(19, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(8, 28, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(28, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(20, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(28, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(15, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(28, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(28, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(28, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(28, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(6, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(28, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(60, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(28, 56, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(56, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(51, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(56, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(40, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(56, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(41, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(56, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(44, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(56, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(35, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(56, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(25, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(56, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(56, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(30, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=56, out_features=10, bias=True)
)
[02/21 08:56:59] cifar10-global-proj-3.0-resnet56 INFO: Params: 0.86 M => 0.39 M (45.44%)
[02/21 08:56:59] cifar10-global-proj-3.0-resnet56 INFO: FLOPs: 127.12 M => 41.96 M (33.01%, 3.03X )
[02/21 08:56:59] cifar10-global-proj-3.0-resnet56 INFO: Acc: 0.9392 => 0.1053
[02/21 08:56:59] cifar10-global-proj-3.0-resnet56 INFO: Val Loss: 0.2587 => 8.3454
[02/21 08:56:59] cifar10-global-proj-3.0-resnet56 INFO: Finetuning...
[02/21 08:57:32] cifar10-global-proj-3.0-resnet56 INFO: Epoch 0/100, Acc=0.8381, Val Loss=0.5072, lr=0.0100
[02/21 08:58:03] cifar10-global-proj-3.0-resnet56 INFO: Epoch 1/100, Acc=0.8699, Val Loss=0.4013, lr=0.0100
[02/21 08:58:36] cifar10-global-proj-3.0-resnet56 INFO: Epoch 2/100, Acc=0.8818, Val Loss=0.3703, lr=0.0100
[02/21 08:59:08] cifar10-global-proj-3.0-resnet56 INFO: Epoch 3/100, Acc=0.8774, Val Loss=0.3862, lr=0.0100
[02/21 08:59:39] cifar10-global-proj-3.0-resnet56 INFO: Epoch 4/100, Acc=0.8731, Val Loss=0.3941, lr=0.0100
[02/21 09:00:11] cifar10-global-proj-3.0-resnet56 INFO: Epoch 5/100, Acc=0.8748, Val Loss=0.4117, lr=0.0100
[02/21 09:00:43] cifar10-global-proj-3.0-resnet56 INFO: Epoch 6/100, Acc=0.8888, Val Loss=0.3471, lr=0.0100
[02/21 09:01:15] cifar10-global-proj-3.0-resnet56 INFO: Epoch 7/100, Acc=0.8636, Val Loss=0.4493, lr=0.0100
[02/21 09:01:47] cifar10-global-proj-3.0-resnet56 INFO: Epoch 8/100, Acc=0.8913, Val Loss=0.3403, lr=0.0100
[02/21 09:02:20] cifar10-global-proj-3.0-resnet56 INFO: Epoch 9/100, Acc=0.8804, Val Loss=0.3753, lr=0.0100
[02/21 09:02:52] cifar10-global-proj-3.0-resnet56 INFO: Epoch 10/100, Acc=0.8676, Val Loss=0.4370, lr=0.0100
[02/21 09:03:24] cifar10-global-proj-3.0-resnet56 INFO: Epoch 11/100, Acc=0.8797, Val Loss=0.3846, lr=0.0100
[02/21 09:03:57] cifar10-global-proj-3.0-resnet56 INFO: Epoch 12/100, Acc=0.8849, Val Loss=0.3535, lr=0.0100
[02/21 09:04:30] cifar10-global-proj-3.0-resnet56 INFO: Epoch 13/100, Acc=0.8827, Val Loss=0.3759, lr=0.0100
[02/21 09:05:03] cifar10-global-proj-3.0-resnet56 INFO: Epoch 14/100, Acc=0.8834, Val Loss=0.3674, lr=0.0100
[02/21 09:05:36] cifar10-global-proj-3.0-resnet56 INFO: Epoch 15/100, Acc=0.8980, Val Loss=0.3404, lr=0.0100
[02/21 09:06:09] cifar10-global-proj-3.0-resnet56 INFO: Epoch 16/100, Acc=0.8803, Val Loss=0.3680, lr=0.0100
[02/21 09:06:41] cifar10-global-proj-3.0-resnet56 INFO: Epoch 17/100, Acc=0.9006, Val Loss=0.3108, lr=0.0100
[02/21 09:07:13] cifar10-global-proj-3.0-resnet56 INFO: Epoch 18/100, Acc=0.8881, Val Loss=0.3628, lr=0.0100
[02/21 09:07:45] cifar10-global-proj-3.0-resnet56 INFO: Epoch 19/100, Acc=0.8907, Val Loss=0.3606, lr=0.0100
[02/21 09:08:17] cifar10-global-proj-3.0-resnet56 INFO: Epoch 20/100, Acc=0.8971, Val Loss=0.3395, lr=0.0100
[02/21 09:08:49] cifar10-global-proj-3.0-resnet56 INFO: Epoch 21/100, Acc=0.8941, Val Loss=0.3494, lr=0.0100
[02/21 09:09:22] cifar10-global-proj-3.0-resnet56 INFO: Epoch 22/100, Acc=0.8872, Val Loss=0.3769, lr=0.0100
[02/21 09:09:54] cifar10-global-proj-3.0-resnet56 INFO: Epoch 23/100, Acc=0.8948, Val Loss=0.3451, lr=0.0100
[02/21 09:10:26] cifar10-global-proj-3.0-resnet56 INFO: Epoch 24/100, Acc=0.8901, Val Loss=0.3674, lr=0.0100
[02/21 09:10:58] cifar10-global-proj-3.0-resnet56 INFO: Epoch 25/100, Acc=0.8943, Val Loss=0.3579, lr=0.0100
[02/21 09:11:29] cifar10-global-proj-3.0-resnet56 INFO: Epoch 26/100, Acc=0.8888, Val Loss=0.3480, lr=0.0100
[02/21 09:12:01] cifar10-global-proj-3.0-resnet56 INFO: Epoch 27/100, Acc=0.8897, Val Loss=0.3687, lr=0.0100
[02/21 09:12:33] cifar10-global-proj-3.0-resnet56 INFO: Epoch 28/100, Acc=0.8935, Val Loss=0.3415, lr=0.0100
[02/21 09:13:05] cifar10-global-proj-3.0-resnet56 INFO: Epoch 29/100, Acc=0.8972, Val Loss=0.3348, lr=0.0100
[02/21 09:13:37] cifar10-global-proj-3.0-resnet56 INFO: Epoch 30/100, Acc=0.8925, Val Loss=0.3683, lr=0.0100
[02/21 09:14:10] cifar10-global-proj-3.0-resnet56 INFO: Epoch 31/100, Acc=0.8972, Val Loss=0.3481, lr=0.0100
[02/21 09:14:41] cifar10-global-proj-3.0-resnet56 INFO: Epoch 32/100, Acc=0.9017, Val Loss=0.3192, lr=0.0100
[02/21 09:15:14] cifar10-global-proj-3.0-resnet56 INFO: Epoch 33/100, Acc=0.8914, Val Loss=0.3633, lr=0.0100
[02/21 09:15:46] cifar10-global-proj-3.0-resnet56 INFO: Epoch 34/100, Acc=0.8804, Val Loss=0.4057, lr=0.0100
[02/21 09:16:18] cifar10-global-proj-3.0-resnet56 INFO: Epoch 35/100, Acc=0.8879, Val Loss=0.3804, lr=0.0100
[02/21 09:16:50] cifar10-global-proj-3.0-resnet56 INFO: Epoch 36/100, Acc=0.8956, Val Loss=0.3573, lr=0.0100
[02/21 09:17:22] cifar10-global-proj-3.0-resnet56 INFO: Epoch 37/100, Acc=0.8984, Val Loss=0.3484, lr=0.0100
[02/21 09:17:53] cifar10-global-proj-3.0-resnet56 INFO: Epoch 38/100, Acc=0.9005, Val Loss=0.3192, lr=0.0100
[02/21 09:18:25] cifar10-global-proj-3.0-resnet56 INFO: Epoch 39/100, Acc=0.8900, Val Loss=0.3757, lr=0.0100
[02/21 09:18:57] cifar10-global-proj-3.0-resnet56 INFO: Epoch 40/100, Acc=0.8924, Val Loss=0.3633, lr=0.0100
[02/21 09:19:29] cifar10-global-proj-3.0-resnet56 INFO: Epoch 41/100, Acc=0.8962, Val Loss=0.3545, lr=0.0100
[02/21 09:20:01] cifar10-global-proj-3.0-resnet56 INFO: Epoch 42/100, Acc=0.8979, Val Loss=0.3601, lr=0.0100
[02/21 09:20:32] cifar10-global-proj-3.0-resnet56 INFO: Epoch 43/100, Acc=0.8953, Val Loss=0.3639, lr=0.0100
[02/21 09:21:04] cifar10-global-proj-3.0-resnet56 INFO: Epoch 44/100, Acc=0.8916, Val Loss=0.3592, lr=0.0100
[02/21 09:21:37] cifar10-global-proj-3.0-resnet56 INFO: Epoch 45/100, Acc=0.8894, Val Loss=0.3866, lr=0.0100
[02/21 09:22:08] cifar10-global-proj-3.0-resnet56 INFO: Epoch 46/100, Acc=0.8879, Val Loss=0.3688, lr=0.0100
[02/21 09:22:40] cifar10-global-proj-3.0-resnet56 INFO: Epoch 47/100, Acc=0.9022, Val Loss=0.3388, lr=0.0100
[02/21 09:23:12] cifar10-global-proj-3.0-resnet56 INFO: Epoch 48/100, Acc=0.8990, Val Loss=0.3477, lr=0.0100
[02/21 09:23:43] cifar10-global-proj-3.0-resnet56 INFO: Epoch 49/100, Acc=0.8997, Val Loss=0.3401, lr=0.0100
[02/21 09:24:15] cifar10-global-proj-3.0-resnet56 INFO: Epoch 50/100, Acc=0.8901, Val Loss=0.3779, lr=0.0100
[02/21 09:24:47] cifar10-global-proj-3.0-resnet56 INFO: Epoch 51/100, Acc=0.8995, Val Loss=0.3305, lr=0.0100
[02/21 09:25:19] cifar10-global-proj-3.0-resnet56 INFO: Epoch 52/100, Acc=0.8794, Val Loss=0.4328, lr=0.0100
[02/21 09:25:51] cifar10-global-proj-3.0-resnet56 INFO: Epoch 53/100, Acc=0.8957, Val Loss=0.3461, lr=0.0100
[02/21 09:26:23] cifar10-global-proj-3.0-resnet56 INFO: Epoch 54/100, Acc=0.8894, Val Loss=0.3833, lr=0.0100
[02/21 09:26:56] cifar10-global-proj-3.0-resnet56 INFO: Epoch 55/100, Acc=0.8976, Val Loss=0.3558, lr=0.0100
[02/21 09:27:28] cifar10-global-proj-3.0-resnet56 INFO: Epoch 56/100, Acc=0.8984, Val Loss=0.3378, lr=0.0100
[02/21 09:28:00] cifar10-global-proj-3.0-resnet56 INFO: Epoch 57/100, Acc=0.8953, Val Loss=0.3773, lr=0.0100
[02/21 09:28:32] cifar10-global-proj-3.0-resnet56 INFO: Epoch 58/100, Acc=0.8970, Val Loss=0.3569, lr=0.0100
[02/21 09:29:04] cifar10-global-proj-3.0-resnet56 INFO: Epoch 59/100, Acc=0.8950, Val Loss=0.3507, lr=0.0100
[02/21 09:29:36] cifar10-global-proj-3.0-resnet56 INFO: Epoch 60/100, Acc=0.9217, Val Loss=0.2608, lr=0.0010
[02/21 09:30:09] cifar10-global-proj-3.0-resnet56 INFO: Epoch 61/100, Acc=0.9256, Val Loss=0.2544, lr=0.0010
[02/21 09:30:41] cifar10-global-proj-3.0-resnet56 INFO: Epoch 62/100, Acc=0.9269, Val Loss=0.2555, lr=0.0010
[02/21 09:31:13] cifar10-global-proj-3.0-resnet56 INFO: Epoch 63/100, Acc=0.9274, Val Loss=0.2565, lr=0.0010
[02/21 09:31:45] cifar10-global-proj-3.0-resnet56 INFO: Epoch 64/100, Acc=0.9277, Val Loss=0.2543, lr=0.0010
[02/21 09:32:17] cifar10-global-proj-3.0-resnet56 INFO: Epoch 65/100, Acc=0.9282, Val Loss=0.2574, lr=0.0010
[02/21 09:32:50] cifar10-global-proj-3.0-resnet56 INFO: Epoch 66/100, Acc=0.9302, Val Loss=0.2597, lr=0.0010
[02/21 09:33:22] cifar10-global-proj-3.0-resnet56 INFO: Epoch 67/100, Acc=0.9301, Val Loss=0.2595, lr=0.0010
[02/21 09:33:55] cifar10-global-proj-3.0-resnet56 INFO: Epoch 68/100, Acc=0.9296, Val Loss=0.2621, lr=0.0010
[02/21 09:34:27] cifar10-global-proj-3.0-resnet56 INFO: Epoch 69/100, Acc=0.9294, Val Loss=0.2644, lr=0.0010
[02/21 09:34:59] cifar10-global-proj-3.0-resnet56 INFO: Epoch 70/100, Acc=0.9311, Val Loss=0.2614, lr=0.0010
[02/21 09:35:32] cifar10-global-proj-3.0-resnet56 INFO: Epoch 71/100, Acc=0.9299, Val Loss=0.2643, lr=0.0010
[02/21 09:36:03] cifar10-global-proj-3.0-resnet56 INFO: Epoch 72/100, Acc=0.9293, Val Loss=0.2678, lr=0.0010
[02/21 09:36:35] cifar10-global-proj-3.0-resnet56 INFO: Epoch 73/100, Acc=0.9284, Val Loss=0.2671, lr=0.0010
[02/21 09:37:07] cifar10-global-proj-3.0-resnet56 INFO: Epoch 74/100, Acc=0.9302, Val Loss=0.2730, lr=0.0010
[02/21 09:37:39] cifar10-global-proj-3.0-resnet56 INFO: Epoch 75/100, Acc=0.9295, Val Loss=0.2686, lr=0.0010
[02/21 09:38:12] cifar10-global-proj-3.0-resnet56 INFO: Epoch 76/100, Acc=0.9285, Val Loss=0.2732, lr=0.0010
[02/21 09:38:44] cifar10-global-proj-3.0-resnet56 INFO: Epoch 77/100, Acc=0.9275, Val Loss=0.2773, lr=0.0010
[02/21 09:39:16] cifar10-global-proj-3.0-resnet56 INFO: Epoch 78/100, Acc=0.9304, Val Loss=0.2706, lr=0.0010
[02/21 09:39:49] cifar10-global-proj-3.0-resnet56 INFO: Epoch 79/100, Acc=0.9301, Val Loss=0.2721, lr=0.0010
[02/21 09:40:21] cifar10-global-proj-3.0-resnet56 INFO: Epoch 80/100, Acc=0.9309, Val Loss=0.2731, lr=0.0001
[02/21 09:40:54] cifar10-global-proj-3.0-resnet56 INFO: Epoch 81/100, Acc=0.9315, Val Loss=0.2700, lr=0.0001
[02/21 09:41:27] cifar10-global-proj-3.0-resnet56 INFO: Epoch 82/100, Acc=0.9306, Val Loss=0.2708, lr=0.0001
[02/21 09:41:59] cifar10-global-proj-3.0-resnet56 INFO: Epoch 83/100, Acc=0.9313, Val Loss=0.2720, lr=0.0001
[02/21 09:42:32] cifar10-global-proj-3.0-resnet56 INFO: Epoch 84/100, Acc=0.9310, Val Loss=0.2722, lr=0.0001
[02/21 09:43:04] cifar10-global-proj-3.0-resnet56 INFO: Epoch 85/100, Acc=0.9317, Val Loss=0.2722, lr=0.0001
[02/21 09:43:37] cifar10-global-proj-3.0-resnet56 INFO: Epoch 86/100, Acc=0.9311, Val Loss=0.2706, lr=0.0001
[02/21 09:44:10] cifar10-global-proj-3.0-resnet56 INFO: Epoch 87/100, Acc=0.9306, Val Loss=0.2734, lr=0.0001
[02/21 09:44:42] cifar10-global-proj-3.0-resnet56 INFO: Epoch 88/100, Acc=0.9315, Val Loss=0.2698, lr=0.0001
[02/21 09:45:15] cifar10-global-proj-3.0-resnet56 INFO: Epoch 89/100, Acc=0.9321, Val Loss=0.2693, lr=0.0001
[02/21 09:45:47] cifar10-global-proj-3.0-resnet56 INFO: Epoch 90/100, Acc=0.9310, Val Loss=0.2721, lr=0.0001
[02/21 09:46:20] cifar10-global-proj-3.0-resnet56 INFO: Epoch 91/100, Acc=0.9317, Val Loss=0.2704, lr=0.0001
[02/21 09:46:52] cifar10-global-proj-3.0-resnet56 INFO: Epoch 92/100, Acc=0.9319, Val Loss=0.2729, lr=0.0001
[02/21 09:47:25] cifar10-global-proj-3.0-resnet56 INFO: Epoch 93/100, Acc=0.9320, Val Loss=0.2707, lr=0.0001
[02/21 09:47:57] cifar10-global-proj-3.0-resnet56 INFO: Epoch 94/100, Acc=0.9318, Val Loss=0.2715, lr=0.0001
[02/21 09:48:30] cifar10-global-proj-3.0-resnet56 INFO: Epoch 95/100, Acc=0.9308, Val Loss=0.2731, lr=0.0001
[02/21 09:49:02] cifar10-global-proj-3.0-resnet56 INFO: Epoch 96/100, Acc=0.9326, Val Loss=0.2718, lr=0.0001
[02/21 09:49:34] cifar10-global-proj-3.0-resnet56 INFO: Epoch 97/100, Acc=0.9313, Val Loss=0.2729, lr=0.0001
[02/21 09:50:06] cifar10-global-proj-3.0-resnet56 INFO: Epoch 98/100, Acc=0.9310, Val Loss=0.2727, lr=0.0001
[02/21 09:50:38] cifar10-global-proj-3.0-resnet56 INFO: Epoch 99/100, Acc=0.9310, Val Loss=0.2726, lr=0.0001
[02/21 09:50:38] cifar10-global-proj-3.0-resnet56 INFO: Best Acc=0.9326
[02/21 09:50:38] cifar10-global-proj-3.0-resnet56 INFO: Params: 0.39 M
[02/21 09:50:38] cifar10-global-proj-3.0-resnet56 INFO: ops: 41.96 M
[02/21 09:50:42] cifar10-global-proj-3.0-resnet56 INFO: Acc: 0.9310 Val Loss: 0.2726

