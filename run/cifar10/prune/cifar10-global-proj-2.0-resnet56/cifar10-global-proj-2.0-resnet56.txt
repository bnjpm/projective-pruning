[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: mode: prune
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: model: resnet56
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: verbose: False
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: dataset: cifar10
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: dataroot: data
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: batch_size: 128
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: total_epochs: 100
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: lr: 0.01
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: restore: run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: output_dir: run/cifar10/prune/cifar10-global-proj-2.0-resnet56
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: finetune: True
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: last_epochs: 100
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: reps: 1
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: method: proj
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: speed_up: 2.0
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: reg: 1e-05
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: seed: 1
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: global_pruning: True
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: sl_restore: None
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: iterative_steps: 400
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: logger: <Logger cifar10-global-proj-2.0-resnet56 (DEBUG)>
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: device: cuda
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: num_classes: 10
[02/21 06:26:22] cifar10-global-proj-2.0-resnet56 INFO: Loading model from run/cifar10/pretrain/cifar10_resnet56.pth
[02/21 06:26:25] cifar10-global-proj-2.0-resnet56 INFO: Pruning...
[02/21 06:28:32] cifar10-global-proj-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(10, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(10, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(10, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(10, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(10, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(10, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(25, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(10, 31, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(31, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(31, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(17, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(31, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(31, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(21, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(31, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(31, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(31, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(31, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(31, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(62, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(31, 61, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(61, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(61, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(52, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(61, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(51, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(61, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(61, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(51, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(61, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(46, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(61, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(36, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(61, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(40, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=61, out_features=10, bias=True)
)
[02/21 06:28:35] cifar10-global-proj-2.0-resnet56 INFO: Params: 0.86 M => 0.56 M (65.94%)
[02/21 06:28:35] cifar10-global-proj-2.0-resnet56 INFO: FLOPs: 127.12 M => 63.45 M (49.91%, 2.00X )
[02/21 06:28:35] cifar10-global-proj-2.0-resnet56 INFO: Acc: 0.9392 => 0.1316
[02/21 06:28:35] cifar10-global-proj-2.0-resnet56 INFO: Val Loss: 0.2587 => 5.8787
[02/21 06:28:35] cifar10-global-proj-2.0-resnet56 INFO: Finetuning...
[02/21 06:29:08] cifar10-global-proj-2.0-resnet56 INFO: Epoch 0/100, Acc=0.8656, Val Loss=0.4305, lr=0.0100
[02/21 06:29:41] cifar10-global-proj-2.0-resnet56 INFO: Epoch 1/100, Acc=0.8917, Val Loss=0.3488, lr=0.0100
[02/21 06:30:14] cifar10-global-proj-2.0-resnet56 INFO: Epoch 2/100, Acc=0.8972, Val Loss=0.3388, lr=0.0100
[02/21 06:30:47] cifar10-global-proj-2.0-resnet56 INFO: Epoch 3/100, Acc=0.9015, Val Loss=0.3040, lr=0.0100
[02/21 06:31:20] cifar10-global-proj-2.0-resnet56 INFO: Epoch 4/100, Acc=0.8957, Val Loss=0.3499, lr=0.0100
[02/21 06:31:54] cifar10-global-proj-2.0-resnet56 INFO: Epoch 5/100, Acc=0.8909, Val Loss=0.3646, lr=0.0100
[02/21 06:32:27] cifar10-global-proj-2.0-resnet56 INFO: Epoch 6/100, Acc=0.8786, Val Loss=0.3928, lr=0.0100
[02/21 06:33:01] cifar10-global-proj-2.0-resnet56 INFO: Epoch 7/100, Acc=0.8944, Val Loss=0.3492, lr=0.0100
[02/21 06:33:34] cifar10-global-proj-2.0-resnet56 INFO: Epoch 8/100, Acc=0.8906, Val Loss=0.3644, lr=0.0100
[02/21 06:34:09] cifar10-global-proj-2.0-resnet56 INFO: Epoch 9/100, Acc=0.9035, Val Loss=0.3191, lr=0.0100
[02/21 06:34:42] cifar10-global-proj-2.0-resnet56 INFO: Epoch 10/100, Acc=0.8944, Val Loss=0.3438, lr=0.0100
[02/21 06:35:16] cifar10-global-proj-2.0-resnet56 INFO: Epoch 11/100, Acc=0.9008, Val Loss=0.3312, lr=0.0100
[02/21 06:35:50] cifar10-global-proj-2.0-resnet56 INFO: Epoch 12/100, Acc=0.8859, Val Loss=0.3971, lr=0.0100
[02/21 06:36:24] cifar10-global-proj-2.0-resnet56 INFO: Epoch 13/100, Acc=0.8985, Val Loss=0.3477, lr=0.0100
[02/21 06:36:57] cifar10-global-proj-2.0-resnet56 INFO: Epoch 14/100, Acc=0.9051, Val Loss=0.3254, lr=0.0100
[02/21 06:37:31] cifar10-global-proj-2.0-resnet56 INFO: Epoch 15/100, Acc=0.9131, Val Loss=0.3033, lr=0.0100
[02/21 06:38:04] cifar10-global-proj-2.0-resnet56 INFO: Epoch 16/100, Acc=0.9023, Val Loss=0.3296, lr=0.0100
[02/21 06:38:38] cifar10-global-proj-2.0-resnet56 INFO: Epoch 17/100, Acc=0.9062, Val Loss=0.3037, lr=0.0100
[02/21 06:39:11] cifar10-global-proj-2.0-resnet56 INFO: Epoch 18/100, Acc=0.8895, Val Loss=0.3742, lr=0.0100
[02/21 06:39:45] cifar10-global-proj-2.0-resnet56 INFO: Epoch 19/100, Acc=0.9104, Val Loss=0.3012, lr=0.0100
[02/21 06:40:19] cifar10-global-proj-2.0-resnet56 INFO: Epoch 20/100, Acc=0.9046, Val Loss=0.3185, lr=0.0100
[02/21 06:40:52] cifar10-global-proj-2.0-resnet56 INFO: Epoch 21/100, Acc=0.9009, Val Loss=0.3376, lr=0.0100
[02/21 06:41:25] cifar10-global-proj-2.0-resnet56 INFO: Epoch 22/100, Acc=0.9047, Val Loss=0.3260, lr=0.0100
[02/21 06:41:58] cifar10-global-proj-2.0-resnet56 INFO: Epoch 23/100, Acc=0.9025, Val Loss=0.3282, lr=0.0100
[02/21 06:42:31] cifar10-global-proj-2.0-resnet56 INFO: Epoch 24/100, Acc=0.8965, Val Loss=0.3455, lr=0.0100
[02/21 06:43:04] cifar10-global-proj-2.0-resnet56 INFO: Epoch 25/100, Acc=0.9029, Val Loss=0.3234, lr=0.0100
[02/21 06:43:38] cifar10-global-proj-2.0-resnet56 INFO: Epoch 26/100, Acc=0.8963, Val Loss=0.3552, lr=0.0100
[02/21 06:44:12] cifar10-global-proj-2.0-resnet56 INFO: Epoch 27/100, Acc=0.9094, Val Loss=0.3267, lr=0.0100
[02/21 06:44:45] cifar10-global-proj-2.0-resnet56 INFO: Epoch 28/100, Acc=0.9052, Val Loss=0.3226, lr=0.0100
[02/21 06:45:18] cifar10-global-proj-2.0-resnet56 INFO: Epoch 29/100, Acc=0.9040, Val Loss=0.3343, lr=0.0100
[02/21 06:45:51] cifar10-global-proj-2.0-resnet56 INFO: Epoch 30/100, Acc=0.9074, Val Loss=0.3255, lr=0.0100
[02/21 06:46:25] cifar10-global-proj-2.0-resnet56 INFO: Epoch 31/100, Acc=0.9033, Val Loss=0.3336, lr=0.0100
[02/21 06:46:57] cifar10-global-proj-2.0-resnet56 INFO: Epoch 32/100, Acc=0.9012, Val Loss=0.3291, lr=0.0100
[02/21 06:47:30] cifar10-global-proj-2.0-resnet56 INFO: Epoch 33/100, Acc=0.9146, Val Loss=0.2932, lr=0.0100
[02/21 06:48:09] cifar10-global-proj-2.0-resnet56 INFO: Epoch 34/100, Acc=0.8996, Val Loss=0.3457, lr=0.0100
[02/21 06:48:42] cifar10-global-proj-2.0-resnet56 INFO: Epoch 35/100, Acc=0.9027, Val Loss=0.3446, lr=0.0100
[02/21 06:49:15] cifar10-global-proj-2.0-resnet56 INFO: Epoch 36/100, Acc=0.9001, Val Loss=0.3511, lr=0.0100
[02/21 06:49:48] cifar10-global-proj-2.0-resnet56 INFO: Epoch 37/100, Acc=0.9080, Val Loss=0.3102, lr=0.0100
[02/21 06:50:21] cifar10-global-proj-2.0-resnet56 INFO: Epoch 38/100, Acc=0.9058, Val Loss=0.3256, lr=0.0100
[02/21 06:50:55] cifar10-global-proj-2.0-resnet56 INFO: Epoch 39/100, Acc=0.9022, Val Loss=0.3475, lr=0.0100
[02/21 06:51:28] cifar10-global-proj-2.0-resnet56 INFO: Epoch 40/100, Acc=0.9027, Val Loss=0.3291, lr=0.0100
[02/21 06:52:00] cifar10-global-proj-2.0-resnet56 INFO: Epoch 41/100, Acc=0.8982, Val Loss=0.3499, lr=0.0100
[02/21 06:52:33] cifar10-global-proj-2.0-resnet56 INFO: Epoch 42/100, Acc=0.9075, Val Loss=0.3095, lr=0.0100
[02/21 06:53:07] cifar10-global-proj-2.0-resnet56 INFO: Epoch 43/100, Acc=0.9060, Val Loss=0.3288, lr=0.0100
[02/21 06:53:40] cifar10-global-proj-2.0-resnet56 INFO: Epoch 44/100, Acc=0.9040, Val Loss=0.3210, lr=0.0100
[02/21 06:54:14] cifar10-global-proj-2.0-resnet56 INFO: Epoch 45/100, Acc=0.9086, Val Loss=0.3125, lr=0.0100
[02/21 06:54:47] cifar10-global-proj-2.0-resnet56 INFO: Epoch 46/100, Acc=0.8995, Val Loss=0.3531, lr=0.0100
[02/21 06:55:21] cifar10-global-proj-2.0-resnet56 INFO: Epoch 47/100, Acc=0.8953, Val Loss=0.3767, lr=0.0100
[02/21 06:55:54] cifar10-global-proj-2.0-resnet56 INFO: Epoch 48/100, Acc=0.8959, Val Loss=0.3676, lr=0.0100
[02/21 06:56:27] cifar10-global-proj-2.0-resnet56 INFO: Epoch 49/100, Acc=0.8992, Val Loss=0.3511, lr=0.0100
[02/21 06:57:00] cifar10-global-proj-2.0-resnet56 INFO: Epoch 50/100, Acc=0.9088, Val Loss=0.3402, lr=0.0100
[02/21 06:57:33] cifar10-global-proj-2.0-resnet56 INFO: Epoch 51/100, Acc=0.9047, Val Loss=0.3432, lr=0.0100
[02/21 06:58:06] cifar10-global-proj-2.0-resnet56 INFO: Epoch 52/100, Acc=0.8874, Val Loss=0.3984, lr=0.0100
[02/21 06:58:39] cifar10-global-proj-2.0-resnet56 INFO: Epoch 53/100, Acc=0.9057, Val Loss=0.3420, lr=0.0100
[02/21 06:59:12] cifar10-global-proj-2.0-resnet56 INFO: Epoch 54/100, Acc=0.9004, Val Loss=0.3512, lr=0.0100
[02/21 06:59:44] cifar10-global-proj-2.0-resnet56 INFO: Epoch 55/100, Acc=0.8959, Val Loss=0.3612, lr=0.0100
[02/21 07:00:18] cifar10-global-proj-2.0-resnet56 INFO: Epoch 56/100, Acc=0.9085, Val Loss=0.3227, lr=0.0100
[02/21 07:00:51] cifar10-global-proj-2.0-resnet56 INFO: Epoch 57/100, Acc=0.9061, Val Loss=0.3153, lr=0.0100
[02/21 07:01:24] cifar10-global-proj-2.0-resnet56 INFO: Epoch 58/100, Acc=0.8952, Val Loss=0.3829, lr=0.0100
[02/21 07:01:57] cifar10-global-proj-2.0-resnet56 INFO: Epoch 59/100, Acc=0.8986, Val Loss=0.3560, lr=0.0100
[02/21 07:02:30] cifar10-global-proj-2.0-resnet56 INFO: Epoch 60/100, Acc=0.9303, Val Loss=0.2361, lr=0.0010
[02/21 07:03:03] cifar10-global-proj-2.0-resnet56 INFO: Epoch 61/100, Acc=0.9314, Val Loss=0.2374, lr=0.0010
[02/21 07:03:37] cifar10-global-proj-2.0-resnet56 INFO: Epoch 62/100, Acc=0.9334, Val Loss=0.2397, lr=0.0010
[02/21 07:04:10] cifar10-global-proj-2.0-resnet56 INFO: Epoch 63/100, Acc=0.9330, Val Loss=0.2395, lr=0.0010
[02/21 07:04:43] cifar10-global-proj-2.0-resnet56 INFO: Epoch 64/100, Acc=0.9337, Val Loss=0.2412, lr=0.0010
[02/21 07:05:15] cifar10-global-proj-2.0-resnet56 INFO: Epoch 65/100, Acc=0.9328, Val Loss=0.2411, lr=0.0010
[02/21 07:05:48] cifar10-global-proj-2.0-resnet56 INFO: Epoch 66/100, Acc=0.9342, Val Loss=0.2428, lr=0.0010
[02/21 07:06:21] cifar10-global-proj-2.0-resnet56 INFO: Epoch 67/100, Acc=0.9346, Val Loss=0.2432, lr=0.0010
[02/21 07:06:54] cifar10-global-proj-2.0-resnet56 INFO: Epoch 68/100, Acc=0.9339, Val Loss=0.2451, lr=0.0010
[02/21 07:07:27] cifar10-global-proj-2.0-resnet56 INFO: Epoch 69/100, Acc=0.9341, Val Loss=0.2420, lr=0.0010
[02/21 07:07:59] cifar10-global-proj-2.0-resnet56 INFO: Epoch 70/100, Acc=0.9341, Val Loss=0.2501, lr=0.0010
[02/21 07:08:32] cifar10-global-proj-2.0-resnet56 INFO: Epoch 71/100, Acc=0.9330, Val Loss=0.2484, lr=0.0010
[02/21 07:09:05] cifar10-global-proj-2.0-resnet56 INFO: Epoch 72/100, Acc=0.9338, Val Loss=0.2494, lr=0.0010
[02/21 07:09:37] cifar10-global-proj-2.0-resnet56 INFO: Epoch 73/100, Acc=0.9359, Val Loss=0.2489, lr=0.0010
[02/21 07:10:10] cifar10-global-proj-2.0-resnet56 INFO: Epoch 74/100, Acc=0.9350, Val Loss=0.2512, lr=0.0010
[02/21 07:10:42] cifar10-global-proj-2.0-resnet56 INFO: Epoch 75/100, Acc=0.9349, Val Loss=0.2493, lr=0.0010
[02/21 07:11:15] cifar10-global-proj-2.0-resnet56 INFO: Epoch 76/100, Acc=0.9366, Val Loss=0.2488, lr=0.0010
[02/21 07:11:48] cifar10-global-proj-2.0-resnet56 INFO: Epoch 77/100, Acc=0.9349, Val Loss=0.2514, lr=0.0010
[02/21 07:12:20] cifar10-global-proj-2.0-resnet56 INFO: Epoch 78/100, Acc=0.9369, Val Loss=0.2530, lr=0.0010
[02/21 07:12:53] cifar10-global-proj-2.0-resnet56 INFO: Epoch 79/100, Acc=0.9365, Val Loss=0.2534, lr=0.0010
[02/21 07:13:26] cifar10-global-proj-2.0-resnet56 INFO: Epoch 80/100, Acc=0.9363, Val Loss=0.2529, lr=0.0001
[02/21 07:13:59] cifar10-global-proj-2.0-resnet56 INFO: Epoch 81/100, Acc=0.9363, Val Loss=0.2506, lr=0.0001
[02/21 07:14:32] cifar10-global-proj-2.0-resnet56 INFO: Epoch 82/100, Acc=0.9365, Val Loss=0.2497, lr=0.0001
[02/21 07:15:05] cifar10-global-proj-2.0-resnet56 INFO: Epoch 83/100, Acc=0.9369, Val Loss=0.2504, lr=0.0001
[02/21 07:15:38] cifar10-global-proj-2.0-resnet56 INFO: Epoch 84/100, Acc=0.9364, Val Loss=0.2503, lr=0.0001
[02/21 07:16:11] cifar10-global-proj-2.0-resnet56 INFO: Epoch 85/100, Acc=0.9367, Val Loss=0.2495, lr=0.0001
[02/21 07:16:43] cifar10-global-proj-2.0-resnet56 INFO: Epoch 86/100, Acc=0.9364, Val Loss=0.2494, lr=0.0001
[02/21 07:17:16] cifar10-global-proj-2.0-resnet56 INFO: Epoch 87/100, Acc=0.9366, Val Loss=0.2515, lr=0.0001
[02/21 07:17:49] cifar10-global-proj-2.0-resnet56 INFO: Epoch 88/100, Acc=0.9371, Val Loss=0.2503, lr=0.0001
[02/21 07:18:22] cifar10-global-proj-2.0-resnet56 INFO: Epoch 89/100, Acc=0.9374, Val Loss=0.2493, lr=0.0001
[02/21 07:18:55] cifar10-global-proj-2.0-resnet56 INFO: Epoch 90/100, Acc=0.9363, Val Loss=0.2536, lr=0.0001
[02/21 07:19:28] cifar10-global-proj-2.0-resnet56 INFO: Epoch 91/100, Acc=0.9374, Val Loss=0.2499, lr=0.0001
[02/21 07:20:01] cifar10-global-proj-2.0-resnet56 INFO: Epoch 92/100, Acc=0.9360, Val Loss=0.2523, lr=0.0001
[02/21 07:20:35] cifar10-global-proj-2.0-resnet56 INFO: Epoch 93/100, Acc=0.9363, Val Loss=0.2507, lr=0.0001
[02/21 07:21:08] cifar10-global-proj-2.0-resnet56 INFO: Epoch 94/100, Acc=0.9368, Val Loss=0.2512, lr=0.0001
[02/21 07:21:41] cifar10-global-proj-2.0-resnet56 INFO: Epoch 95/100, Acc=0.9369, Val Loss=0.2521, lr=0.0001
[02/21 07:22:14] cifar10-global-proj-2.0-resnet56 INFO: Epoch 96/100, Acc=0.9363, Val Loss=0.2518, lr=0.0001
[02/21 07:22:48] cifar10-global-proj-2.0-resnet56 INFO: Epoch 97/100, Acc=0.9364, Val Loss=0.2530, lr=0.0001
[02/21 07:23:21] cifar10-global-proj-2.0-resnet56 INFO: Epoch 98/100, Acc=0.9354, Val Loss=0.2522, lr=0.0001
[02/21 07:23:53] cifar10-global-proj-2.0-resnet56 INFO: Epoch 99/100, Acc=0.9363, Val Loss=0.2524, lr=0.0001
[02/21 07:23:53] cifar10-global-proj-2.0-resnet56 INFO: Best Acc=0.9374
[02/21 07:23:53] cifar10-global-proj-2.0-resnet56 INFO: Params: 0.56 M
[02/21 07:23:53] cifar10-global-proj-2.0-resnet56 INFO: ops: 63.45 M
[02/21 07:23:56] cifar10-global-proj-2.0-resnet56 INFO: Acc: 0.9363 Val Loss: 0.2524

