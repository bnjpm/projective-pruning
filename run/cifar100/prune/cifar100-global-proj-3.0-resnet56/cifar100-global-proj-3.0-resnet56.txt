[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: mode: prune
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: model: resnet56
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: verbose: False
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: dataset: cifar100
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: dataroot: data
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: batch_size: 128
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: total_epochs: 100
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: lr: 0.01
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-proj-3.0-resnet56
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: finetune: True
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: last_epochs: 100
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: reps: 1
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: method: proj
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: speed_up: 3.0
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: reg: 1e-05
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: seed: 1
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: global_pruning: True
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: sl_restore: None
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: iterative_steps: 400
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: logger: <Logger cifar100-global-proj-3.0-resnet56 (DEBUG)>
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: device: cuda
[02/21 12:31:01] cifar100-global-proj-3.0-resnet56 INFO: num_classes: 100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: mode: prune
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: model: resnet56
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: verbose: False
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: dataset: cifar100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: dataroot: data
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: batch_size: 128
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: total_epochs: 100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: lr: 0.01
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-proj-3.0-resnet56
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: finetune: True
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: last_epochs: 100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: reps: 1
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: method: proj
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: speed_up: 3.0
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: reg: 1e-05
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: delta_reg: 0.0001
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: weight_decay: 0.0005
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: seed: 1
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: global_pruning: True
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: sl_total_epochs: 100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: sl_lr: 0.01
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: sl_restore: None
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: iterative_steps: 400
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: logger: <Logger cifar100-global-proj-3.0-resnet56 (DEBUG)>
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: device: cuda
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: num_classes: 100
[02/22 00:02:42] cifar100-global-proj-3.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/22 00:02:46] cifar100-global-proj-3.0-resnet56 INFO: Pruning...
[02/22 00:05:13] cifar100-global-proj-3.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(2, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(2, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(24, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(24, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(24, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(24, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(24, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(52, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(24, 59, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(59, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(43, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(59, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(59, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(52, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(59, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(57, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(59, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(46, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(59, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(49, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(59, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(59, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(46, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=59, out_features=100, bias=True)
)
[02/22 00:05:15] cifar100-global-proj-3.0-resnet56 INFO: Params: 0.86 M => 0.51 M (59.59%)
[02/22 00:05:15] cifar100-global-proj-3.0-resnet56 INFO: FLOPs: 127.12 M => 42.27 M (33.25%, 3.01X )
[02/22 00:05:15] cifar100-global-proj-3.0-resnet56 INFO: Acc: 0.7269 => 0.0100
[02/22 00:05:15] cifar100-global-proj-3.0-resnet56 INFO: Val Loss: 1.1578 => 15.5368
[02/22 00:05:15] cifar100-global-proj-3.0-resnet56 INFO: Finetuning...
[02/22 00:05:42] cifar100-global-proj-3.0-resnet56 INFO: Epoch 0/100, Acc=0.1598, Val Loss=3.6702, lr=0.0100
[02/22 00:06:09] cifar100-global-proj-3.0-resnet56 INFO: Epoch 1/100, Acc=0.3828, Val Loss=2.4342, lr=0.0100
[02/22 00:06:36] cifar100-global-proj-3.0-resnet56 INFO: Epoch 2/100, Acc=0.3946, Val Loss=2.4514, lr=0.0100
[02/22 00:07:03] cifar100-global-proj-3.0-resnet56 INFO: Epoch 3/100, Acc=0.3942, Val Loss=2.5161, lr=0.0100
[02/22 00:07:30] cifar100-global-proj-3.0-resnet56 INFO: Epoch 4/100, Acc=0.5330, Val Loss=1.7343, lr=0.0100
[02/22 00:07:57] cifar100-global-proj-3.0-resnet56 INFO: Epoch 5/100, Acc=0.5221, Val Loss=1.8042, lr=0.0100
[02/22 00:08:24] cifar100-global-proj-3.0-resnet56 INFO: Epoch 6/100, Acc=0.5433, Val Loss=1.7224, lr=0.0100
[02/22 00:08:50] cifar100-global-proj-3.0-resnet56 INFO: Epoch 7/100, Acc=0.5420, Val Loss=1.7261, lr=0.0100
[02/22 00:09:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 8/100, Acc=0.5619, Val Loss=1.6346, lr=0.0100
[02/22 00:09:44] cifar100-global-proj-3.0-resnet56 INFO: Epoch 9/100, Acc=0.5791, Val Loss=1.5569, lr=0.0100
[02/22 00:10:11] cifar100-global-proj-3.0-resnet56 INFO: Epoch 10/100, Acc=0.5681, Val Loss=1.6065, lr=0.0100
[02/22 00:10:39] cifar100-global-proj-3.0-resnet56 INFO: Epoch 11/100, Acc=0.5698, Val Loss=1.6196, lr=0.0100
[02/22 00:11:06] cifar100-global-proj-3.0-resnet56 INFO: Epoch 12/100, Acc=0.5551, Val Loss=1.6814, lr=0.0100
[02/22 00:11:33] cifar100-global-proj-3.0-resnet56 INFO: Epoch 13/100, Acc=0.5891, Val Loss=1.5297, lr=0.0100
[02/22 00:12:01] cifar100-global-proj-3.0-resnet56 INFO: Epoch 14/100, Acc=0.5528, Val Loss=1.6936, lr=0.0100
[02/22 00:12:28] cifar100-global-proj-3.0-resnet56 INFO: Epoch 15/100, Acc=0.5926, Val Loss=1.5276, lr=0.0100
[02/22 00:12:55] cifar100-global-proj-3.0-resnet56 INFO: Epoch 16/100, Acc=0.5811, Val Loss=1.5555, lr=0.0100
[02/22 00:13:22] cifar100-global-proj-3.0-resnet56 INFO: Epoch 17/100, Acc=0.5871, Val Loss=1.5532, lr=0.0100
[02/22 00:13:50] cifar100-global-proj-3.0-resnet56 INFO: Epoch 18/100, Acc=0.5856, Val Loss=1.5692, lr=0.0100
[02/22 00:14:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 19/100, Acc=0.5847, Val Loss=1.5646, lr=0.0100
[02/22 00:14:45] cifar100-global-proj-3.0-resnet56 INFO: Epoch 20/100, Acc=0.5912, Val Loss=1.5668, lr=0.0100
[02/22 00:15:12] cifar100-global-proj-3.0-resnet56 INFO: Epoch 21/100, Acc=0.6002, Val Loss=1.4827, lr=0.0100
[02/22 00:15:39] cifar100-global-proj-3.0-resnet56 INFO: Epoch 22/100, Acc=0.6037, Val Loss=1.4823, lr=0.0100
[02/22 00:16:07] cifar100-global-proj-3.0-resnet56 INFO: Epoch 23/100, Acc=0.6042, Val Loss=1.4817, lr=0.0100
[02/22 00:16:34] cifar100-global-proj-3.0-resnet56 INFO: Epoch 24/100, Acc=0.6115, Val Loss=1.4632, lr=0.0100
[02/22 00:17:02] cifar100-global-proj-3.0-resnet56 INFO: Epoch 25/100, Acc=0.5963, Val Loss=1.5317, lr=0.0100
[02/22 00:17:29] cifar100-global-proj-3.0-resnet56 INFO: Epoch 26/100, Acc=0.6170, Val Loss=1.4618, lr=0.0100
[02/22 00:17:56] cifar100-global-proj-3.0-resnet56 INFO: Epoch 27/100, Acc=0.5914, Val Loss=1.5782, lr=0.0100
[02/22 00:18:23] cifar100-global-proj-3.0-resnet56 INFO: Epoch 28/100, Acc=0.6009, Val Loss=1.5285, lr=0.0100
[02/22 00:18:50] cifar100-global-proj-3.0-resnet56 INFO: Epoch 29/100, Acc=0.5872, Val Loss=1.5763, lr=0.0100
[02/22 00:19:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 30/100, Acc=0.6021, Val Loss=1.5361, lr=0.0100
[02/22 00:19:44] cifar100-global-proj-3.0-resnet56 INFO: Epoch 31/100, Acc=0.6083, Val Loss=1.4636, lr=0.0100
[02/22 00:20:11] cifar100-global-proj-3.0-resnet56 INFO: Epoch 32/100, Acc=0.6044, Val Loss=1.5093, lr=0.0100
[02/22 00:20:38] cifar100-global-proj-3.0-resnet56 INFO: Epoch 33/100, Acc=0.5860, Val Loss=1.5775, lr=0.0100
[02/22 00:21:05] cifar100-global-proj-3.0-resnet56 INFO: Epoch 34/100, Acc=0.5992, Val Loss=1.5362, lr=0.0100
[02/22 00:21:32] cifar100-global-proj-3.0-resnet56 INFO: Epoch 35/100, Acc=0.6060, Val Loss=1.4837, lr=0.0100
[02/22 00:21:59] cifar100-global-proj-3.0-resnet56 INFO: Epoch 36/100, Acc=0.6038, Val Loss=1.5367, lr=0.0100
[02/22 00:22:26] cifar100-global-proj-3.0-resnet56 INFO: Epoch 37/100, Acc=0.6085, Val Loss=1.5591, lr=0.0100
[02/22 00:22:53] cifar100-global-proj-3.0-resnet56 INFO: Epoch 38/100, Acc=0.6052, Val Loss=1.5199, lr=0.0100
[02/22 00:23:20] cifar100-global-proj-3.0-resnet56 INFO: Epoch 39/100, Acc=0.5932, Val Loss=1.5613, lr=0.0100
[02/22 00:23:47] cifar100-global-proj-3.0-resnet56 INFO: Epoch 40/100, Acc=0.6175, Val Loss=1.4517, lr=0.0100
[02/22 00:24:14] cifar100-global-proj-3.0-resnet56 INFO: Epoch 41/100, Acc=0.6025, Val Loss=1.5483, lr=0.0100
[02/22 00:24:41] cifar100-global-proj-3.0-resnet56 INFO: Epoch 42/100, Acc=0.6070, Val Loss=1.5202, lr=0.0100
[02/22 00:25:08] cifar100-global-proj-3.0-resnet56 INFO: Epoch 43/100, Acc=0.5948, Val Loss=1.5697, lr=0.0100
[02/22 00:25:35] cifar100-global-proj-3.0-resnet56 INFO: Epoch 44/100, Acc=0.6199, Val Loss=1.4373, lr=0.0100
[02/22 00:26:02] cifar100-global-proj-3.0-resnet56 INFO: Epoch 45/100, Acc=0.5987, Val Loss=1.5779, lr=0.0100
[02/22 00:26:29] cifar100-global-proj-3.0-resnet56 INFO: Epoch 46/100, Acc=0.6157, Val Loss=1.4836, lr=0.0100
[02/22 00:26:56] cifar100-global-proj-3.0-resnet56 INFO: Epoch 47/100, Acc=0.6069, Val Loss=1.5293, lr=0.0100
[02/22 00:27:23] cifar100-global-proj-3.0-resnet56 INFO: Epoch 48/100, Acc=0.6024, Val Loss=1.5729, lr=0.0100
[02/22 00:27:51] cifar100-global-proj-3.0-resnet56 INFO: Epoch 49/100, Acc=0.6172, Val Loss=1.4682, lr=0.0100
[02/22 00:28:18] cifar100-global-proj-3.0-resnet56 INFO: Epoch 50/100, Acc=0.6106, Val Loss=1.4783, lr=0.0100
[02/22 00:28:45] cifar100-global-proj-3.0-resnet56 INFO: Epoch 51/100, Acc=0.6095, Val Loss=1.5366, lr=0.0100
[02/22 00:29:12] cifar100-global-proj-3.0-resnet56 INFO: Epoch 52/100, Acc=0.6084, Val Loss=1.4850, lr=0.0100
[02/22 00:29:39] cifar100-global-proj-3.0-resnet56 INFO: Epoch 53/100, Acc=0.6065, Val Loss=1.5413, lr=0.0100
[02/22 00:30:07] cifar100-global-proj-3.0-resnet56 INFO: Epoch 54/100, Acc=0.6048, Val Loss=1.5603, lr=0.0100
[02/22 00:30:34] cifar100-global-proj-3.0-resnet56 INFO: Epoch 55/100, Acc=0.6163, Val Loss=1.5404, lr=0.0100
[02/22 00:31:01] cifar100-global-proj-3.0-resnet56 INFO: Epoch 56/100, Acc=0.5953, Val Loss=1.6064, lr=0.0100
[02/22 00:31:28] cifar100-global-proj-3.0-resnet56 INFO: Epoch 57/100, Acc=0.5967, Val Loss=1.6220, lr=0.0100
[02/22 00:31:55] cifar100-global-proj-3.0-resnet56 INFO: Epoch 58/100, Acc=0.6224, Val Loss=1.4590, lr=0.0100
[02/22 00:32:23] cifar100-global-proj-3.0-resnet56 INFO: Epoch 59/100, Acc=0.6104, Val Loss=1.5063, lr=0.0100
[02/22 00:32:50] cifar100-global-proj-3.0-resnet56 INFO: Epoch 60/100, Acc=0.6793, Val Loss=1.2101, lr=0.0010
[02/22 00:33:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 61/100, Acc=0.6812, Val Loss=1.2002, lr=0.0010
[02/22 00:33:44] cifar100-global-proj-3.0-resnet56 INFO: Epoch 62/100, Acc=0.6808, Val Loss=1.2005, lr=0.0010
[02/22 00:34:12] cifar100-global-proj-3.0-resnet56 INFO: Epoch 63/100, Acc=0.6799, Val Loss=1.2116, lr=0.0010
[02/22 00:34:39] cifar100-global-proj-3.0-resnet56 INFO: Epoch 64/100, Acc=0.6803, Val Loss=1.2262, lr=0.0010
[02/22 00:35:06] cifar100-global-proj-3.0-resnet56 INFO: Epoch 65/100, Acc=0.6790, Val Loss=1.2161, lr=0.0010
[02/22 00:35:33] cifar100-global-proj-3.0-resnet56 INFO: Epoch 66/100, Acc=0.6750, Val Loss=1.2384, lr=0.0010
[02/22 00:36:01] cifar100-global-proj-3.0-resnet56 INFO: Epoch 67/100, Acc=0.6771, Val Loss=1.2333, lr=0.0010
[02/22 00:36:28] cifar100-global-proj-3.0-resnet56 INFO: Epoch 68/100, Acc=0.6791, Val Loss=1.2314, lr=0.0010
[02/22 00:36:55] cifar100-global-proj-3.0-resnet56 INFO: Epoch 69/100, Acc=0.6797, Val Loss=1.2391, lr=0.0010
[02/22 00:37:22] cifar100-global-proj-3.0-resnet56 INFO: Epoch 70/100, Acc=0.6804, Val Loss=1.2452, lr=0.0010
[02/22 00:37:50] cifar100-global-proj-3.0-resnet56 INFO: Epoch 71/100, Acc=0.6781, Val Loss=1.2544, lr=0.0010
[02/22 00:38:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 72/100, Acc=0.6782, Val Loss=1.2504, lr=0.0010
[02/22 00:38:44] cifar100-global-proj-3.0-resnet56 INFO: Epoch 73/100, Acc=0.6790, Val Loss=1.2614, lr=0.0010
[02/22 00:39:12] cifar100-global-proj-3.0-resnet56 INFO: Epoch 74/100, Acc=0.6779, Val Loss=1.2594, lr=0.0010
[02/22 00:39:39] cifar100-global-proj-3.0-resnet56 INFO: Epoch 75/100, Acc=0.6800, Val Loss=1.2598, lr=0.0010
[02/22 00:40:06] cifar100-global-proj-3.0-resnet56 INFO: Epoch 76/100, Acc=0.6757, Val Loss=1.2753, lr=0.0010
[02/22 00:40:34] cifar100-global-proj-3.0-resnet56 INFO: Epoch 77/100, Acc=0.6770, Val Loss=1.2748, lr=0.0010
[02/22 00:41:01] cifar100-global-proj-3.0-resnet56 INFO: Epoch 78/100, Acc=0.6774, Val Loss=1.2848, lr=0.0010
[02/22 00:41:30] cifar100-global-proj-3.0-resnet56 INFO: Epoch 79/100, Acc=0.6743, Val Loss=1.2797, lr=0.0010
[02/22 00:41:58] cifar100-global-proj-3.0-resnet56 INFO: Epoch 80/100, Acc=0.6774, Val Loss=1.2688, lr=0.0001
[02/22 00:42:26] cifar100-global-proj-3.0-resnet56 INFO: Epoch 81/100, Acc=0.6763, Val Loss=1.2704, lr=0.0001
[02/22 00:42:55] cifar100-global-proj-3.0-resnet56 INFO: Epoch 82/100, Acc=0.6779, Val Loss=1.2681, lr=0.0001
[02/22 00:43:23] cifar100-global-proj-3.0-resnet56 INFO: Epoch 83/100, Acc=0.6782, Val Loss=1.2720, lr=0.0001
[02/22 00:43:52] cifar100-global-proj-3.0-resnet56 INFO: Epoch 84/100, Acc=0.6785, Val Loss=1.2726, lr=0.0001
[02/22 00:44:20] cifar100-global-proj-3.0-resnet56 INFO: Epoch 85/100, Acc=0.6783, Val Loss=1.2731, lr=0.0001
[02/22 00:44:48] cifar100-global-proj-3.0-resnet56 INFO: Epoch 86/100, Acc=0.6808, Val Loss=1.2740, lr=0.0001
[02/22 00:45:15] cifar100-global-proj-3.0-resnet56 INFO: Epoch 87/100, Acc=0.6798, Val Loss=1.2729, lr=0.0001
[02/22 00:45:43] cifar100-global-proj-3.0-resnet56 INFO: Epoch 88/100, Acc=0.6798, Val Loss=1.2699, lr=0.0001
[02/22 00:46:10] cifar100-global-proj-3.0-resnet56 INFO: Epoch 89/100, Acc=0.6783, Val Loss=1.2709, lr=0.0001
[02/22 00:46:37] cifar100-global-proj-3.0-resnet56 INFO: Epoch 90/100, Acc=0.6801, Val Loss=1.2682, lr=0.0001
[02/22 00:47:05] cifar100-global-proj-3.0-resnet56 INFO: Epoch 91/100, Acc=0.6777, Val Loss=1.2788, lr=0.0001
[02/22 00:47:32] cifar100-global-proj-3.0-resnet56 INFO: Epoch 92/100, Acc=0.6812, Val Loss=1.2677, lr=0.0001
[02/22 00:48:00] cifar100-global-proj-3.0-resnet56 INFO: Epoch 93/100, Acc=0.6777, Val Loss=1.2770, lr=0.0001
[02/22 00:48:27] cifar100-global-proj-3.0-resnet56 INFO: Epoch 94/100, Acc=0.6791, Val Loss=1.2720, lr=0.0001
[02/22 00:48:54] cifar100-global-proj-3.0-resnet56 INFO: Epoch 95/100, Acc=0.6792, Val Loss=1.2763, lr=0.0001
[02/22 00:49:22] cifar100-global-proj-3.0-resnet56 INFO: Epoch 96/100, Acc=0.6796, Val Loss=1.2745, lr=0.0001
[02/22 00:49:49] cifar100-global-proj-3.0-resnet56 INFO: Epoch 97/100, Acc=0.6798, Val Loss=1.2741, lr=0.0001
[02/22 00:50:17] cifar100-global-proj-3.0-resnet56 INFO: Epoch 98/100, Acc=0.6807, Val Loss=1.2727, lr=0.0001
[02/22 00:50:44] cifar100-global-proj-3.0-resnet56 INFO: Epoch 99/100, Acc=0.6772, Val Loss=1.2771, lr=0.0001
[02/22 00:50:44] cifar100-global-proj-3.0-resnet56 INFO: Best Acc=0.6812
[02/22 00:50:44] cifar100-global-proj-3.0-resnet56 INFO: Params: 0.51 M
[02/22 00:50:44] cifar100-global-proj-3.0-resnet56 INFO: ops: 42.27 M
[02/22 00:50:47] cifar100-global-proj-3.0-resnet56 INFO: Acc: 0.6772 Val Loss: 1.2771

