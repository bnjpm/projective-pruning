[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: mode: prune
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: model: vgg19
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: verbose: False
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: dataset: cifar100
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: dataroot: data
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: batch_size: 128
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: total_epochs: 100
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: lr_decay_milestones: 60,80
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: lr_decay_gamma: 0.1
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: lr: 0.01
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: restore: run/cifar100/pretrain/cifar100_vgg19.pth
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: output_dir: run/cifar100/prune/cifar100-global-lamp-3.0-vgg19
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: finetune: True
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: last_epochs: 100
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: reps: 1
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: method: lamp
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: speed_up: 3.0
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: max_pruning_ratio: 1.0
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: soft_keeping_ratio: 0.0
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: reg: 1e-05
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: delta_reg: 0.0001
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: weight_decay: 0.0005
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: seed: 1
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: global_pruning: True
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: sl_total_epochs: 100
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: sl_lr: 0.01
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: sl_lr_decay_milestones: 60,80
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: sl_reg_warmup: 0
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: sl_restore: None
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: iterative_steps: 400
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: logger: <Logger cifar100-global-lamp-3.0-vgg19 (DEBUG)>
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: device: cuda
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: num_classes: 100
[02/25 06:20:56] cifar100-global-lamp-3.0-vgg19 INFO: Loading model from run/cifar100/pretrain/cifar100_vgg19.pth
[02/25 06:20:59] cifar100-global-lamp-3.0-vgg19 INFO: Pruning...
[02/25 06:21:11] cifar100-global-lamp-3.0-vgg19 INFO: VGG(
  (block0): Sequential(
    (0): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(30, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block1): Sequential(
    (0): Conv2d(63, 117, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(117, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(128, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(179, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(184, 193, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(193, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block3): Sequential(
    (0): Conv2d(193, 189, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(189, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(189, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(186, 135, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(135, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block4): Sequential(
    (0): Conv2d(112, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(132, 141, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(141, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(141, 151, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(151, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(151, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=160, out_features=100, bias=True)
)
[02/25 06:21:14] cifar100-global-lamp-3.0-vgg19 INFO: Params: 20.09 M => 3.09 M (15.36%)
[02/25 06:21:14] cifar100-global-lamp-3.0-vgg19 INFO: FLOPs: 512.73 M => 170.23 M (33.20%, 3.01X )
[02/25 06:21:14] cifar100-global-lamp-3.0-vgg19 INFO: Acc: 0.7376 => 0.0154
[02/25 06:21:14] cifar100-global-lamp-3.0-vgg19 INFO: Val Loss: 1.2744 => 4.8322
[02/25 06:21:14] cifar100-global-lamp-3.0-vgg19 INFO: Finetuning...
[02/25 06:21:35] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 0/100, Acc=0.6163, Val Loss=1.5140, lr=0.0100
[02/25 06:21:57] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 1/100, Acc=0.6219, Val Loss=1.4844, lr=0.0100
[02/25 06:22:18] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 2/100, Acc=0.6354, Val Loss=1.4330, lr=0.0100
[02/25 06:22:40] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 3/100, Acc=0.6453, Val Loss=1.4244, lr=0.0100
[02/25 06:23:02] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 4/100, Acc=0.6391, Val Loss=1.4491, lr=0.0100
[02/25 06:23:24] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 5/100, Acc=0.6480, Val Loss=1.4132, lr=0.0100
[02/25 06:23:45] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 6/100, Acc=0.6488, Val Loss=1.4180, lr=0.0100
[02/25 06:24:07] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 7/100, Acc=0.6573, Val Loss=1.4002, lr=0.0100
[02/25 06:24:29] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 8/100, Acc=0.6624, Val Loss=1.3864, lr=0.0100
[02/25 06:24:51] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 9/100, Acc=0.6572, Val Loss=1.4058, lr=0.0100
[02/25 06:25:13] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 10/100, Acc=0.6522, Val Loss=1.4461, lr=0.0100
[02/25 06:25:35] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 11/100, Acc=0.6465, Val Loss=1.5157, lr=0.0100
[02/25 06:25:56] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 12/100, Acc=0.6486, Val Loss=1.4635, lr=0.0100
[02/25 06:26:18] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 13/100, Acc=0.6460, Val Loss=1.5052, lr=0.0100
[02/25 06:26:40] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 14/100, Acc=0.6602, Val Loss=1.4165, lr=0.0100
[02/25 06:27:02] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 15/100, Acc=0.6531, Val Loss=1.4533, lr=0.0100
[02/25 06:27:24] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 16/100, Acc=0.6587, Val Loss=1.4317, lr=0.0100
[02/25 06:27:46] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 17/100, Acc=0.6664, Val Loss=1.3955, lr=0.0100
[02/25 06:28:07] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 18/100, Acc=0.6503, Val Loss=1.5207, lr=0.0100
[02/25 06:28:29] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 19/100, Acc=0.6601, Val Loss=1.4366, lr=0.0100
[02/25 06:28:51] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 20/100, Acc=0.6607, Val Loss=1.4006, lr=0.0100
[02/25 06:29:13] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 21/100, Acc=0.6632, Val Loss=1.4038, lr=0.0100
[02/25 06:29:35] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 22/100, Acc=0.6640, Val Loss=1.4364, lr=0.0100
[02/25 06:29:56] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 23/100, Acc=0.6529, Val Loss=1.4766, lr=0.0100
[02/25 06:30:18] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 24/100, Acc=0.6442, Val Loss=1.5450, lr=0.0100
[02/25 06:30:40] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 25/100, Acc=0.6688, Val Loss=1.4087, lr=0.0100
[02/25 06:31:02] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 26/100, Acc=0.6546, Val Loss=1.5013, lr=0.0100
[02/25 06:31:23] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 27/100, Acc=0.6482, Val Loss=1.5399, lr=0.0100
[02/25 06:31:45] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 28/100, Acc=0.6616, Val Loss=1.4611, lr=0.0100
[02/25 06:32:07] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 29/100, Acc=0.6539, Val Loss=1.4647, lr=0.0100
[02/25 06:32:28] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 30/100, Acc=0.6614, Val Loss=1.4715, lr=0.0100
[02/25 06:32:50] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 31/100, Acc=0.6583, Val Loss=1.4844, lr=0.0100
[02/25 06:33:12] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 32/100, Acc=0.6612, Val Loss=1.5009, lr=0.0100
[02/25 06:33:34] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 33/100, Acc=0.6709, Val Loss=1.4183, lr=0.0100
[02/25 06:33:55] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 34/100, Acc=0.6547, Val Loss=1.5121, lr=0.0100
[02/25 06:34:17] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 35/100, Acc=0.6667, Val Loss=1.4571, lr=0.0100
[02/25 06:34:40] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 36/100, Acc=0.6768, Val Loss=1.4177, lr=0.0100
[02/25 06:35:02] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 37/100, Acc=0.6623, Val Loss=1.4903, lr=0.0100
[02/25 06:35:25] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 38/100, Acc=0.6611, Val Loss=1.5020, lr=0.0100
[02/25 06:35:48] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 39/100, Acc=0.6616, Val Loss=1.4691, lr=0.0100
[02/25 06:36:10] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 40/100, Acc=0.6687, Val Loss=1.4649, lr=0.0100
[02/25 06:36:31] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 41/100, Acc=0.6607, Val Loss=1.5053, lr=0.0100
[02/25 06:36:53] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 42/100, Acc=0.6568, Val Loss=1.5277, lr=0.0100
[02/25 06:37:16] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 43/100, Acc=0.6685, Val Loss=1.4508, lr=0.0100
[02/25 06:37:38] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 44/100, Acc=0.6657, Val Loss=1.4784, lr=0.0100
[02/25 06:38:00] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 45/100, Acc=0.6677, Val Loss=1.4368, lr=0.0100
[02/25 06:38:22] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 46/100, Acc=0.6479, Val Loss=1.5605, lr=0.0100
[02/25 06:38:45] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 47/100, Acc=0.6620, Val Loss=1.5085, lr=0.0100
[02/25 06:39:07] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 48/100, Acc=0.6605, Val Loss=1.5326, lr=0.0100
[02/25 06:39:30] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 49/100, Acc=0.6588, Val Loss=1.5218, lr=0.0100
[02/25 06:39:52] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 50/100, Acc=0.6745, Val Loss=1.4650, lr=0.0100
[02/25 06:40:14] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 51/100, Acc=0.6668, Val Loss=1.4725, lr=0.0100
[02/25 06:40:36] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 52/100, Acc=0.6548, Val Loss=1.5619, lr=0.0100
[02/25 06:40:58] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 53/100, Acc=0.6672, Val Loss=1.4393, lr=0.0100
[02/25 06:41:20] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 54/100, Acc=0.6695, Val Loss=1.4446, lr=0.0100
[02/25 06:41:42] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 55/100, Acc=0.6672, Val Loss=1.4893, lr=0.0100
[02/25 06:42:03] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 56/100, Acc=0.6755, Val Loss=1.4247, lr=0.0100
[02/25 06:42:25] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 57/100, Acc=0.6667, Val Loss=1.4961, lr=0.0100
[02/25 06:42:47] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 58/100, Acc=0.6700, Val Loss=1.4679, lr=0.0100
[02/25 06:43:09] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 59/100, Acc=0.6652, Val Loss=1.4633, lr=0.0100
[02/25 06:43:31] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 60/100, Acc=0.7179, Val Loss=1.2158, lr=0.0010
[02/25 06:43:53] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 61/100, Acc=0.7217, Val Loss=1.2171, lr=0.0010
[02/25 06:44:14] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 62/100, Acc=0.7226, Val Loss=1.2280, lr=0.0010
[02/25 06:44:36] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 63/100, Acc=0.7240, Val Loss=1.2312, lr=0.0010
[02/25 06:44:58] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 64/100, Acc=0.7221, Val Loss=1.2450, lr=0.0010
[02/25 06:45:20] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 65/100, Acc=0.7267, Val Loss=1.2428, lr=0.0010
[02/25 06:45:42] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 66/100, Acc=0.7283, Val Loss=1.2515, lr=0.0010
[02/25 06:46:03] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 67/100, Acc=0.7242, Val Loss=1.2642, lr=0.0010
[02/25 06:46:25] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 68/100, Acc=0.7260, Val Loss=1.2700, lr=0.0010
[02/25 06:46:47] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 69/100, Acc=0.7242, Val Loss=1.2713, lr=0.0010
[02/25 06:47:09] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 70/100, Acc=0.7258, Val Loss=1.2723, lr=0.0010
[02/25 06:47:30] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 71/100, Acc=0.7294, Val Loss=1.2748, lr=0.0010
[02/25 06:47:52] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 72/100, Acc=0.7268, Val Loss=1.2845, lr=0.0010
[02/25 06:48:14] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 73/100, Acc=0.7273, Val Loss=1.2813, lr=0.0010
[02/25 06:48:35] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 74/100, Acc=0.7271, Val Loss=1.2903, lr=0.0010
[02/25 06:48:57] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 75/100, Acc=0.7272, Val Loss=1.2954, lr=0.0010
[02/25 06:49:19] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 76/100, Acc=0.7263, Val Loss=1.2979, lr=0.0010
[02/25 06:49:40] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 77/100, Acc=0.7272, Val Loss=1.2937, lr=0.0010
[02/25 06:50:04] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 78/100, Acc=0.7307, Val Loss=1.3063, lr=0.0010
[02/25 06:50:28] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 79/100, Acc=0.7264, Val Loss=1.3163, lr=0.0010
[02/25 06:50:52] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 80/100, Acc=0.7293, Val Loss=1.3079, lr=0.0001
[02/25 06:51:15] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 81/100, Acc=0.7283, Val Loss=1.3099, lr=0.0001
[02/25 06:51:38] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 82/100, Acc=0.7289, Val Loss=1.3079, lr=0.0001
[02/25 06:52:01] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 83/100, Acc=0.7290, Val Loss=1.3078, lr=0.0001
[02/25 06:52:24] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 84/100, Acc=0.7295, Val Loss=1.3076, lr=0.0001
[02/25 06:52:47] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 85/100, Acc=0.7276, Val Loss=1.3105, lr=0.0001
[02/25 06:53:10] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 86/100, Acc=0.7304, Val Loss=1.3029, lr=0.0001
[02/25 06:53:32] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 87/100, Acc=0.7288, Val Loss=1.3054, lr=0.0001
[02/25 06:53:55] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 88/100, Acc=0.7295, Val Loss=1.3013, lr=0.0001
[02/25 06:54:18] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 89/100, Acc=0.7290, Val Loss=1.3014, lr=0.0001
[02/25 06:54:41] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 90/100, Acc=0.7287, Val Loss=1.3076, lr=0.0001
[02/25 06:55:04] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 91/100, Acc=0.7295, Val Loss=1.3038, lr=0.0001
[02/25 06:55:27] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 92/100, Acc=0.7280, Val Loss=1.3084, lr=0.0001
[02/25 06:55:50] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 93/100, Acc=0.7279, Val Loss=1.3055, lr=0.0001
[02/25 06:56:13] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 94/100, Acc=0.7290, Val Loss=1.3032, lr=0.0001
[02/25 06:56:36] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 95/100, Acc=0.7283, Val Loss=1.3113, lr=0.0001
[02/25 06:57:00] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 96/100, Acc=0.7308, Val Loss=1.3060, lr=0.0001
[02/25 06:57:24] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 97/100, Acc=0.7289, Val Loss=1.3022, lr=0.0001
[02/25 06:57:48] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 98/100, Acc=0.7281, Val Loss=1.3148, lr=0.0001
[02/25 06:58:11] cifar100-global-lamp-3.0-vgg19 INFO: Epoch 99/100, Acc=0.7277, Val Loss=1.3111, lr=0.0001
[02/25 06:58:11] cifar100-global-lamp-3.0-vgg19 INFO: Best Acc=0.7308
[02/25 06:58:11] cifar100-global-lamp-3.0-vgg19 INFO: Params: 3.09 M
[02/25 06:58:11] cifar100-global-lamp-3.0-vgg19 INFO: ops: 170.23 M
[02/25 06:58:14] cifar100-global-lamp-3.0-vgg19 INFO: Acc: 0.7277 Val Loss: 1.3111

