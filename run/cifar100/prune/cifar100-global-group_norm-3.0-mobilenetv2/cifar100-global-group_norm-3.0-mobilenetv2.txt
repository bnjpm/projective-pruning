[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: mode: prune
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: model: mobilenetv2
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: verbose: False
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: dataset: cifar100
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: dataroot: data
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: batch_size: 128
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: total_epochs: 100
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: lr: 0.01
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: restore: run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: output_dir: run/cifar100/prune/cifar100-global-group_norm-3.0-mobilenetv2
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: finetune: True
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: last_epochs: 100
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: reps: 1
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: method: group_norm
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: speed_up: 3.0
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: reg: 1e-05
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: seed: 1
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: global_pruning: True
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: sl_lr: 0.01
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: sl_restore: None
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: iterative_steps: 400
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: logger: <Logger cifar100-global-group_norm-3.0-mobilenetv2 (DEBUG)>
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: device: cuda
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: num_classes: 100
[02/26 20:58:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Loading model from run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/26 20:59:01] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Pruning...
[02/26 20:59:35] cifar100-global-group_norm-3.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(9, 15, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)
      (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(15, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72)
        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 78, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(78, 78, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=78)
        (4): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(78, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 71, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(71, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(71, 71, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=71)
        (4): BatchNorm2d(71, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(71, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 82, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(82, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=82)
        (4): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(82, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 55, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55)
        (4): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(55, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 81, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(81, 81, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=81)
        (4): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(81, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 33, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(33, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=33)
        (4): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(33, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 14, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=14)
        (4): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20)
        (4): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 175, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(175, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(175, 175, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=175)
        (4): BatchNorm2d(175, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(175, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 43, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(43, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=43)
        (4): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(43, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 29, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(29, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=29)
        (4): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(29, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 172, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172)
        (4): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(172, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 94, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=94)
        (4): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(94, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 69, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(69, 69, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=69)
        (4): BatchNorm2d(69, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(69, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 102, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=102)
      (4): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(102, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 100, kernel_size=(1, 1), stride=(1, 1))
)
[02/26 20:59:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Params: 2.37 M => 0.79 M (33.23%)
[02/26 20:59:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: FLOPs: 68.40 M => 22.75 M (33.26%, 3.01X )
[02/26 20:59:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Acc: 0.6699 => 0.6699
[02/26 20:59:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Val Loss: 1.1637 => 1.1637
[02/26 20:59:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Finetuning...
[02/26 21:00:10] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.5853, Val Loss=1.4848, lr=0.0100
[02/26 21:00:40] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.6048, Val Loss=1.3806, lr=0.0100
[02/26 21:01:11] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5913, Val Loss=1.4728, lr=0.0100
[02/26 21:01:42] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.5908, Val Loss=1.4680, lr=0.0100
[02/26 21:02:13] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5928, Val Loss=1.4591, lr=0.0100
[02/26 21:02:44] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.6095, Val Loss=1.3836, lr=0.0100
[02/26 21:03:15] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.5931, Val Loss=1.4542, lr=0.0100
[02/26 21:03:46] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6048, Val Loss=1.4005, lr=0.0100
[02/26 21:04:17] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.5908, Val Loss=1.4661, lr=0.0100
[02/26 21:04:48] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6059, Val Loss=1.3996, lr=0.0100
[02/26 21:05:19] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6093, Val Loss=1.3612, lr=0.0100
[02/26 21:05:50] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6160, Val Loss=1.3713, lr=0.0100
[02/26 21:06:21] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.5865, Val Loss=1.5115, lr=0.0100
[02/26 21:06:52] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.5953, Val Loss=1.4448, lr=0.0100
[02/26 21:07:22] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.6047, Val Loss=1.4071, lr=0.0100
[02/26 21:07:53] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.5983, Val Loss=1.4224, lr=0.0100
[02/26 21:08:24] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.5732, Val Loss=1.5440, lr=0.0100
[02/26 21:08:57] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.5888, Val Loss=1.4698, lr=0.0100
[02/26 21:09:28] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6143, Val Loss=1.3719, lr=0.0100
[02/26 21:10:00] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.5914, Val Loss=1.4753, lr=0.0100
[02/26 21:10:31] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.6000, Val Loss=1.4042, lr=0.0100
[02/26 21:11:02] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.6025, Val Loss=1.4269, lr=0.0100
[02/26 21:11:33] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.6043, Val Loss=1.3972, lr=0.0100
[02/26 21:12:04] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.6060, Val Loss=1.3998, lr=0.0100
[02/26 21:12:35] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.6031, Val Loss=1.4236, lr=0.0100
[02/26 21:13:07] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.5945, Val Loss=1.4632, lr=0.0100
[02/26 21:13:38] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.5902, Val Loss=1.4826, lr=0.0100
[02/26 21:14:09] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.5750, Val Loss=1.5243, lr=0.0100
[02/26 21:14:40] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.6057, Val Loss=1.4065, lr=0.0100
[02/26 21:15:12] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.5985, Val Loss=1.4473, lr=0.0100
[02/26 21:15:44] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.6047, Val Loss=1.4152, lr=0.0100
[02/26 21:16:16] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.5973, Val Loss=1.4490, lr=0.0100
[02/26 21:16:48] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.6040, Val Loss=1.4331, lr=0.0100
[02/26 21:17:20] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.6160, Val Loss=1.3513, lr=0.0100
[02/26 21:17:51] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.6165, Val Loss=1.3838, lr=0.0100
[02/26 21:18:23] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.6228, Val Loss=1.3430, lr=0.0100
[02/26 21:18:55] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.6167, Val Loss=1.3560, lr=0.0100
[02/26 21:19:28] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.6100, Val Loss=1.3798, lr=0.0100
[02/26 21:20:00] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.6179, Val Loss=1.3452, lr=0.0100
[02/26 21:20:32] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.5812, Val Loss=1.5354, lr=0.0100
[02/26 21:21:04] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.6107, Val Loss=1.3675, lr=0.0100
[02/26 21:21:36] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.6144, Val Loss=1.3723, lr=0.0100
[02/26 21:22:09] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.6082, Val Loss=1.3942, lr=0.0100
[02/26 21:22:41] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.6219, Val Loss=1.3554, lr=0.0100
[02/26 21:23:13] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.5903, Val Loss=1.4803, lr=0.0100
[02/26 21:23:45] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.6211, Val Loss=1.3318, lr=0.0100
[02/26 21:24:17] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.6094, Val Loss=1.3860, lr=0.0100
[02/26 21:24:49] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.6224, Val Loss=1.3350, lr=0.0100
[02/26 21:25:20] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.6017, Val Loss=1.4053, lr=0.0100
[02/26 21:25:52] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.6122, Val Loss=1.4108, lr=0.0100
[02/26 21:26:23] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.6232, Val Loss=1.3414, lr=0.0100
[02/26 21:26:55] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.6122, Val Loss=1.3824, lr=0.0100
[02/26 21:27:27] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.6066, Val Loss=1.4210, lr=0.0100
[02/26 21:27:58] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.6162, Val Loss=1.3779, lr=0.0100
[02/26 21:28:30] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.6133, Val Loss=1.3681, lr=0.0100
[02/26 21:29:01] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.6049, Val Loss=1.4063, lr=0.0100
[02/26 21:29:33] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.6204, Val Loss=1.3628, lr=0.0100
[02/26 21:30:05] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.6310, Val Loss=1.3359, lr=0.0100
[02/26 21:30:36] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.6106, Val Loss=1.4005, lr=0.0100
[02/26 21:31:07] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.6091, Val Loss=1.3823, lr=0.0100
[02/26 21:31:39] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.6737, Val Loss=1.1419, lr=0.0010
[02/26 21:32:11] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.6754, Val Loss=1.1419, lr=0.0010
[02/26 21:32:42] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.6760, Val Loss=1.1313, lr=0.0010
[02/26 21:33:13] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.6803, Val Loss=1.1289, lr=0.0010
[02/26 21:33:45] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.6801, Val Loss=1.1295, lr=0.0010
[02/26 21:34:17] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.6786, Val Loss=1.1295, lr=0.0010
[02/26 21:34:48] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.6789, Val Loss=1.1265, lr=0.0010
[02/26 21:35:20] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.6811, Val Loss=1.1279, lr=0.0010
[02/26 21:35:53] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.6801, Val Loss=1.1294, lr=0.0010
[02/26 21:36:25] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.6783, Val Loss=1.1299, lr=0.0010
[02/26 21:36:57] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.6822, Val Loss=1.1322, lr=0.0010
[02/26 21:37:29] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.6835, Val Loss=1.1304, lr=0.0010
[02/26 21:38:00] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.6815, Val Loss=1.1310, lr=0.0010
[02/26 21:38:32] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.6810, Val Loss=1.1331, lr=0.0010
[02/26 21:39:04] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.6815, Val Loss=1.1321, lr=0.0010
[02/26 21:39:36] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.6783, Val Loss=1.1390, lr=0.0010
[02/26 21:40:08] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.6800, Val Loss=1.1360, lr=0.0010
[02/26 21:40:43] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.6799, Val Loss=1.1410, lr=0.0010
[02/26 21:41:14] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.6803, Val Loss=1.1360, lr=0.0010
[02/26 21:41:46] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.6798, Val Loss=1.1413, lr=0.0010
[02/26 21:42:17] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.6840, Val Loss=1.1326, lr=0.0001
[02/26 21:42:49] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.6841, Val Loss=1.1317, lr=0.0001
[02/26 21:43:21] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.6843, Val Loss=1.1312, lr=0.0001
[02/26 21:43:52] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.6840, Val Loss=1.1308, lr=0.0001
[02/26 21:44:24] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.6845, Val Loss=1.1291, lr=0.0001
[02/26 21:44:56] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.6849, Val Loss=1.1316, lr=0.0001
[02/26 21:45:28] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.6835, Val Loss=1.1305, lr=0.0001
[02/26 21:46:00] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.6828, Val Loss=1.1297, lr=0.0001
[02/26 21:46:32] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.6832, Val Loss=1.1308, lr=0.0001
[02/26 21:47:03] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.6834, Val Loss=1.1312, lr=0.0001
[02/26 21:47:35] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.6834, Val Loss=1.1325, lr=0.0001
[02/26 21:48:06] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.6843, Val Loss=1.1313, lr=0.0001
[02/26 21:48:37] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.6813, Val Loss=1.1328, lr=0.0001
[02/26 21:49:08] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.6821, Val Loss=1.1331, lr=0.0001
[02/26 21:49:40] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.6814, Val Loss=1.1337, lr=0.0001
[02/26 21:50:11] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.6822, Val Loss=1.1324, lr=0.0001
[02/26 21:50:42] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.6833, Val Loss=1.1300, lr=0.0001
[02/26 21:51:13] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.6822, Val Loss=1.1324, lr=0.0001
[02/26 21:51:44] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.6832, Val Loss=1.1314, lr=0.0001
[02/26 21:52:15] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.6837, Val Loss=1.1323, lr=0.0001
[02/26 21:52:15] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Best Acc=0.6849
[02/26 21:52:16] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Params: 0.79 M
[02/26 21:52:16] cifar100-global-group_norm-3.0-mobilenetv2 INFO: ops: 22.75 M
[02/26 21:52:19] cifar100-global-group_norm-3.0-mobilenetv2 INFO: Acc: 0.6837 Val Loss: 1.1323

