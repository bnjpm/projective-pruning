[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: mode: prune
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: model: resnet56
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: verbose: False
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: dataset: cifar100
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: dataroot: data
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: batch_size: 128
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: total_epochs: 100
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: lr: 0.01
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-l2-3.0-resnet56
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: finetune: True
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: last_epochs: 100
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: reps: 1
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: method: l2
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: speed_up: 3.0
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: reg: 1e-05
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: seed: 1
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: global_pruning: True
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: sl_restore: None
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: iterative_steps: 400
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: logger: <Logger cifar100-global-l2-3.0-resnet56 (DEBUG)>
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: device: cuda
[02/21 12:30:05] cifar100-global-l2-3.0-resnet56 INFO: num_classes: 100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: mode: prune
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: model: resnet56
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: verbose: False
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: dataset: cifar100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: dataroot: data
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: batch_size: 128
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: total_epochs: 100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: lr: 0.01
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-l2-3.0-resnet56
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: finetune: True
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: last_epochs: 100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: reps: 1
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: method: l2
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: speed_up: 3.0
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: reg: 1e-05
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: seed: 1
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: global_pruning: True
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: sl_restore: None
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: iterative_steps: 400
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: logger: <Logger cifar100-global-l2-3.0-resnet56 (DEBUG)>
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: device: cuda
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: num_classes: 100
[02/21 16:59:28] cifar100-global-l2-3.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 16:59:32] cifar100-global-l2-3.0-resnet56 INFO: Pruning...
[02/21 16:59:48] cifar100-global-l2-3.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(7, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(7, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(7, 9, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(9, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(13, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(9, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(9, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(9, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(9, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(9, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=64, out_features=100, bias=True)
)
[02/21 16:59:51] cifar100-global-l2-3.0-resnet56 INFO: Params: 0.86 M => 0.58 M (66.81%)
[02/21 16:59:51] cifar100-global-l2-3.0-resnet56 INFO: FLOPs: 127.12 M => 42.33 M (33.29%, 3.00X )
[02/21 16:59:51] cifar100-global-l2-3.0-resnet56 INFO: Acc: 0.7269 => 0.0147
[02/21 16:59:51] cifar100-global-l2-3.0-resnet56 INFO: Val Loss: 1.1578 => 15.9639
[02/21 16:59:51] cifar100-global-l2-3.0-resnet56 INFO: Finetuning...
[02/21 17:00:18] cifar100-global-l2-3.0-resnet56 INFO: Epoch 0/100, Acc=0.4913, Val Loss=2.0116, lr=0.0100
[02/21 17:00:46] cifar100-global-l2-3.0-resnet56 INFO: Epoch 1/100, Acc=0.5623, Val Loss=1.6519, lr=0.0100
[02/21 17:01:14] cifar100-global-l2-3.0-resnet56 INFO: Epoch 2/100, Acc=0.5673, Val Loss=1.6267, lr=0.0100
[02/21 17:01:42] cifar100-global-l2-3.0-resnet56 INFO: Epoch 3/100, Acc=0.5766, Val Loss=1.5848, lr=0.0100
[02/21 17:02:09] cifar100-global-l2-3.0-resnet56 INFO: Epoch 4/100, Acc=0.5643, Val Loss=1.6929, lr=0.0100
[02/21 17:02:36] cifar100-global-l2-3.0-resnet56 INFO: Epoch 5/100, Acc=0.5800, Val Loss=1.6234, lr=0.0100
[02/21 17:03:03] cifar100-global-l2-3.0-resnet56 INFO: Epoch 6/100, Acc=0.6083, Val Loss=1.4852, lr=0.0100
[02/21 17:03:31] cifar100-global-l2-3.0-resnet56 INFO: Epoch 7/100, Acc=0.5970, Val Loss=1.4797, lr=0.0100
[02/21 17:03:59] cifar100-global-l2-3.0-resnet56 INFO: Epoch 8/100, Acc=0.6221, Val Loss=1.4453, lr=0.0100
[02/21 17:04:26] cifar100-global-l2-3.0-resnet56 INFO: Epoch 9/100, Acc=0.6100, Val Loss=1.4671, lr=0.0100
[02/21 17:04:54] cifar100-global-l2-3.0-resnet56 INFO: Epoch 10/100, Acc=0.5915, Val Loss=1.5604, lr=0.0100
[02/21 17:05:21] cifar100-global-l2-3.0-resnet56 INFO: Epoch 11/100, Acc=0.5906, Val Loss=1.5863, lr=0.0100
[02/21 17:05:49] cifar100-global-l2-3.0-resnet56 INFO: Epoch 12/100, Acc=0.5997, Val Loss=1.5773, lr=0.0100
[02/21 17:06:17] cifar100-global-l2-3.0-resnet56 INFO: Epoch 13/100, Acc=0.5702, Val Loss=1.7177, lr=0.0100
[02/21 17:06:45] cifar100-global-l2-3.0-resnet56 INFO: Epoch 14/100, Acc=0.6026, Val Loss=1.5082, lr=0.0100
[02/21 17:07:12] cifar100-global-l2-3.0-resnet56 INFO: Epoch 15/100, Acc=0.6024, Val Loss=1.5147, lr=0.0100
[02/21 17:07:40] cifar100-global-l2-3.0-resnet56 INFO: Epoch 16/100, Acc=0.6079, Val Loss=1.4955, lr=0.0100
[02/21 17:08:08] cifar100-global-l2-3.0-resnet56 INFO: Epoch 17/100, Acc=0.6174, Val Loss=1.4872, lr=0.0100
[02/21 17:08:35] cifar100-global-l2-3.0-resnet56 INFO: Epoch 18/100, Acc=0.6223, Val Loss=1.4308, lr=0.0100
[02/21 17:09:03] cifar100-global-l2-3.0-resnet56 INFO: Epoch 19/100, Acc=0.6128, Val Loss=1.4889, lr=0.0100
[02/21 17:09:31] cifar100-global-l2-3.0-resnet56 INFO: Epoch 20/100, Acc=0.6011, Val Loss=1.5725, lr=0.0100
[02/21 17:09:59] cifar100-global-l2-3.0-resnet56 INFO: Epoch 21/100, Acc=0.6153, Val Loss=1.4817, lr=0.0100
[02/21 17:10:27] cifar100-global-l2-3.0-resnet56 INFO: Epoch 22/100, Acc=0.6123, Val Loss=1.4847, lr=0.0100
[02/21 17:10:55] cifar100-global-l2-3.0-resnet56 INFO: Epoch 23/100, Acc=0.6367, Val Loss=1.3602, lr=0.0100
[02/21 17:11:22] cifar100-global-l2-3.0-resnet56 INFO: Epoch 24/100, Acc=0.6202, Val Loss=1.4679, lr=0.0100
[02/21 17:11:50] cifar100-global-l2-3.0-resnet56 INFO: Epoch 25/100, Acc=0.6221, Val Loss=1.4692, lr=0.0100
[02/21 17:12:18] cifar100-global-l2-3.0-resnet56 INFO: Epoch 26/100, Acc=0.6232, Val Loss=1.4745, lr=0.0100
[02/21 17:12:45] cifar100-global-l2-3.0-resnet56 INFO: Epoch 27/100, Acc=0.6140, Val Loss=1.5019, lr=0.0100
[02/21 17:13:13] cifar100-global-l2-3.0-resnet56 INFO: Epoch 28/100, Acc=0.5891, Val Loss=1.6058, lr=0.0100
[02/21 17:13:40] cifar100-global-l2-3.0-resnet56 INFO: Epoch 29/100, Acc=0.6214, Val Loss=1.4759, lr=0.0100
[02/21 17:14:08] cifar100-global-l2-3.0-resnet56 INFO: Epoch 30/100, Acc=0.6293, Val Loss=1.4388, lr=0.0100
[02/21 17:14:35] cifar100-global-l2-3.0-resnet56 INFO: Epoch 31/100, Acc=0.6058, Val Loss=1.5475, lr=0.0100
[02/21 17:15:03] cifar100-global-l2-3.0-resnet56 INFO: Epoch 32/100, Acc=0.6197, Val Loss=1.4988, lr=0.0100
[02/21 17:15:30] cifar100-global-l2-3.0-resnet56 INFO: Epoch 33/100, Acc=0.6250, Val Loss=1.4629, lr=0.0100
[02/21 17:15:58] cifar100-global-l2-3.0-resnet56 INFO: Epoch 34/100, Acc=0.6183, Val Loss=1.4898, lr=0.0100
[02/21 17:16:25] cifar100-global-l2-3.0-resnet56 INFO: Epoch 35/100, Acc=0.6373, Val Loss=1.3774, lr=0.0100
[02/21 17:16:53] cifar100-global-l2-3.0-resnet56 INFO: Epoch 36/100, Acc=0.6222, Val Loss=1.5035, lr=0.0100
[02/21 17:17:20] cifar100-global-l2-3.0-resnet56 INFO: Epoch 37/100, Acc=0.6286, Val Loss=1.4802, lr=0.0100
[02/21 17:17:48] cifar100-global-l2-3.0-resnet56 INFO: Epoch 38/100, Acc=0.6074, Val Loss=1.5682, lr=0.0100
[02/21 17:18:15] cifar100-global-l2-3.0-resnet56 INFO: Epoch 39/100, Acc=0.6243, Val Loss=1.4815, lr=0.0100
[02/21 17:18:43] cifar100-global-l2-3.0-resnet56 INFO: Epoch 40/100, Acc=0.6165, Val Loss=1.5262, lr=0.0100
[02/21 17:19:11] cifar100-global-l2-3.0-resnet56 INFO: Epoch 41/100, Acc=0.6323, Val Loss=1.4361, lr=0.0100
[02/21 17:19:38] cifar100-global-l2-3.0-resnet56 INFO: Epoch 42/100, Acc=0.6169, Val Loss=1.5240, lr=0.0100
[02/21 17:20:06] cifar100-global-l2-3.0-resnet56 INFO: Epoch 43/100, Acc=0.5991, Val Loss=1.6112, lr=0.0100
[02/21 17:20:34] cifar100-global-l2-3.0-resnet56 INFO: Epoch 44/100, Acc=0.6235, Val Loss=1.4696, lr=0.0100
[02/21 17:21:02] cifar100-global-l2-3.0-resnet56 INFO: Epoch 45/100, Acc=0.6115, Val Loss=1.5566, lr=0.0100
[02/21 17:21:30] cifar100-global-l2-3.0-resnet56 INFO: Epoch 46/100, Acc=0.6273, Val Loss=1.4796, lr=0.0100
[02/21 17:21:57] cifar100-global-l2-3.0-resnet56 INFO: Epoch 47/100, Acc=0.6152, Val Loss=1.5455, lr=0.0100
[02/21 17:22:25] cifar100-global-l2-3.0-resnet56 INFO: Epoch 48/100, Acc=0.6251, Val Loss=1.4844, lr=0.0100
[02/21 17:22:52] cifar100-global-l2-3.0-resnet56 INFO: Epoch 49/100, Acc=0.5812, Val Loss=1.7383, lr=0.0100
[02/21 17:23:19] cifar100-global-l2-3.0-resnet56 INFO: Epoch 50/100, Acc=0.6296, Val Loss=1.4703, lr=0.0100
[02/21 17:23:46] cifar100-global-l2-3.0-resnet56 INFO: Epoch 51/100, Acc=0.6230, Val Loss=1.4522, lr=0.0100
[02/21 17:24:14] cifar100-global-l2-3.0-resnet56 INFO: Epoch 52/100, Acc=0.6210, Val Loss=1.4825, lr=0.0100
[02/21 17:24:41] cifar100-global-l2-3.0-resnet56 INFO: Epoch 53/100, Acc=0.6200, Val Loss=1.5059, lr=0.0100
[02/21 17:25:08] cifar100-global-l2-3.0-resnet56 INFO: Epoch 54/100, Acc=0.6334, Val Loss=1.4283, lr=0.0100
[02/21 17:25:36] cifar100-global-l2-3.0-resnet56 INFO: Epoch 55/100, Acc=0.6298, Val Loss=1.4514, lr=0.0100
[02/21 17:26:03] cifar100-global-l2-3.0-resnet56 INFO: Epoch 56/100, Acc=0.6110, Val Loss=1.5243, lr=0.0100
[02/21 17:26:30] cifar100-global-l2-3.0-resnet56 INFO: Epoch 57/100, Acc=0.6278, Val Loss=1.4733, lr=0.0100
[02/21 17:26:57] cifar100-global-l2-3.0-resnet56 INFO: Epoch 58/100, Acc=0.6234, Val Loss=1.5222, lr=0.0100
[02/21 17:27:25] cifar100-global-l2-3.0-resnet56 INFO: Epoch 59/100, Acc=0.6239, Val Loss=1.4950, lr=0.0100
[02/21 17:27:52] cifar100-global-l2-3.0-resnet56 INFO: Epoch 60/100, Acc=0.6864, Val Loss=1.1895, lr=0.0010
[02/21 17:28:19] cifar100-global-l2-3.0-resnet56 INFO: Epoch 61/100, Acc=0.6880, Val Loss=1.1978, lr=0.0010
[02/21 17:28:47] cifar100-global-l2-3.0-resnet56 INFO: Epoch 62/100, Acc=0.6890, Val Loss=1.1922, lr=0.0010
[02/21 17:29:14] cifar100-global-l2-3.0-resnet56 INFO: Epoch 63/100, Acc=0.6900, Val Loss=1.2013, lr=0.0010
[02/21 17:29:42] cifar100-global-l2-3.0-resnet56 INFO: Epoch 64/100, Acc=0.6886, Val Loss=1.2083, lr=0.0010
[02/21 17:30:09] cifar100-global-l2-3.0-resnet56 INFO: Epoch 65/100, Acc=0.6870, Val Loss=1.2157, lr=0.0010
[02/21 17:30:36] cifar100-global-l2-3.0-resnet56 INFO: Epoch 66/100, Acc=0.6886, Val Loss=1.2226, lr=0.0010
[02/21 17:31:04] cifar100-global-l2-3.0-resnet56 INFO: Epoch 67/100, Acc=0.6866, Val Loss=1.2297, lr=0.0010
[02/21 17:31:31] cifar100-global-l2-3.0-resnet56 INFO: Epoch 68/100, Acc=0.6851, Val Loss=1.2363, lr=0.0010
[02/21 17:31:59] cifar100-global-l2-3.0-resnet56 INFO: Epoch 69/100, Acc=0.6832, Val Loss=1.2440, lr=0.0010
[02/21 17:32:26] cifar100-global-l2-3.0-resnet56 INFO: Epoch 70/100, Acc=0.6891, Val Loss=1.2440, lr=0.0010
[02/21 17:32:54] cifar100-global-l2-3.0-resnet56 INFO: Epoch 71/100, Acc=0.6876, Val Loss=1.2502, lr=0.0010
[02/21 17:33:21] cifar100-global-l2-3.0-resnet56 INFO: Epoch 72/100, Acc=0.6880, Val Loss=1.2542, lr=0.0010
[02/21 17:33:49] cifar100-global-l2-3.0-resnet56 INFO: Epoch 73/100, Acc=0.6857, Val Loss=1.2562, lr=0.0010
[02/21 17:34:16] cifar100-global-l2-3.0-resnet56 INFO: Epoch 74/100, Acc=0.6863, Val Loss=1.2613, lr=0.0010
[02/21 17:34:44] cifar100-global-l2-3.0-resnet56 INFO: Epoch 75/100, Acc=0.6889, Val Loss=1.2603, lr=0.0010
[02/21 17:35:11] cifar100-global-l2-3.0-resnet56 INFO: Epoch 76/100, Acc=0.6840, Val Loss=1.2625, lr=0.0010
[02/21 17:35:39] cifar100-global-l2-3.0-resnet56 INFO: Epoch 77/100, Acc=0.6845, Val Loss=1.2791, lr=0.0010
[02/21 17:36:06] cifar100-global-l2-3.0-resnet56 INFO: Epoch 78/100, Acc=0.6857, Val Loss=1.2785, lr=0.0010
[02/21 17:36:34] cifar100-global-l2-3.0-resnet56 INFO: Epoch 79/100, Acc=0.6842, Val Loss=1.2825, lr=0.0010
[02/21 17:37:01] cifar100-global-l2-3.0-resnet56 INFO: Epoch 80/100, Acc=0.6864, Val Loss=1.2720, lr=0.0001
[02/21 17:37:29] cifar100-global-l2-3.0-resnet56 INFO: Epoch 81/100, Acc=0.6881, Val Loss=1.2686, lr=0.0001
[02/21 17:37:56] cifar100-global-l2-3.0-resnet56 INFO: Epoch 82/100, Acc=0.6885, Val Loss=1.2690, lr=0.0001
[02/21 17:38:24] cifar100-global-l2-3.0-resnet56 INFO: Epoch 83/100, Acc=0.6876, Val Loss=1.2713, lr=0.0001
[02/21 17:38:51] cifar100-global-l2-3.0-resnet56 INFO: Epoch 84/100, Acc=0.6881, Val Loss=1.2770, lr=0.0001
[02/21 17:39:19] cifar100-global-l2-3.0-resnet56 INFO: Epoch 85/100, Acc=0.6870, Val Loss=1.2666, lr=0.0001
[02/21 17:39:47] cifar100-global-l2-3.0-resnet56 INFO: Epoch 86/100, Acc=0.6888, Val Loss=1.2765, lr=0.0001
[02/21 17:40:14] cifar100-global-l2-3.0-resnet56 INFO: Epoch 87/100, Acc=0.6874, Val Loss=1.2769, lr=0.0001
[02/21 17:40:41] cifar100-global-l2-3.0-resnet56 INFO: Epoch 88/100, Acc=0.6886, Val Loss=1.2702, lr=0.0001
[02/21 17:41:09] cifar100-global-l2-3.0-resnet56 INFO: Epoch 89/100, Acc=0.6894, Val Loss=1.2732, lr=0.0001
[02/21 17:41:37] cifar100-global-l2-3.0-resnet56 INFO: Epoch 90/100, Acc=0.6888, Val Loss=1.2689, lr=0.0001
[02/21 17:42:04] cifar100-global-l2-3.0-resnet56 INFO: Epoch 91/100, Acc=0.6857, Val Loss=1.2792, lr=0.0001
[02/21 17:42:32] cifar100-global-l2-3.0-resnet56 INFO: Epoch 92/100, Acc=0.6881, Val Loss=1.2718, lr=0.0001
[02/21 17:42:59] cifar100-global-l2-3.0-resnet56 INFO: Epoch 93/100, Acc=0.6886, Val Loss=1.2758, lr=0.0001
[02/21 17:43:27] cifar100-global-l2-3.0-resnet56 INFO: Epoch 94/100, Acc=0.6891, Val Loss=1.2729, lr=0.0001
[02/21 17:43:55] cifar100-global-l2-3.0-resnet56 INFO: Epoch 95/100, Acc=0.6860, Val Loss=1.2766, lr=0.0001
[02/21 17:44:22] cifar100-global-l2-3.0-resnet56 INFO: Epoch 96/100, Acc=0.6847, Val Loss=1.2823, lr=0.0001
[02/21 17:44:50] cifar100-global-l2-3.0-resnet56 INFO: Epoch 97/100, Acc=0.6879, Val Loss=1.2785, lr=0.0001
[02/21 17:45:18] cifar100-global-l2-3.0-resnet56 INFO: Epoch 98/100, Acc=0.6880, Val Loss=1.2751, lr=0.0001
[02/21 17:45:46] cifar100-global-l2-3.0-resnet56 INFO: Epoch 99/100, Acc=0.6856, Val Loss=1.2770, lr=0.0001
[02/21 17:45:46] cifar100-global-l2-3.0-resnet56 INFO: Best Acc=0.6900
[02/21 17:45:46] cifar100-global-l2-3.0-resnet56 INFO: Params: 0.58 M
[02/21 17:45:46] cifar100-global-l2-3.0-resnet56 INFO: ops: 42.33 M
[02/21 17:45:49] cifar100-global-l2-3.0-resnet56 INFO: Acc: 0.6856 Val Loss: 1.2770

