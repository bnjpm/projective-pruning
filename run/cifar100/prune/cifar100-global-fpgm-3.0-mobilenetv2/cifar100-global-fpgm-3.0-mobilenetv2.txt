[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: mode: prune
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: model: mobilenetv2
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: verbose: False
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: dataset: cifar100
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: dataroot: data
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: batch_size: 128
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: total_epochs: 100
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: lr: 0.01
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: restore: run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: output_dir: run/cifar100/prune/cifar100-global-fpgm-3.0-mobilenetv2
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: finetune: True
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: last_epochs: 100
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: reps: 1
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: method: fpgm
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: speed_up: 3.0
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: reg: 1e-05
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: seed: 1
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: global_pruning: True
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: sl_lr: 0.01
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: sl_restore: None
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: iterative_steps: 400
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: logger: <Logger cifar100-global-fpgm-3.0-mobilenetv2 (DEBUG)>
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: device: cuda
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: num_classes: 100
[02/26 17:21:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Loading model from run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/26 17:21:34] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Pruning...
[02/26 17:21:59] cifar100-global-fpgm-3.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(9, 15, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)
      (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(15, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 73, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(73, 73, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=73)
        (4): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(73, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 84, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84)
        (4): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(84, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 76, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(76, 76, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=76)
        (4): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(76, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 85, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(85, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=85)
        (4): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(85, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 61, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(61, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=61)
        (4): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(61, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 88, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=88)
        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(88, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 38, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=38)
        (4): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(38, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)
        (4): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13)
        (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 188, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(188, 188, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=188)
        (4): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(188, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 33, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(33, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=33)
        (4): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(33, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 15, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)
        (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(15, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 189, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(189, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(189, 189, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=189)
        (4): BatchNorm2d(189, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(189, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 102, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=102)
        (4): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(102, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 45, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45)
        (4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(45, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 110, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(110, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=110)
      (4): BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(110, 283, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(283, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(283, 1278, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1278, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1278, 100, kernel_size=(1, 1), stride=(1, 1))
)
[02/26 17:22:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Params: 2.37 M => 0.74 M (31.09%)
[02/26 17:22:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: FLOPs: 68.40 M => 21.73 M (31.77%, 3.15X )
[02/26 17:22:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Acc: 0.6699 => 0.6671
[02/26 17:22:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Val Loss: 1.1637 => 1.1706
[02/26 17:22:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Finetuning...
[02/26 17:22:33] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.5948, Val Loss=1.4458, lr=0.0100
[02/26 17:23:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.5989, Val Loss=1.4451, lr=0.0100
[02/26 17:23:33] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5927, Val Loss=1.4607, lr=0.0100
[02/26 17:24:04] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.6015, Val Loss=1.4087, lr=0.0100
[02/26 17:24:35] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5831, Val Loss=1.5054, lr=0.0100
[02/26 17:25:06] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.5917, Val Loss=1.4236, lr=0.0100
[02/26 17:25:36] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.5992, Val Loss=1.4206, lr=0.0100
[02/26 17:26:07] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.5969, Val Loss=1.4277, lr=0.0100
[02/26 17:26:37] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.6004, Val Loss=1.4093, lr=0.0100
[02/26 17:27:08] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6092, Val Loss=1.3817, lr=0.0100
[02/26 17:27:39] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6100, Val Loss=1.3818, lr=0.0100
[02/26 17:28:09] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6178, Val Loss=1.3778, lr=0.0100
[02/26 17:28:40] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.6036, Val Loss=1.4219, lr=0.0100
[02/26 17:29:10] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.5790, Val Loss=1.5157, lr=0.0100
[02/26 17:29:41] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.5886, Val Loss=1.4660, lr=0.0100
[02/26 17:30:11] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.6077, Val Loss=1.3858, lr=0.0100
[02/26 17:30:42] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.6001, Val Loss=1.4268, lr=0.0100
[02/26 17:31:12] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.5909, Val Loss=1.4486, lr=0.0100
[02/26 17:31:42] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6102, Val Loss=1.3840, lr=0.0100
[02/26 17:32:13] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.5983, Val Loss=1.4347, lr=0.0100
[02/26 17:32:44] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.6143, Val Loss=1.3615, lr=0.0100
[02/26 17:33:14] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.5979, Val Loss=1.4419, lr=0.0100
[02/26 17:33:45] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.6170, Val Loss=1.3535, lr=0.0100
[02/26 17:34:15] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.6020, Val Loss=1.4195, lr=0.0100
[02/26 17:34:46] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.5956, Val Loss=1.4611, lr=0.0100
[02/26 17:35:17] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.5931, Val Loss=1.4439, lr=0.0100
[02/26 17:35:47] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.5843, Val Loss=1.5370, lr=0.0100
[02/26 17:36:18] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.6047, Val Loss=1.4019, lr=0.0100
[02/26 17:36:49] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.6243, Val Loss=1.3347, lr=0.0100
[02/26 17:37:20] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.6113, Val Loss=1.3804, lr=0.0100
[02/26 17:37:50] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.6077, Val Loss=1.4062, lr=0.0100
[02/26 17:38:20] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.6182, Val Loss=1.3592, lr=0.0100
[02/26 17:38:51] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.5965, Val Loss=1.4455, lr=0.0100
[02/26 17:39:22] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.6047, Val Loss=1.4204, lr=0.0100
[02/26 17:39:52] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.6165, Val Loss=1.3705, lr=0.0100
[02/26 17:40:23] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.6213, Val Loss=1.3554, lr=0.0100
[02/26 17:40:53] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.6066, Val Loss=1.3996, lr=0.0100
[02/26 17:41:24] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.6089, Val Loss=1.3873, lr=0.0100
[02/26 17:41:54] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.6203, Val Loss=1.3304, lr=0.0100
[02/26 17:42:25] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.6029, Val Loss=1.4286, lr=0.0100
[02/26 17:42:56] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.6157, Val Loss=1.3778, lr=0.0100
[02/26 17:43:26] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.6254, Val Loss=1.3172, lr=0.0100
[02/26 17:43:57] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.6033, Val Loss=1.4167, lr=0.0100
[02/26 17:44:27] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.6201, Val Loss=1.3438, lr=0.0100
[02/26 17:44:58] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.5908, Val Loss=1.4927, lr=0.0100
[02/26 17:45:28] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.6143, Val Loss=1.3611, lr=0.0100
[02/26 17:45:59] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.5942, Val Loss=1.4568, lr=0.0100
[02/26 17:46:29] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.6095, Val Loss=1.4041, lr=0.0100
[02/26 17:46:59] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.6186, Val Loss=1.3383, lr=0.0100
[02/26 17:47:30] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.6103, Val Loss=1.3990, lr=0.0100
[02/26 17:48:00] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.6286, Val Loss=1.3290, lr=0.0100
[02/26 17:48:31] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.6068, Val Loss=1.3829, lr=0.0100
[02/26 17:49:02] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.6005, Val Loss=1.4550, lr=0.0100
[02/26 17:49:32] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.6189, Val Loss=1.3818, lr=0.0100
[02/26 17:50:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.6204, Val Loss=1.3362, lr=0.0100
[02/26 17:50:34] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.5986, Val Loss=1.4292, lr=0.0100
[02/26 17:51:05] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.6168, Val Loss=1.3462, lr=0.0100
[02/26 17:51:35] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.6347, Val Loss=1.3133, lr=0.0100
[02/26 17:52:07] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.6083, Val Loss=1.4115, lr=0.0100
[02/26 17:52:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.6037, Val Loss=1.3988, lr=0.0100
[02/26 17:53:09] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.6776, Val Loss=1.1386, lr=0.0010
[02/26 17:53:40] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.6768, Val Loss=1.1337, lr=0.0010
[02/26 17:54:11] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.6812, Val Loss=1.1208, lr=0.0010
[02/26 17:54:42] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.6797, Val Loss=1.1231, lr=0.0010
[02/26 17:55:13] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.6821, Val Loss=1.1209, lr=0.0010
[02/26 17:55:45] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.6814, Val Loss=1.1216, lr=0.0010
[02/26 17:56:16] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.6830, Val Loss=1.1160, lr=0.0010
[02/26 17:56:52] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.6797, Val Loss=1.1207, lr=0.0010
[02/26 17:57:29] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.6822, Val Loss=1.1218, lr=0.0010
[02/26 17:58:02] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.6818, Val Loss=1.1211, lr=0.0010
[02/26 17:58:33] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.6813, Val Loss=1.1238, lr=0.0010
[02/26 17:59:04] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.6826, Val Loss=1.1241, lr=0.0010
[02/26 17:59:36] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.6785, Val Loss=1.1249, lr=0.0010
[02/26 18:00:07] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.6800, Val Loss=1.1266, lr=0.0010
[02/26 18:00:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.6789, Val Loss=1.1341, lr=0.0010
[02/26 18:01:09] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.6801, Val Loss=1.1329, lr=0.0010
[02/26 18:01:40] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.6802, Val Loss=1.1263, lr=0.0010
[02/26 18:02:11] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.6783, Val Loss=1.1296, lr=0.0010
[02/26 18:02:43] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.6808, Val Loss=1.1311, lr=0.0010
[02/26 18:03:14] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.6762, Val Loss=1.1349, lr=0.0010
[02/26 18:03:45] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.6826, Val Loss=1.1236, lr=0.0001
[02/26 18:04:16] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.6827, Val Loss=1.1230, lr=0.0001
[02/26 18:04:47] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.6840, Val Loss=1.1236, lr=0.0001
[02/26 18:05:18] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.6834, Val Loss=1.1236, lr=0.0001
[02/26 18:05:49] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.6848, Val Loss=1.1210, lr=0.0001
[02/26 18:06:20] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.6839, Val Loss=1.1238, lr=0.0001
[02/26 18:06:51] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.6818, Val Loss=1.1221, lr=0.0001
[02/26 18:07:22] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.6844, Val Loss=1.1211, lr=0.0001
[02/26 18:07:53] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.6819, Val Loss=1.1232, lr=0.0001
[02/26 18:08:24] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.6837, Val Loss=1.1237, lr=0.0001
[02/26 18:08:55] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.6825, Val Loss=1.1236, lr=0.0001
[02/26 18:09:26] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.6819, Val Loss=1.1249, lr=0.0001
[02/26 18:09:57] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.6828, Val Loss=1.1244, lr=0.0001
[02/26 18:10:28] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.6834, Val Loss=1.1245, lr=0.0001
[02/26 18:11:00] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.6836, Val Loss=1.1244, lr=0.0001
[02/26 18:11:31] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.6831, Val Loss=1.1246, lr=0.0001
[02/26 18:12:03] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.6830, Val Loss=1.1242, lr=0.0001
[02/26 18:12:35] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.6838, Val Loss=1.1262, lr=0.0001
[02/26 18:13:06] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.6831, Val Loss=1.1249, lr=0.0001
[02/26 18:13:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.6818, Val Loss=1.1261, lr=0.0001
[02/26 18:13:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Best Acc=0.6848
[02/26 18:13:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Params: 0.74 M
[02/26 18:13:38] cifar100-global-fpgm-3.0-mobilenetv2 INFO: ops: 21.73 M
[02/26 18:13:41] cifar100-global-fpgm-3.0-mobilenetv2 INFO: Acc: 0.6818 Val Loss: 1.1261

