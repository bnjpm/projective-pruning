[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: mode: prune
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: model: resnet56
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: verbose: False
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: dataset: cifar100
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: dataroot: data
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: batch_size: 128
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: total_epochs: 100
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: lr: 0.01
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-random-3.0-resnet56
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: finetune: True
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: last_epochs: 100
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: reps: 1
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: method: random
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: speed_up: 3.0
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: reg: 1e-05
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: seed: 1
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: global_pruning: True
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: sl_restore: None
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: iterative_steps: 400
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: logger: <Logger cifar100-global-random-3.0-resnet56 (DEBUG)>
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: device: cuda
[02/21 12:29:54] cifar100-global-random-3.0-resnet56 INFO: num_classes: 100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: mode: prune
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: model: resnet56
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: verbose: False
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: dataset: cifar100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: dataroot: data
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: batch_size: 128
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: total_epochs: 100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: lr: 0.01
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-random-3.0-resnet56
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: finetune: True
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: last_epochs: 100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: reps: 1
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: method: random
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: speed_up: 3.0
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: reg: 1e-05
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: seed: 1
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: global_pruning: True
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: sl_restore: None
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: iterative_steps: 400
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: logger: <Logger cifar100-global-random-3.0-resnet56 (DEBUG)>
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: device: cuda
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: num_classes: 100
[02/21 16:13:58] cifar100-global-random-3.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 16:14:02] cifar100-global-random-3.0-resnet56 INFO: Pruning...
[02/21 16:14:10] cifar100-global-random-3.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(2, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(2, 18, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(18, 50, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(18, 50, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=50, out_features=100, bias=True)
)
[02/21 16:14:13] cifar100-global-random-3.0-resnet56 INFO: Params: 0.86 M => 0.45 M (52.21%)
[02/21 16:14:13] cifar100-global-random-3.0-resnet56 INFO: FLOPs: 127.12 M => 39.03 M (30.70%, 3.26X )
[02/21 16:14:13] cifar100-global-random-3.0-resnet56 INFO: Acc: 0.7269 => 0.0100
[02/21 16:14:13] cifar100-global-random-3.0-resnet56 INFO: Val Loss: 1.1578 => 22.4019
[02/21 16:14:13] cifar100-global-random-3.0-resnet56 INFO: Finetuning...
[02/21 16:14:40] cifar100-global-random-3.0-resnet56 INFO: Epoch 0/100, Acc=0.2287, Val Loss=3.2025, lr=0.0100
[02/21 16:15:07] cifar100-global-random-3.0-resnet56 INFO: Epoch 1/100, Acc=0.3757, Val Loss=2.4780, lr=0.0100
[02/21 16:15:34] cifar100-global-random-3.0-resnet56 INFO: Epoch 2/100, Acc=0.4216, Val Loss=2.2664, lr=0.0100
[02/21 16:16:01] cifar100-global-random-3.0-resnet56 INFO: Epoch 3/100, Acc=0.4531, Val Loss=2.1542, lr=0.0100
[02/21 16:16:28] cifar100-global-random-3.0-resnet56 INFO: Epoch 4/100, Acc=0.4808, Val Loss=1.9509, lr=0.0100
[02/21 16:16:55] cifar100-global-random-3.0-resnet56 INFO: Epoch 5/100, Acc=0.4835, Val Loss=2.0132, lr=0.0100
[02/21 16:17:22] cifar100-global-random-3.0-resnet56 INFO: Epoch 6/100, Acc=0.5174, Val Loss=1.8325, lr=0.0100
[02/21 16:17:49] cifar100-global-random-3.0-resnet56 INFO: Epoch 7/100, Acc=0.5281, Val Loss=1.7575, lr=0.0100
[02/21 16:18:16] cifar100-global-random-3.0-resnet56 INFO: Epoch 8/100, Acc=0.5349, Val Loss=1.7336, lr=0.0100
[02/21 16:18:43] cifar100-global-random-3.0-resnet56 INFO: Epoch 9/100, Acc=0.4705, Val Loss=2.1237, lr=0.0100
[02/21 16:19:10] cifar100-global-random-3.0-resnet56 INFO: Epoch 10/100, Acc=0.5142, Val Loss=1.8513, lr=0.0100
[02/21 16:19:37] cifar100-global-random-3.0-resnet56 INFO: Epoch 11/100, Acc=0.5364, Val Loss=1.7633, lr=0.0100
[02/21 16:20:04] cifar100-global-random-3.0-resnet56 INFO: Epoch 12/100, Acc=0.5703, Val Loss=1.5768, lr=0.0100
[02/21 16:20:31] cifar100-global-random-3.0-resnet56 INFO: Epoch 13/100, Acc=0.5477, Val Loss=1.7237, lr=0.0100
[02/21 16:20:58] cifar100-global-random-3.0-resnet56 INFO: Epoch 14/100, Acc=0.5303, Val Loss=1.7852, lr=0.0100
[02/21 16:21:25] cifar100-global-random-3.0-resnet56 INFO: Epoch 15/100, Acc=0.5563, Val Loss=1.6896, lr=0.0100
[02/21 16:21:52] cifar100-global-random-3.0-resnet56 INFO: Epoch 16/100, Acc=0.5411, Val Loss=1.7413, lr=0.0100
[02/21 16:22:19] cifar100-global-random-3.0-resnet56 INFO: Epoch 17/100, Acc=0.5653, Val Loss=1.6248, lr=0.0100
[02/21 16:22:46] cifar100-global-random-3.0-resnet56 INFO: Epoch 18/100, Acc=0.5829, Val Loss=1.5550, lr=0.0100
[02/21 16:23:13] cifar100-global-random-3.0-resnet56 INFO: Epoch 19/100, Acc=0.5712, Val Loss=1.5869, lr=0.0100
[02/21 16:23:40] cifar100-global-random-3.0-resnet56 INFO: Epoch 20/100, Acc=0.5683, Val Loss=1.6239, lr=0.0100
[02/21 16:24:07] cifar100-global-random-3.0-resnet56 INFO: Epoch 21/100, Acc=0.5584, Val Loss=1.6985, lr=0.0100
[02/21 16:24:34] cifar100-global-random-3.0-resnet56 INFO: Epoch 22/100, Acc=0.5732, Val Loss=1.6040, lr=0.0100
[02/21 16:25:01] cifar100-global-random-3.0-resnet56 INFO: Epoch 23/100, Acc=0.5706, Val Loss=1.6302, lr=0.0100
[02/21 16:25:28] cifar100-global-random-3.0-resnet56 INFO: Epoch 24/100, Acc=0.5840, Val Loss=1.5687, lr=0.0100
[02/21 16:25:55] cifar100-global-random-3.0-resnet56 INFO: Epoch 25/100, Acc=0.5838, Val Loss=1.5768, lr=0.0100
[02/21 16:26:22] cifar100-global-random-3.0-resnet56 INFO: Epoch 26/100, Acc=0.6021, Val Loss=1.4972, lr=0.0100
[02/21 16:26:49] cifar100-global-random-3.0-resnet56 INFO: Epoch 27/100, Acc=0.5887, Val Loss=1.5469, lr=0.0100
[02/21 16:27:16] cifar100-global-random-3.0-resnet56 INFO: Epoch 28/100, Acc=0.5547, Val Loss=1.7302, lr=0.0100
[02/21 16:27:43] cifar100-global-random-3.0-resnet56 INFO: Epoch 29/100, Acc=0.5685, Val Loss=1.7053, lr=0.0100
[02/21 16:28:10] cifar100-global-random-3.0-resnet56 INFO: Epoch 30/100, Acc=0.5715, Val Loss=1.6799, lr=0.0100
[02/21 16:28:37] cifar100-global-random-3.0-resnet56 INFO: Epoch 31/100, Acc=0.5561, Val Loss=1.6785, lr=0.0100
[02/21 16:29:04] cifar100-global-random-3.0-resnet56 INFO: Epoch 32/100, Acc=0.5482, Val Loss=1.7748, lr=0.0100
[02/21 16:29:31] cifar100-global-random-3.0-resnet56 INFO: Epoch 33/100, Acc=0.5750, Val Loss=1.6402, lr=0.0100
[02/21 16:29:58] cifar100-global-random-3.0-resnet56 INFO: Epoch 34/100, Acc=0.5912, Val Loss=1.5652, lr=0.0100
[02/21 16:30:25] cifar100-global-random-3.0-resnet56 INFO: Epoch 35/100, Acc=0.5793, Val Loss=1.6233, lr=0.0100
[02/21 16:30:52] cifar100-global-random-3.0-resnet56 INFO: Epoch 36/100, Acc=0.5554, Val Loss=1.7909, lr=0.0100
[02/21 16:31:20] cifar100-global-random-3.0-resnet56 INFO: Epoch 37/100, Acc=0.5809, Val Loss=1.6093, lr=0.0100
[02/21 16:31:47] cifar100-global-random-3.0-resnet56 INFO: Epoch 38/100, Acc=0.5813, Val Loss=1.6087, lr=0.0100
[02/21 16:32:14] cifar100-global-random-3.0-resnet56 INFO: Epoch 39/100, Acc=0.5984, Val Loss=1.5184, lr=0.0100
[02/21 16:32:41] cifar100-global-random-3.0-resnet56 INFO: Epoch 40/100, Acc=0.5891, Val Loss=1.5407, lr=0.0100
[02/21 16:33:08] cifar100-global-random-3.0-resnet56 INFO: Epoch 41/100, Acc=0.5983, Val Loss=1.5403, lr=0.0100
[02/21 16:33:35] cifar100-global-random-3.0-resnet56 INFO: Epoch 42/100, Acc=0.5728, Val Loss=1.6555, lr=0.0100
[02/21 16:34:02] cifar100-global-random-3.0-resnet56 INFO: Epoch 43/100, Acc=0.5988, Val Loss=1.5201, lr=0.0100
[02/21 16:34:29] cifar100-global-random-3.0-resnet56 INFO: Epoch 44/100, Acc=0.6036, Val Loss=1.4982, lr=0.0100
[02/21 16:34:56] cifar100-global-random-3.0-resnet56 INFO: Epoch 45/100, Acc=0.5856, Val Loss=1.5813, lr=0.0100
[02/21 16:35:23] cifar100-global-random-3.0-resnet56 INFO: Epoch 46/100, Acc=0.5994, Val Loss=1.5295, lr=0.0100
[02/21 16:35:50] cifar100-global-random-3.0-resnet56 INFO: Epoch 47/100, Acc=0.5947, Val Loss=1.5456, lr=0.0100
[02/21 16:36:17] cifar100-global-random-3.0-resnet56 INFO: Epoch 48/100, Acc=0.5931, Val Loss=1.5765, lr=0.0100
[02/21 16:36:45] cifar100-global-random-3.0-resnet56 INFO: Epoch 49/100, Acc=0.5873, Val Loss=1.5814, lr=0.0100
[02/21 16:37:12] cifar100-global-random-3.0-resnet56 INFO: Epoch 50/100, Acc=0.5755, Val Loss=1.6957, lr=0.0100
[02/21 16:37:39] cifar100-global-random-3.0-resnet56 INFO: Epoch 51/100, Acc=0.5615, Val Loss=1.7325, lr=0.0100
[02/21 16:38:07] cifar100-global-random-3.0-resnet56 INFO: Epoch 52/100, Acc=0.5561, Val Loss=1.8330, lr=0.0100
[02/21 16:38:34] cifar100-global-random-3.0-resnet56 INFO: Epoch 53/100, Acc=0.5983, Val Loss=1.5450, lr=0.0100
[02/21 16:39:02] cifar100-global-random-3.0-resnet56 INFO: Epoch 54/100, Acc=0.5920, Val Loss=1.6316, lr=0.0100
[02/21 16:39:29] cifar100-global-random-3.0-resnet56 INFO: Epoch 55/100, Acc=0.5949, Val Loss=1.5747, lr=0.0100
[02/21 16:39:56] cifar100-global-random-3.0-resnet56 INFO: Epoch 56/100, Acc=0.5945, Val Loss=1.5721, lr=0.0100
[02/21 16:40:24] cifar100-global-random-3.0-resnet56 INFO: Epoch 57/100, Acc=0.5809, Val Loss=1.7018, lr=0.0100
[02/21 16:40:51] cifar100-global-random-3.0-resnet56 INFO: Epoch 58/100, Acc=0.6016, Val Loss=1.5554, lr=0.0100
[02/21 16:41:18] cifar100-global-random-3.0-resnet56 INFO: Epoch 59/100, Acc=0.5912, Val Loss=1.5736, lr=0.0100
[02/21 16:41:46] cifar100-global-random-3.0-resnet56 INFO: Epoch 60/100, Acc=0.6617, Val Loss=1.2571, lr=0.0010
[02/21 16:42:13] cifar100-global-random-3.0-resnet56 INFO: Epoch 61/100, Acc=0.6598, Val Loss=1.2537, lr=0.0010
[02/21 16:42:40] cifar100-global-random-3.0-resnet56 INFO: Epoch 62/100, Acc=0.6651, Val Loss=1.2500, lr=0.0010
[02/21 16:43:08] cifar100-global-random-3.0-resnet56 INFO: Epoch 63/100, Acc=0.6668, Val Loss=1.2488, lr=0.0010
[02/21 16:43:35] cifar100-global-random-3.0-resnet56 INFO: Epoch 64/100, Acc=0.6658, Val Loss=1.2593, lr=0.0010
[02/21 16:44:01] cifar100-global-random-3.0-resnet56 INFO: Epoch 65/100, Acc=0.6666, Val Loss=1.2672, lr=0.0010
[02/21 16:44:28] cifar100-global-random-3.0-resnet56 INFO: Epoch 66/100, Acc=0.6661, Val Loss=1.2756, lr=0.0010
[02/21 16:44:55] cifar100-global-random-3.0-resnet56 INFO: Epoch 67/100, Acc=0.6647, Val Loss=1.2678, lr=0.0010
[02/21 16:45:22] cifar100-global-random-3.0-resnet56 INFO: Epoch 68/100, Acc=0.6675, Val Loss=1.2694, lr=0.0010
[02/21 16:45:49] cifar100-global-random-3.0-resnet56 INFO: Epoch 69/100, Acc=0.6637, Val Loss=1.2787, lr=0.0010
[02/21 16:46:16] cifar100-global-random-3.0-resnet56 INFO: Epoch 70/100, Acc=0.6663, Val Loss=1.2742, lr=0.0010
[02/21 16:46:43] cifar100-global-random-3.0-resnet56 INFO: Epoch 71/100, Acc=0.6651, Val Loss=1.2825, lr=0.0010
[02/21 16:47:11] cifar100-global-random-3.0-resnet56 INFO: Epoch 72/100, Acc=0.6688, Val Loss=1.2772, lr=0.0010
[02/21 16:47:38] cifar100-global-random-3.0-resnet56 INFO: Epoch 73/100, Acc=0.6685, Val Loss=1.2814, lr=0.0010
[02/21 16:48:05] cifar100-global-random-3.0-resnet56 INFO: Epoch 74/100, Acc=0.6688, Val Loss=1.2818, lr=0.0010
[02/21 16:48:33] cifar100-global-random-3.0-resnet56 INFO: Epoch 75/100, Acc=0.6672, Val Loss=1.2921, lr=0.0010
[02/21 16:49:00] cifar100-global-random-3.0-resnet56 INFO: Epoch 76/100, Acc=0.6697, Val Loss=1.2871, lr=0.0010
[02/21 16:49:27] cifar100-global-random-3.0-resnet56 INFO: Epoch 77/100, Acc=0.6652, Val Loss=1.3023, lr=0.0010
[02/21 16:49:54] cifar100-global-random-3.0-resnet56 INFO: Epoch 78/100, Acc=0.6619, Val Loss=1.3072, lr=0.0010
[02/21 16:50:21] cifar100-global-random-3.0-resnet56 INFO: Epoch 79/100, Acc=0.6628, Val Loss=1.3194, lr=0.0010
[02/21 16:50:48] cifar100-global-random-3.0-resnet56 INFO: Epoch 80/100, Acc=0.6673, Val Loss=1.2986, lr=0.0001
[02/21 16:51:15] cifar100-global-random-3.0-resnet56 INFO: Epoch 81/100, Acc=0.6693, Val Loss=1.2938, lr=0.0001
[02/21 16:51:42] cifar100-global-random-3.0-resnet56 INFO: Epoch 82/100, Acc=0.6662, Val Loss=1.2941, lr=0.0001
[02/21 16:52:09] cifar100-global-random-3.0-resnet56 INFO: Epoch 83/100, Acc=0.6684, Val Loss=1.2957, lr=0.0001
[02/21 16:52:36] cifar100-global-random-3.0-resnet56 INFO: Epoch 84/100, Acc=0.6668, Val Loss=1.2980, lr=0.0001
[02/21 16:53:02] cifar100-global-random-3.0-resnet56 INFO: Epoch 85/100, Acc=0.6681, Val Loss=1.2973, lr=0.0001
[02/21 16:53:29] cifar100-global-random-3.0-resnet56 INFO: Epoch 86/100, Acc=0.6696, Val Loss=1.2992, lr=0.0001
[02/21 16:53:56] cifar100-global-random-3.0-resnet56 INFO: Epoch 87/100, Acc=0.6677, Val Loss=1.2996, lr=0.0001
[02/21 16:54:23] cifar100-global-random-3.0-resnet56 INFO: Epoch 88/100, Acc=0.6677, Val Loss=1.2946, lr=0.0001
[02/21 16:54:50] cifar100-global-random-3.0-resnet56 INFO: Epoch 89/100, Acc=0.6670, Val Loss=1.2969, lr=0.0001
[02/21 16:55:16] cifar100-global-random-3.0-resnet56 INFO: Epoch 90/100, Acc=0.6687, Val Loss=1.2950, lr=0.0001
[02/21 16:55:43] cifar100-global-random-3.0-resnet56 INFO: Epoch 91/100, Acc=0.6669, Val Loss=1.3034, lr=0.0001
[02/21 16:56:10] cifar100-global-random-3.0-resnet56 INFO: Epoch 92/100, Acc=0.6708, Val Loss=1.2922, lr=0.0001
[02/21 16:56:37] cifar100-global-random-3.0-resnet56 INFO: Epoch 93/100, Acc=0.6671, Val Loss=1.3000, lr=0.0001
[02/21 16:57:04] cifar100-global-random-3.0-resnet56 INFO: Epoch 94/100, Acc=0.6705, Val Loss=1.2988, lr=0.0001
[02/21 16:57:31] cifar100-global-random-3.0-resnet56 INFO: Epoch 95/100, Acc=0.6679, Val Loss=1.3026, lr=0.0001
[02/21 16:57:58] cifar100-global-random-3.0-resnet56 INFO: Epoch 96/100, Acc=0.6670, Val Loss=1.3024, lr=0.0001
[02/21 16:58:25] cifar100-global-random-3.0-resnet56 INFO: Epoch 97/100, Acc=0.6658, Val Loss=1.3000, lr=0.0001
[02/21 16:58:51] cifar100-global-random-3.0-resnet56 INFO: Epoch 98/100, Acc=0.6680, Val Loss=1.3008, lr=0.0001
[02/21 16:59:18] cifar100-global-random-3.0-resnet56 INFO: Epoch 99/100, Acc=0.6671, Val Loss=1.3013, lr=0.0001
[02/21 16:59:18] cifar100-global-random-3.0-resnet56 INFO: Best Acc=0.6708
[02/21 16:59:18] cifar100-global-random-3.0-resnet56 INFO: Params: 0.45 M
[02/21 16:59:18] cifar100-global-random-3.0-resnet56 INFO: ops: 39.03 M
[02/21 16:59:21] cifar100-global-random-3.0-resnet56 INFO: Acc: 0.6671 Val Loss: 1.3013

