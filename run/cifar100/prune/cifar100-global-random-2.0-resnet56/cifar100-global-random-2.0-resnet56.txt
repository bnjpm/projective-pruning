[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: mode: prune
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: model: resnet56
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: verbose: False
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: dataset: cifar100
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: dataroot: data
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: batch_size: 128
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: total_epochs: 100
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: lr: 0.01
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-random-2.0-resnet56
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: finetune: True
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: last_epochs: 100
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: reps: 1
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: method: random
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: speed_up: 2.0
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: reg: 1e-05
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: seed: 1
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: global_pruning: True
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: sl_restore: None
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: iterative_steps: 400
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: logger: <Logger cifar100-global-random-2.0-resnet56 (DEBUG)>
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: device: cuda
[02/21 12:29:53] cifar100-global-random-2.0-resnet56 INFO: num_classes: 100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: mode: prune
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: model: resnet56
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: verbose: False
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: dataset: cifar100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: dataroot: data
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: batch_size: 128
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: total_epochs: 100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: lr: 0.01
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-random-2.0-resnet56
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: finetune: True
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: last_epochs: 100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: reps: 1
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: method: random
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: speed_up: 2.0
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: reg: 1e-05
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: seed: 1
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: global_pruning: True
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: sl_restore: None
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: iterative_steps: 400
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: logger: <Logger cifar100-global-random-2.0-resnet56 (DEBUG)>
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: device: cuda
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: num_classes: 100
[02/21 14:19:29] cifar100-global-random-2.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 14:19:33] cifar100-global-random-2.0-resnet56 INFO: Pruning...
[02/21 14:19:39] cifar100-global-random-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 23, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(7, 23, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(23, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(23, 55, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=55, out_features=100, bias=True)
)
[02/21 14:19:42] cifar100-global-random-2.0-resnet56 INFO: Params: 0.86 M => 0.57 M (66.73%)
[02/21 14:19:42] cifar100-global-random-2.0-resnet56 INFO: FLOPs: 127.12 M => 60.68 M (47.73%, 2.09X )
[02/21 14:19:42] cifar100-global-random-2.0-resnet56 INFO: Acc: 0.7269 => 0.0172
[02/21 14:19:42] cifar100-global-random-2.0-resnet56 INFO: Val Loss: 1.1578 => 12.2143
[02/21 14:19:42] cifar100-global-random-2.0-resnet56 INFO: Finetuning...
[02/21 14:20:09] cifar100-global-random-2.0-resnet56 INFO: Epoch 0/100, Acc=0.5412, Val Loss=1.7476, lr=0.0100
[02/21 14:20:36] cifar100-global-random-2.0-resnet56 INFO: Epoch 1/100, Acc=0.5396, Val Loss=1.7866, lr=0.0100
[02/21 14:21:03] cifar100-global-random-2.0-resnet56 INFO: Epoch 2/100, Acc=0.5666, Val Loss=1.6627, lr=0.0100
[02/21 14:21:30] cifar100-global-random-2.0-resnet56 INFO: Epoch 3/100, Acc=0.6200, Val Loss=1.4005, lr=0.0100
[02/21 14:21:57] cifar100-global-random-2.0-resnet56 INFO: Epoch 4/100, Acc=0.6119, Val Loss=1.4466, lr=0.0100
[02/21 14:22:24] cifar100-global-random-2.0-resnet56 INFO: Epoch 5/100, Acc=0.6174, Val Loss=1.4436, lr=0.0100
[02/21 14:22:51] cifar100-global-random-2.0-resnet56 INFO: Epoch 6/100, Acc=0.6196, Val Loss=1.4390, lr=0.0100
[02/21 14:23:18] cifar100-global-random-2.0-resnet56 INFO: Epoch 7/100, Acc=0.6053, Val Loss=1.4777, lr=0.0100
[02/21 14:23:45] cifar100-global-random-2.0-resnet56 INFO: Epoch 8/100, Acc=0.6083, Val Loss=1.4667, lr=0.0100
[02/21 14:24:12] cifar100-global-random-2.0-resnet56 INFO: Epoch 9/100, Acc=0.6120, Val Loss=1.5159, lr=0.0100
[02/21 14:24:39] cifar100-global-random-2.0-resnet56 INFO: Epoch 10/100, Acc=0.5985, Val Loss=1.5736, lr=0.0100
[02/21 14:25:06] cifar100-global-random-2.0-resnet56 INFO: Epoch 11/100, Acc=0.5744, Val Loss=1.6748, lr=0.0100
[02/21 14:25:33] cifar100-global-random-2.0-resnet56 INFO: Epoch 12/100, Acc=0.6193, Val Loss=1.4326, lr=0.0100
[02/21 14:26:00] cifar100-global-random-2.0-resnet56 INFO: Epoch 13/100, Acc=0.6405, Val Loss=1.3329, lr=0.0100
[02/21 14:26:27] cifar100-global-random-2.0-resnet56 INFO: Epoch 14/100, Acc=0.6426, Val Loss=1.3258, lr=0.0100
[02/21 14:26:54] cifar100-global-random-2.0-resnet56 INFO: Epoch 15/100, Acc=0.6373, Val Loss=1.3749, lr=0.0100
[02/21 14:27:21] cifar100-global-random-2.0-resnet56 INFO: Epoch 16/100, Acc=0.6218, Val Loss=1.4681, lr=0.0100
[02/21 14:27:48] cifar100-global-random-2.0-resnet56 INFO: Epoch 17/100, Acc=0.6352, Val Loss=1.4088, lr=0.0100
[02/21 14:28:15] cifar100-global-random-2.0-resnet56 INFO: Epoch 18/100, Acc=0.6397, Val Loss=1.3995, lr=0.0100
[02/21 14:28:42] cifar100-global-random-2.0-resnet56 INFO: Epoch 19/100, Acc=0.6360, Val Loss=1.3875, lr=0.0100
[02/21 14:29:09] cifar100-global-random-2.0-resnet56 INFO: Epoch 20/100, Acc=0.6473, Val Loss=1.3713, lr=0.0100
[02/21 14:29:37] cifar100-global-random-2.0-resnet56 INFO: Epoch 21/100, Acc=0.6246, Val Loss=1.4439, lr=0.0100
[02/21 14:30:04] cifar100-global-random-2.0-resnet56 INFO: Epoch 22/100, Acc=0.6375, Val Loss=1.4175, lr=0.0100
[02/21 14:30:31] cifar100-global-random-2.0-resnet56 INFO: Epoch 23/100, Acc=0.6039, Val Loss=1.5618, lr=0.0100
[02/21 14:30:59] cifar100-global-random-2.0-resnet56 INFO: Epoch 24/100, Acc=0.6339, Val Loss=1.4161, lr=0.0100
[02/21 14:31:26] cifar100-global-random-2.0-resnet56 INFO: Epoch 25/100, Acc=0.6161, Val Loss=1.4991, lr=0.0100
[02/21 14:31:53] cifar100-global-random-2.0-resnet56 INFO: Epoch 26/100, Acc=0.6308, Val Loss=1.4585, lr=0.0100
[02/21 14:32:21] cifar100-global-random-2.0-resnet56 INFO: Epoch 27/100, Acc=0.6395, Val Loss=1.4260, lr=0.0100
[02/21 14:32:48] cifar100-global-random-2.0-resnet56 INFO: Epoch 28/100, Acc=0.6286, Val Loss=1.4465, lr=0.0100
[02/21 14:33:16] cifar100-global-random-2.0-resnet56 INFO: Epoch 29/100, Acc=0.6390, Val Loss=1.4062, lr=0.0100
[02/21 14:33:43] cifar100-global-random-2.0-resnet56 INFO: Epoch 30/100, Acc=0.6215, Val Loss=1.5258, lr=0.0100
[02/21 14:34:10] cifar100-global-random-2.0-resnet56 INFO: Epoch 31/100, Acc=0.6436, Val Loss=1.3695, lr=0.0100
[02/21 14:34:38] cifar100-global-random-2.0-resnet56 INFO: Epoch 32/100, Acc=0.6461, Val Loss=1.3966, lr=0.0100
[02/21 14:35:05] cifar100-global-random-2.0-resnet56 INFO: Epoch 33/100, Acc=0.6191, Val Loss=1.5130, lr=0.0100
[02/21 14:35:32] cifar100-global-random-2.0-resnet56 INFO: Epoch 34/100, Acc=0.6356, Val Loss=1.4561, lr=0.0100
[02/21 14:35:59] cifar100-global-random-2.0-resnet56 INFO: Epoch 35/100, Acc=0.6348, Val Loss=1.4171, lr=0.0100
[02/21 14:36:26] cifar100-global-random-2.0-resnet56 INFO: Epoch 36/100, Acc=0.6412, Val Loss=1.4578, lr=0.0100
[02/21 14:36:53] cifar100-global-random-2.0-resnet56 INFO: Epoch 37/100, Acc=0.6371, Val Loss=1.4146, lr=0.0100
[02/21 14:37:20] cifar100-global-random-2.0-resnet56 INFO: Epoch 38/100, Acc=0.6468, Val Loss=1.3784, lr=0.0100
[02/21 14:37:47] cifar100-global-random-2.0-resnet56 INFO: Epoch 39/100, Acc=0.6532, Val Loss=1.3484, lr=0.0100
[02/21 14:38:14] cifar100-global-random-2.0-resnet56 INFO: Epoch 40/100, Acc=0.6368, Val Loss=1.4320, lr=0.0100
[02/21 14:38:41] cifar100-global-random-2.0-resnet56 INFO: Epoch 41/100, Acc=0.6245, Val Loss=1.4998, lr=0.0100
[02/21 14:39:08] cifar100-global-random-2.0-resnet56 INFO: Epoch 42/100, Acc=0.6398, Val Loss=1.3989, lr=0.0100
[02/21 14:39:35] cifar100-global-random-2.0-resnet56 INFO: Epoch 43/100, Acc=0.6507, Val Loss=1.3323, lr=0.0100
[02/21 14:40:02] cifar100-global-random-2.0-resnet56 INFO: Epoch 44/100, Acc=0.6116, Val Loss=1.5953, lr=0.0100
[02/21 14:40:30] cifar100-global-random-2.0-resnet56 INFO: Epoch 45/100, Acc=0.6443, Val Loss=1.3970, lr=0.0100
[02/21 14:40:57] cifar100-global-random-2.0-resnet56 INFO: Epoch 46/100, Acc=0.6452, Val Loss=1.3994, lr=0.0100
[02/21 14:41:24] cifar100-global-random-2.0-resnet56 INFO: Epoch 47/100, Acc=0.6385, Val Loss=1.4416, lr=0.0100
[02/21 14:41:51] cifar100-global-random-2.0-resnet56 INFO: Epoch 48/100, Acc=0.6367, Val Loss=1.4479, lr=0.0100
[02/21 14:42:19] cifar100-global-random-2.0-resnet56 INFO: Epoch 49/100, Acc=0.6280, Val Loss=1.4882, lr=0.0100
[02/21 14:42:46] cifar100-global-random-2.0-resnet56 INFO: Epoch 50/100, Acc=0.6208, Val Loss=1.5264, lr=0.0100
[02/21 14:43:13] cifar100-global-random-2.0-resnet56 INFO: Epoch 51/100, Acc=0.6253, Val Loss=1.4575, lr=0.0100
[02/21 14:43:41] cifar100-global-random-2.0-resnet56 INFO: Epoch 52/100, Acc=0.6380, Val Loss=1.4558, lr=0.0100
[02/21 14:44:08] cifar100-global-random-2.0-resnet56 INFO: Epoch 53/100, Acc=0.6293, Val Loss=1.5075, lr=0.0100
[02/21 14:44:35] cifar100-global-random-2.0-resnet56 INFO: Epoch 54/100, Acc=0.6402, Val Loss=1.4724, lr=0.0100
[02/21 14:45:02] cifar100-global-random-2.0-resnet56 INFO: Epoch 55/100, Acc=0.6406, Val Loss=1.4080, lr=0.0100
[02/21 14:45:29] cifar100-global-random-2.0-resnet56 INFO: Epoch 56/100, Acc=0.6529, Val Loss=1.3838, lr=0.0100
[02/21 14:45:56] cifar100-global-random-2.0-resnet56 INFO: Epoch 57/100, Acc=0.6228, Val Loss=1.5368, lr=0.0100
[02/21 14:46:23] cifar100-global-random-2.0-resnet56 INFO: Epoch 58/100, Acc=0.6234, Val Loss=1.5308, lr=0.0100
[02/21 14:46:50] cifar100-global-random-2.0-resnet56 INFO: Epoch 59/100, Acc=0.6398, Val Loss=1.4554, lr=0.0100
[02/21 14:47:17] cifar100-global-random-2.0-resnet56 INFO: Epoch 60/100, Acc=0.7038, Val Loss=1.1333, lr=0.0010
[02/21 14:47:44] cifar100-global-random-2.0-resnet56 INFO: Epoch 61/100, Acc=0.7045, Val Loss=1.1406, lr=0.0010
[02/21 14:48:11] cifar100-global-random-2.0-resnet56 INFO: Epoch 62/100, Acc=0.7050, Val Loss=1.1449, lr=0.0010
[02/21 14:48:39] cifar100-global-random-2.0-resnet56 INFO: Epoch 63/100, Acc=0.7084, Val Loss=1.1507, lr=0.0010
[02/21 14:49:06] cifar100-global-random-2.0-resnet56 INFO: Epoch 64/100, Acc=0.7059, Val Loss=1.1587, lr=0.0010
[02/21 14:49:34] cifar100-global-random-2.0-resnet56 INFO: Epoch 65/100, Acc=0.7088, Val Loss=1.1544, lr=0.0010
[02/21 14:50:01] cifar100-global-random-2.0-resnet56 INFO: Epoch 66/100, Acc=0.7091, Val Loss=1.1726, lr=0.0010
[02/21 14:50:29] cifar100-global-random-2.0-resnet56 INFO: Epoch 67/100, Acc=0.7060, Val Loss=1.1739, lr=0.0010
[02/21 14:50:56] cifar100-global-random-2.0-resnet56 INFO: Epoch 68/100, Acc=0.7075, Val Loss=1.1733, lr=0.0010
[02/21 14:51:24] cifar100-global-random-2.0-resnet56 INFO: Epoch 69/100, Acc=0.7072, Val Loss=1.1889, lr=0.0010
[02/21 14:51:52] cifar100-global-random-2.0-resnet56 INFO: Epoch 70/100, Acc=0.7099, Val Loss=1.1892, lr=0.0010
[02/21 14:52:19] cifar100-global-random-2.0-resnet56 INFO: Epoch 71/100, Acc=0.7070, Val Loss=1.1924, lr=0.0010
[02/21 14:52:46] cifar100-global-random-2.0-resnet56 INFO: Epoch 72/100, Acc=0.7069, Val Loss=1.1890, lr=0.0010
[02/21 14:53:13] cifar100-global-random-2.0-resnet56 INFO: Epoch 73/100, Acc=0.7073, Val Loss=1.2031, lr=0.0010
[02/21 14:53:41] cifar100-global-random-2.0-resnet56 INFO: Epoch 74/100, Acc=0.7048, Val Loss=1.2046, lr=0.0010
[02/21 14:54:08] cifar100-global-random-2.0-resnet56 INFO: Epoch 75/100, Acc=0.7020, Val Loss=1.2127, lr=0.0010
[02/21 14:54:35] cifar100-global-random-2.0-resnet56 INFO: Epoch 76/100, Acc=0.7055, Val Loss=1.2126, lr=0.0010
[02/21 14:55:02] cifar100-global-random-2.0-resnet56 INFO: Epoch 77/100, Acc=0.7038, Val Loss=1.2241, lr=0.0010
[02/21 14:55:29] cifar100-global-random-2.0-resnet56 INFO: Epoch 78/100, Acc=0.7035, Val Loss=1.2221, lr=0.0010
[02/21 14:55:56] cifar100-global-random-2.0-resnet56 INFO: Epoch 79/100, Acc=0.7025, Val Loss=1.2272, lr=0.0010
[02/21 14:56:23] cifar100-global-random-2.0-resnet56 INFO: Epoch 80/100, Acc=0.7080, Val Loss=1.2158, lr=0.0001
[02/21 14:56:50] cifar100-global-random-2.0-resnet56 INFO: Epoch 81/100, Acc=0.7073, Val Loss=1.2184, lr=0.0001
[02/21 14:57:17] cifar100-global-random-2.0-resnet56 INFO: Epoch 82/100, Acc=0.7070, Val Loss=1.2134, lr=0.0001
[02/21 14:57:44] cifar100-global-random-2.0-resnet56 INFO: Epoch 83/100, Acc=0.7061, Val Loss=1.2149, lr=0.0001
[02/21 14:58:12] cifar100-global-random-2.0-resnet56 INFO: Epoch 84/100, Acc=0.7069, Val Loss=1.2181, lr=0.0001
[02/21 14:58:39] cifar100-global-random-2.0-resnet56 INFO: Epoch 85/100, Acc=0.7065, Val Loss=1.2162, lr=0.0001
[02/21 14:59:06] cifar100-global-random-2.0-resnet56 INFO: Epoch 86/100, Acc=0.7061, Val Loss=1.2218, lr=0.0001
[02/21 14:59:33] cifar100-global-random-2.0-resnet56 INFO: Epoch 87/100, Acc=0.7075, Val Loss=1.2158, lr=0.0001
[02/21 15:00:00] cifar100-global-random-2.0-resnet56 INFO: Epoch 88/100, Acc=0.7064, Val Loss=1.2140, lr=0.0001
[02/21 15:00:27] cifar100-global-random-2.0-resnet56 INFO: Epoch 89/100, Acc=0.7079, Val Loss=1.2163, lr=0.0001
[02/21 15:00:54] cifar100-global-random-2.0-resnet56 INFO: Epoch 90/100, Acc=0.7073, Val Loss=1.2153, lr=0.0001
[02/21 15:01:21] cifar100-global-random-2.0-resnet56 INFO: Epoch 91/100, Acc=0.7048, Val Loss=1.2256, lr=0.0001
[02/21 15:01:48] cifar100-global-random-2.0-resnet56 INFO: Epoch 92/100, Acc=0.7069, Val Loss=1.2144, lr=0.0001
[02/21 15:02:15] cifar100-global-random-2.0-resnet56 INFO: Epoch 93/100, Acc=0.7075, Val Loss=1.2199, lr=0.0001
[02/21 15:02:42] cifar100-global-random-2.0-resnet56 INFO: Epoch 94/100, Acc=0.7079, Val Loss=1.2179, lr=0.0001
[02/21 15:03:09] cifar100-global-random-2.0-resnet56 INFO: Epoch 95/100, Acc=0.7077, Val Loss=1.2217, lr=0.0001
[02/21 15:03:36] cifar100-global-random-2.0-resnet56 INFO: Epoch 96/100, Acc=0.7060, Val Loss=1.2229, lr=0.0001
[02/21 15:04:03] cifar100-global-random-2.0-resnet56 INFO: Epoch 97/100, Acc=0.7061, Val Loss=1.2213, lr=0.0001
[02/21 15:04:30] cifar100-global-random-2.0-resnet56 INFO: Epoch 98/100, Acc=0.7069, Val Loss=1.2189, lr=0.0001
[02/21 15:04:57] cifar100-global-random-2.0-resnet56 INFO: Epoch 99/100, Acc=0.7066, Val Loss=1.2197, lr=0.0001
[02/21 15:04:57] cifar100-global-random-2.0-resnet56 INFO: Best Acc=0.7099
[02/21 15:04:57] cifar100-global-random-2.0-resnet56 INFO: Params: 0.57 M
[02/21 15:04:57] cifar100-global-random-2.0-resnet56 INFO: ops: 60.68 M
[02/21 15:05:00] cifar100-global-random-2.0-resnet56 INFO: Acc: 0.7066 Val Loss: 1.2197

