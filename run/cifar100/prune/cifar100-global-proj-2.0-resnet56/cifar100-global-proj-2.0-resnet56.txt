[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: mode: prune
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: model: resnet56
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: verbose: False
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: dataset: cifar100
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: dataroot: data
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: batch_size: 128
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: total_epochs: 100
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: lr: 0.01
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-proj-2.0-resnet56
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: finetune: True
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: last_epochs: 100
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: reps: 1
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: method: proj
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: speed_up: 2.0
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: reg: 1e-05
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: seed: 1
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: global_pruning: True
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: sl_restore: None
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: iterative_steps: 400
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: logger: <Logger cifar100-global-proj-2.0-resnet56 (DEBUG)>
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: device: cuda
[02/21 12:30:36] cifar100-global-proj-2.0-resnet56 INFO: num_classes: 100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: mode: prune
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: model: resnet56
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: verbose: False
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: dataset: cifar100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: dataroot: data
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: batch_size: 128
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: total_epochs: 100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: lr: 0.01
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-proj-2.0-resnet56
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: finetune: True
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: last_epochs: 100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: reps: 1
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: method: proj
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: speed_up: 2.0
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: reg: 1e-05
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: delta_reg: 0.0001
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: weight_decay: 0.0005
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: seed: 1
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: global_pruning: True
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: sl_total_epochs: 100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: sl_lr: 0.01
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: sl_restore: None
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: iterative_steps: 400
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: logger: <Logger cifar100-global-proj-2.0-resnet56 (DEBUG)>
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: device: cuda
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: num_classes: 100
[02/21 22:06:29] cifar100-global-proj-2.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 22:06:32] cifar100-global-proj-2.0-resnet56 INFO: Pruning...
[02/21 22:08:14] cifar100-global-proj-2.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(7, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(7, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(7, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(8, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(7, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(7, 29, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(29, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(16, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(29, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(18, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(29, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(23, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(29, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(21, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(29, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(20, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(29, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(19, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(29, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(29, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(29, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(29, 62, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(62, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(52, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(62, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(62, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(60, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(62, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(62, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(62, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(62, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=62, out_features=100, bias=True)
)
[02/21 22:08:17] cifar100-global-proj-2.0-resnet56 INFO: Params: 0.86 M => 0.66 M (76.74%)
[02/21 22:08:17] cifar100-global-proj-2.0-resnet56 INFO: FLOPs: 127.12 M => 62.84 M (49.43%, 2.02X )
[02/21 22:08:17] cifar100-global-proj-2.0-resnet56 INFO: Acc: 0.7269 => 0.0093
[02/21 22:08:17] cifar100-global-proj-2.0-resnet56 INFO: Val Loss: 1.1578 => 13.5115
[02/21 22:08:17] cifar100-global-proj-2.0-resnet56 INFO: Finetuning...
[02/21 22:08:45] cifar100-global-proj-2.0-resnet56 INFO: Epoch 0/100, Acc=0.5611, Val Loss=1.6991, lr=0.0100
[02/21 22:09:12] cifar100-global-proj-2.0-resnet56 INFO: Epoch 1/100, Acc=0.6293, Val Loss=1.3833, lr=0.0100
[02/21 22:09:40] cifar100-global-proj-2.0-resnet56 INFO: Epoch 2/100, Acc=0.6170, Val Loss=1.4896, lr=0.0100
[02/21 22:10:08] cifar100-global-proj-2.0-resnet56 INFO: Epoch 3/100, Acc=0.6091, Val Loss=1.4950, lr=0.0100
[02/21 22:10:35] cifar100-global-proj-2.0-resnet56 INFO: Epoch 4/100, Acc=0.6296, Val Loss=1.4423, lr=0.0100
[02/21 22:11:03] cifar100-global-proj-2.0-resnet56 INFO: Epoch 5/100, Acc=0.6377, Val Loss=1.3970, lr=0.0100
[02/21 22:11:30] cifar100-global-proj-2.0-resnet56 INFO: Epoch 6/100, Acc=0.6438, Val Loss=1.3699, lr=0.0100
[02/21 22:11:58] cifar100-global-proj-2.0-resnet56 INFO: Epoch 7/100, Acc=0.6298, Val Loss=1.4444, lr=0.0100
[02/21 22:12:25] cifar100-global-proj-2.0-resnet56 INFO: Epoch 8/100, Acc=0.6265, Val Loss=1.4845, lr=0.0100
[02/21 22:12:52] cifar100-global-proj-2.0-resnet56 INFO: Epoch 9/100, Acc=0.6541, Val Loss=1.3298, lr=0.0100
[02/21 22:13:20] cifar100-global-proj-2.0-resnet56 INFO: Epoch 10/100, Acc=0.5795, Val Loss=1.7073, lr=0.0100
[02/21 22:13:47] cifar100-global-proj-2.0-resnet56 INFO: Epoch 11/100, Acc=0.6217, Val Loss=1.5309, lr=0.0100
[02/21 22:14:15] cifar100-global-proj-2.0-resnet56 INFO: Epoch 12/100, Acc=0.6395, Val Loss=1.4041, lr=0.0100
[02/21 22:14:42] cifar100-global-proj-2.0-resnet56 INFO: Epoch 13/100, Acc=0.6530, Val Loss=1.3229, lr=0.0100
[02/21 22:15:10] cifar100-global-proj-2.0-resnet56 INFO: Epoch 14/100, Acc=0.6382, Val Loss=1.3860, lr=0.0100
[02/21 22:15:37] cifar100-global-proj-2.0-resnet56 INFO: Epoch 15/100, Acc=0.6579, Val Loss=1.3526, lr=0.0100
[02/21 22:16:05] cifar100-global-proj-2.0-resnet56 INFO: Epoch 16/100, Acc=0.6260, Val Loss=1.4652, lr=0.0100
[02/21 22:16:32] cifar100-global-proj-2.0-resnet56 INFO: Epoch 17/100, Acc=0.6378, Val Loss=1.4366, lr=0.0100
[02/21 22:17:00] cifar100-global-proj-2.0-resnet56 INFO: Epoch 18/100, Acc=0.6422, Val Loss=1.3750, lr=0.0100
[02/21 22:17:28] cifar100-global-proj-2.0-resnet56 INFO: Epoch 19/100, Acc=0.6389, Val Loss=1.4022, lr=0.0100
[02/21 22:17:55] cifar100-global-proj-2.0-resnet56 INFO: Epoch 20/100, Acc=0.6478, Val Loss=1.3781, lr=0.0100
[02/21 22:18:23] cifar100-global-proj-2.0-resnet56 INFO: Epoch 21/100, Acc=0.6443, Val Loss=1.3917, lr=0.0100
[02/21 22:18:50] cifar100-global-proj-2.0-resnet56 INFO: Epoch 22/100, Acc=0.6321, Val Loss=1.4429, lr=0.0100
[02/21 22:19:18] cifar100-global-proj-2.0-resnet56 INFO: Epoch 23/100, Acc=0.6421, Val Loss=1.4187, lr=0.0100
[02/21 22:19:45] cifar100-global-proj-2.0-resnet56 INFO: Epoch 24/100, Acc=0.6427, Val Loss=1.4362, lr=0.0100
[02/21 22:20:13] cifar100-global-proj-2.0-resnet56 INFO: Epoch 25/100, Acc=0.6423, Val Loss=1.4102, lr=0.0100
[02/21 22:20:40] cifar100-global-proj-2.0-resnet56 INFO: Epoch 26/100, Acc=0.6405, Val Loss=1.4125, lr=0.0100
[02/21 22:21:08] cifar100-global-proj-2.0-resnet56 INFO: Epoch 27/100, Acc=0.6564, Val Loss=1.3569, lr=0.0100
[02/21 22:21:35] cifar100-global-proj-2.0-resnet56 INFO: Epoch 28/100, Acc=0.6375, Val Loss=1.4720, lr=0.0100
[02/21 22:22:03] cifar100-global-proj-2.0-resnet56 INFO: Epoch 29/100, Acc=0.6389, Val Loss=1.4892, lr=0.0100
[02/21 22:22:30] cifar100-global-proj-2.0-resnet56 INFO: Epoch 30/100, Acc=0.6300, Val Loss=1.5263, lr=0.0100
[02/21 22:22:58] cifar100-global-proj-2.0-resnet56 INFO: Epoch 31/100, Acc=0.6450, Val Loss=1.4309, lr=0.0100
[02/21 22:23:25] cifar100-global-proj-2.0-resnet56 INFO: Epoch 32/100, Acc=0.6387, Val Loss=1.4752, lr=0.0100
[02/21 22:23:53] cifar100-global-proj-2.0-resnet56 INFO: Epoch 33/100, Acc=0.6638, Val Loss=1.3634, lr=0.0100
[02/21 22:24:20] cifar100-global-proj-2.0-resnet56 INFO: Epoch 34/100, Acc=0.6379, Val Loss=1.4312, lr=0.0100
[02/21 22:24:48] cifar100-global-proj-2.0-resnet56 INFO: Epoch 35/100, Acc=0.6534, Val Loss=1.3814, lr=0.0100
[02/21 22:25:15] cifar100-global-proj-2.0-resnet56 INFO: Epoch 36/100, Acc=0.6400, Val Loss=1.4642, lr=0.0100
[02/21 22:25:43] cifar100-global-proj-2.0-resnet56 INFO: Epoch 37/100, Acc=0.6320, Val Loss=1.4633, lr=0.0100
[02/21 22:26:10] cifar100-global-proj-2.0-resnet56 INFO: Epoch 38/100, Acc=0.6549, Val Loss=1.4109, lr=0.0100
[02/21 22:26:38] cifar100-global-proj-2.0-resnet56 INFO: Epoch 39/100, Acc=0.6410, Val Loss=1.4537, lr=0.0100
[02/21 22:27:06] cifar100-global-proj-2.0-resnet56 INFO: Epoch 40/100, Acc=0.6274, Val Loss=1.4902, lr=0.0100
[02/21 22:27:33] cifar100-global-proj-2.0-resnet56 INFO: Epoch 41/100, Acc=0.6462, Val Loss=1.4189, lr=0.0100
[02/21 22:28:01] cifar100-global-proj-2.0-resnet56 INFO: Epoch 42/100, Acc=0.6423, Val Loss=1.4525, lr=0.0100
[02/21 22:28:28] cifar100-global-proj-2.0-resnet56 INFO: Epoch 43/100, Acc=0.6442, Val Loss=1.4340, lr=0.0100
[02/21 22:28:56] cifar100-global-proj-2.0-resnet56 INFO: Epoch 44/100, Acc=0.6340, Val Loss=1.5169, lr=0.0100
[02/21 22:29:24] cifar100-global-proj-2.0-resnet56 INFO: Epoch 45/100, Acc=0.6312, Val Loss=1.5172, lr=0.0100
[02/21 22:29:52] cifar100-global-proj-2.0-resnet56 INFO: Epoch 46/100, Acc=0.6559, Val Loss=1.4078, lr=0.0100
[02/21 22:30:20] cifar100-global-proj-2.0-resnet56 INFO: Epoch 47/100, Acc=0.6301, Val Loss=1.5379, lr=0.0100
[02/21 22:30:48] cifar100-global-proj-2.0-resnet56 INFO: Epoch 48/100, Acc=0.6398, Val Loss=1.5014, lr=0.0100
[02/21 22:31:16] cifar100-global-proj-2.0-resnet56 INFO: Epoch 49/100, Acc=0.6505, Val Loss=1.4476, lr=0.0100
[02/21 22:31:44] cifar100-global-proj-2.0-resnet56 INFO: Epoch 50/100, Acc=0.6183, Val Loss=1.5917, lr=0.0100
[02/21 22:32:12] cifar100-global-proj-2.0-resnet56 INFO: Epoch 51/100, Acc=0.6354, Val Loss=1.4862, lr=0.0100
[02/21 22:32:39] cifar100-global-proj-2.0-resnet56 INFO: Epoch 52/100, Acc=0.6495, Val Loss=1.4567, lr=0.0100
[02/21 22:33:07] cifar100-global-proj-2.0-resnet56 INFO: Epoch 53/100, Acc=0.6355, Val Loss=1.5229, lr=0.0100
[02/21 22:33:35] cifar100-global-proj-2.0-resnet56 INFO: Epoch 54/100, Acc=0.6252, Val Loss=1.5678, lr=0.0100
[02/21 22:34:02] cifar100-global-proj-2.0-resnet56 INFO: Epoch 55/100, Acc=0.6636, Val Loss=1.3572, lr=0.0100
[02/21 22:34:30] cifar100-global-proj-2.0-resnet56 INFO: Epoch 56/100, Acc=0.6425, Val Loss=1.4166, lr=0.0100
[02/21 22:34:58] cifar100-global-proj-2.0-resnet56 INFO: Epoch 57/100, Acc=0.6548, Val Loss=1.4223, lr=0.0100
[02/21 22:35:25] cifar100-global-proj-2.0-resnet56 INFO: Epoch 58/100, Acc=0.6465, Val Loss=1.4435, lr=0.0100
[02/21 22:35:53] cifar100-global-proj-2.0-resnet56 INFO: Epoch 59/100, Acc=0.6483, Val Loss=1.4594, lr=0.0100
[02/21 22:36:20] cifar100-global-proj-2.0-resnet56 INFO: Epoch 60/100, Acc=0.7116, Val Loss=1.1433, lr=0.0010
[02/21 22:36:48] cifar100-global-proj-2.0-resnet56 INFO: Epoch 61/100, Acc=0.7118, Val Loss=1.1451, lr=0.0010
[02/21 22:37:16] cifar100-global-proj-2.0-resnet56 INFO: Epoch 62/100, Acc=0.7122, Val Loss=1.1422, lr=0.0010
[02/21 22:37:43] cifar100-global-proj-2.0-resnet56 INFO: Epoch 63/100, Acc=0.7117, Val Loss=1.1532, lr=0.0010
[02/21 22:38:11] cifar100-global-proj-2.0-resnet56 INFO: Epoch 64/100, Acc=0.7156, Val Loss=1.1521, lr=0.0010
[02/21 22:38:39] cifar100-global-proj-2.0-resnet56 INFO: Epoch 65/100, Acc=0.7148, Val Loss=1.1550, lr=0.0010
[02/21 22:39:06] cifar100-global-proj-2.0-resnet56 INFO: Epoch 66/100, Acc=0.7132, Val Loss=1.1662, lr=0.0010
[02/21 22:39:34] cifar100-global-proj-2.0-resnet56 INFO: Epoch 67/100, Acc=0.7148, Val Loss=1.1721, lr=0.0010
[02/21 22:40:02] cifar100-global-proj-2.0-resnet56 INFO: Epoch 68/100, Acc=0.7128, Val Loss=1.1728, lr=0.0010
[02/21 22:40:29] cifar100-global-proj-2.0-resnet56 INFO: Epoch 69/100, Acc=0.7141, Val Loss=1.1778, lr=0.0010
[02/21 22:40:57] cifar100-global-proj-2.0-resnet56 INFO: Epoch 70/100, Acc=0.7152, Val Loss=1.1833, lr=0.0010
[02/21 22:41:24] cifar100-global-proj-2.0-resnet56 INFO: Epoch 71/100, Acc=0.7115, Val Loss=1.1900, lr=0.0010
[02/21 22:41:52] cifar100-global-proj-2.0-resnet56 INFO: Epoch 72/100, Acc=0.7134, Val Loss=1.1948, lr=0.0010
[02/21 22:42:20] cifar100-global-proj-2.0-resnet56 INFO: Epoch 73/100, Acc=0.7126, Val Loss=1.1957, lr=0.0010
[02/21 22:42:48] cifar100-global-proj-2.0-resnet56 INFO: Epoch 74/100, Acc=0.7138, Val Loss=1.1976, lr=0.0010
[02/21 22:43:16] cifar100-global-proj-2.0-resnet56 INFO: Epoch 75/100, Acc=0.7131, Val Loss=1.1979, lr=0.0010
[02/21 22:43:44] cifar100-global-proj-2.0-resnet56 INFO: Epoch 76/100, Acc=0.7116, Val Loss=1.2105, lr=0.0010
[02/21 22:44:12] cifar100-global-proj-2.0-resnet56 INFO: Epoch 77/100, Acc=0.7132, Val Loss=1.2107, lr=0.0010
[02/21 22:44:40] cifar100-global-proj-2.0-resnet56 INFO: Epoch 78/100, Acc=0.7133, Val Loss=1.2107, lr=0.0010
[02/21 22:45:08] cifar100-global-proj-2.0-resnet56 INFO: Epoch 79/100, Acc=0.7126, Val Loss=1.2214, lr=0.0010
[02/21 22:45:35] cifar100-global-proj-2.0-resnet56 INFO: Epoch 80/100, Acc=0.7138, Val Loss=1.2118, lr=0.0001
[02/21 22:46:03] cifar100-global-proj-2.0-resnet56 INFO: Epoch 81/100, Acc=0.7128, Val Loss=1.2106, lr=0.0001
[02/21 22:46:31] cifar100-global-proj-2.0-resnet56 INFO: Epoch 82/100, Acc=0.7127, Val Loss=1.2079, lr=0.0001
[02/21 22:46:59] cifar100-global-proj-2.0-resnet56 INFO: Epoch 83/100, Acc=0.7153, Val Loss=1.2106, lr=0.0001
[02/21 22:47:28] cifar100-global-proj-2.0-resnet56 INFO: Epoch 84/100, Acc=0.7135, Val Loss=1.2175, lr=0.0001
[02/21 22:47:56] cifar100-global-proj-2.0-resnet56 INFO: Epoch 85/100, Acc=0.7150, Val Loss=1.2116, lr=0.0001
[02/21 22:48:24] cifar100-global-proj-2.0-resnet56 INFO: Epoch 86/100, Acc=0.7144, Val Loss=1.2153, lr=0.0001
[02/21 22:48:52] cifar100-global-proj-2.0-resnet56 INFO: Epoch 87/100, Acc=0.7149, Val Loss=1.2147, lr=0.0001
[02/21 22:49:19] cifar100-global-proj-2.0-resnet56 INFO: Epoch 88/100, Acc=0.7152, Val Loss=1.2095, lr=0.0001
[02/21 22:49:47] cifar100-global-proj-2.0-resnet56 INFO: Epoch 89/100, Acc=0.7137, Val Loss=1.2127, lr=0.0001
[02/21 22:50:15] cifar100-global-proj-2.0-resnet56 INFO: Epoch 90/100, Acc=0.7139, Val Loss=1.2100, lr=0.0001
[02/21 22:50:43] cifar100-global-proj-2.0-resnet56 INFO: Epoch 91/100, Acc=0.7119, Val Loss=1.2218, lr=0.0001
[02/21 22:51:10] cifar100-global-proj-2.0-resnet56 INFO: Epoch 92/100, Acc=0.7145, Val Loss=1.2133, lr=0.0001
[02/21 22:51:38] cifar100-global-proj-2.0-resnet56 INFO: Epoch 93/100, Acc=0.7150, Val Loss=1.2143, lr=0.0001
[02/21 22:52:06] cifar100-global-proj-2.0-resnet56 INFO: Epoch 94/100, Acc=0.7169, Val Loss=1.2125, lr=0.0001
[02/21 22:52:33] cifar100-global-proj-2.0-resnet56 INFO: Epoch 95/100, Acc=0.7151, Val Loss=1.2190, lr=0.0001
[02/21 22:53:01] cifar100-global-proj-2.0-resnet56 INFO: Epoch 96/100, Acc=0.7128, Val Loss=1.2187, lr=0.0001
[02/21 22:53:29] cifar100-global-proj-2.0-resnet56 INFO: Epoch 97/100, Acc=0.7148, Val Loss=1.2173, lr=0.0001
[02/21 22:53:57] cifar100-global-proj-2.0-resnet56 INFO: Epoch 98/100, Acc=0.7125, Val Loss=1.2146, lr=0.0001
[02/21 22:54:25] cifar100-global-proj-2.0-resnet56 INFO: Epoch 99/100, Acc=0.7147, Val Loss=1.2169, lr=0.0001
[02/21 22:54:25] cifar100-global-proj-2.0-resnet56 INFO: Best Acc=0.7169
[02/21 22:54:25] cifar100-global-proj-2.0-resnet56 INFO: Params: 0.66 M
[02/21 22:54:25] cifar100-global-proj-2.0-resnet56 INFO: ops: 62.84 M
[02/21 22:54:28] cifar100-global-proj-2.0-resnet56 INFO: Acc: 0.7147 Val Loss: 1.2169

