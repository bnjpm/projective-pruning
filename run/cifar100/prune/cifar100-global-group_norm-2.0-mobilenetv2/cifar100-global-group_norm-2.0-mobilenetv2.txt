[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: mode: prune
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: verbose: False
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: dataset: cifar100
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: dataroot: data
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: batch_size: 128
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: total_epochs: 100
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: lr: 0.01
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: restore: run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: output_dir: run/cifar100/prune/cifar100-global-group_norm-2.0-mobilenetv2
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: finetune: True
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: last_epochs: 100
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: reps: 1
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: method: group_norm
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: reg: 1e-05
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: seed: 1
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: global_pruning: True
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: sl_restore: None
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: logger: <Logger cifar100-global-group_norm-2.0-mobilenetv2 (DEBUG)>
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: device: cuda
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: num_classes: 100
[02/24 04:08:27] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Loading model from run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 04:08:31] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Pruning...
[02/24 04:08:57] cifar100-global-group_norm-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 13, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(13, 15, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)
      (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(15, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 81, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(81, 81, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=81)
        (4): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(81, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 115, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(115, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=115)
        (4): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(115, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 89, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(89, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=89)
        (4): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(89, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 116, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(116, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 89, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=89)
        (4): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(89, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 107, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(107, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(107, 107, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=107)
        (4): BatchNorm2d(107, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(107, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 139, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(139, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(139, 139, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=139)
        (4): BatchNorm2d(139, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(139, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 132, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=132)
        (4): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(132, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 102, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=102)
        (4): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(102, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 238, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(238, 238, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=238)
        (4): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(238, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 176, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(176, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 115, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(115, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=115)
        (4): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(115, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 270, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(270, 270, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=270)
        (4): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(270, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 376, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=376)
        (4): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(376, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 418, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(418, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(418, 418, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=418)
        (4): BatchNorm2d(418, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(418, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 180, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
      (4): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(180, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 100, kernel_size=(1, 1), stride=(1, 1))
)
[02/24 04:09:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Params: 2.37 M => 1.18 M (49.65%)
[02/24 04:09:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: FLOPs: 68.40 M => 34.12 M (49.88%, 2.00X )
[02/24 04:09:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Acc: 0.6699 => 0.6699
[02/24 04:09:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Val Loss: 1.1637 => 1.1637
[02/24 04:09:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Finetuning...
[02/24 04:09:32] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.5982, Val Loss=1.4418, lr=0.0100
[02/24 04:10:05] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.6009, Val Loss=1.4087, lr=0.0100
[02/24 04:10:37] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5928, Val Loss=1.4416, lr=0.0100
[02/24 04:11:10] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.6001, Val Loss=1.4264, lr=0.0100
[02/24 04:11:42] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5962, Val Loss=1.4225, lr=0.0100
[02/24 04:12:14] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.5900, Val Loss=1.4406, lr=0.0100
[02/24 04:12:47] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.6093, Val Loss=1.3989, lr=0.0100
[02/24 04:13:20] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6094, Val Loss=1.3936, lr=0.0100
[02/24 04:13:53] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.6084, Val Loss=1.3931, lr=0.0100
[02/24 04:14:25] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6065, Val Loss=1.3993, lr=0.0100
[02/24 04:14:57] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6051, Val Loss=1.4005, lr=0.0100
[02/24 04:15:29] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6234, Val Loss=1.3399, lr=0.0100
[02/24 04:16:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.6037, Val Loss=1.4041, lr=0.0100
[02/24 04:16:31] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.5989, Val Loss=1.4350, lr=0.0100
[02/24 04:17:02] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.6079, Val Loss=1.3965, lr=0.0100
[02/24 04:17:33] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.6130, Val Loss=1.3605, lr=0.0100
[02/24 04:18:05] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.5955, Val Loss=1.4402, lr=0.0100
[02/24 04:18:37] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.5990, Val Loss=1.4462, lr=0.0100
[02/24 04:19:09] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6022, Val Loss=1.4137, lr=0.0100
[02/24 04:19:40] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.6036, Val Loss=1.4109, lr=0.0100
[02/24 04:20:12] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.6095, Val Loss=1.3897, lr=0.0100
[02/24 04:20:44] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.6035, Val Loss=1.4054, lr=0.0100
[02/24 04:21:15] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.5836, Val Loss=1.4816, lr=0.0100
[02/24 04:21:46] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.6121, Val Loss=1.3708, lr=0.0100
[02/24 04:22:17] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.6093, Val Loss=1.4063, lr=0.0100
[02/24 04:22:48] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.5952, Val Loss=1.4602, lr=0.0100
[02/24 04:23:19] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.6094, Val Loss=1.3932, lr=0.0100
[02/24 04:23:51] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.6013, Val Loss=1.4172, lr=0.0100
[02/24 04:24:22] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.6145, Val Loss=1.3800, lr=0.0100
[02/24 04:24:54] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.6130, Val Loss=1.3903, lr=0.0100
[02/24 04:25:25] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.6097, Val Loss=1.4070, lr=0.0100
[02/24 04:25:57] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.5732, Val Loss=1.5540, lr=0.0100
[02/24 04:26:28] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.5849, Val Loss=1.5036, lr=0.0100
[02/24 04:26:59] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.6020, Val Loss=1.4090, lr=0.0100
[02/24 04:27:30] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.6306, Val Loss=1.3170, lr=0.0100
[02/24 04:28:02] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.6195, Val Loss=1.3502, lr=0.0100
[02/24 04:28:35] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.6065, Val Loss=1.3803, lr=0.0100
[02/24 04:29:07] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.5983, Val Loss=1.4243, lr=0.0100
[02/24 04:29:39] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.6117, Val Loss=1.3844, lr=0.0100
[02/24 04:30:11] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.6044, Val Loss=1.4292, lr=0.0100
[02/24 04:30:44] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.6048, Val Loss=1.4163, lr=0.0100
[02/24 04:31:16] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.6183, Val Loss=1.3610, lr=0.0100
[02/24 04:31:48] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.6132, Val Loss=1.3727, lr=0.0100
[02/24 04:32:20] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.6140, Val Loss=1.4005, lr=0.0100
[02/24 04:32:52] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.5826, Val Loss=1.4885, lr=0.0100
[02/24 04:33:25] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.6070, Val Loss=1.3820, lr=0.0100
[02/24 04:33:59] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.6137, Val Loss=1.3789, lr=0.0100
[02/24 04:34:33] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.6183, Val Loss=1.3649, lr=0.0100
[02/24 04:35:06] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.6073, Val Loss=1.3850, lr=0.0100
[02/24 04:35:39] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.6065, Val Loss=1.4186, lr=0.0100
[02/24 04:36:11] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.6152, Val Loss=1.3757, lr=0.0100
[02/24 04:36:44] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.6165, Val Loss=1.3783, lr=0.0100
[02/24 04:37:17] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.6171, Val Loss=1.3641, lr=0.0100
[02/24 04:37:56] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.6085, Val Loss=1.3877, lr=0.0100
[02/24 04:38:34] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.6018, Val Loss=1.4543, lr=0.0100
[02/24 04:39:13] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.6146, Val Loss=1.3703, lr=0.0100
[02/24 04:39:52] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.6185, Val Loss=1.3650, lr=0.0100
[02/24 04:40:30] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.6125, Val Loss=1.3802, lr=0.0100
[02/24 04:41:04] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.6057, Val Loss=1.4065, lr=0.0100
[02/24 04:41:37] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.6013, Val Loss=1.4352, lr=0.0100
[02/24 04:42:10] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.6754, Val Loss=1.1429, lr=0.0010
[02/24 04:42:43] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.6772, Val Loss=1.1348, lr=0.0010
[02/24 04:43:17] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.6834, Val Loss=1.1262, lr=0.0010
[02/24 04:43:51] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.6820, Val Loss=1.1232, lr=0.0010
[02/24 04:44:24] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.6797, Val Loss=1.1252, lr=0.0010
[02/24 04:44:57] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.6814, Val Loss=1.1278, lr=0.0010
[02/24 04:45:30] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.6814, Val Loss=1.1225, lr=0.0010
[02/24 04:46:03] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.6792, Val Loss=1.1252, lr=0.0010
[02/24 04:46:36] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.6788, Val Loss=1.1253, lr=0.0010
[02/24 04:47:09] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.6789, Val Loss=1.1259, lr=0.0010
[02/24 04:47:43] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.6799, Val Loss=1.1262, lr=0.0010
[02/24 04:48:16] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.6823, Val Loss=1.1260, lr=0.0010
[02/24 04:48:50] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.6795, Val Loss=1.1276, lr=0.0010
[02/24 04:49:25] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.6785, Val Loss=1.1303, lr=0.0010
[02/24 04:49:59] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.6810, Val Loss=1.1346, lr=0.0010
[02/24 04:50:33] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.6799, Val Loss=1.1325, lr=0.0010
[02/24 04:51:06] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.6801, Val Loss=1.1307, lr=0.0010
[02/24 04:51:40] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.6788, Val Loss=1.1360, lr=0.0010
[02/24 04:52:13] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.6820, Val Loss=1.1317, lr=0.0010
[02/24 04:52:48] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.6777, Val Loss=1.1352, lr=0.0010
[02/24 04:53:22] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.6808, Val Loss=1.1261, lr=0.0001
[02/24 04:54:03] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.6812, Val Loss=1.1245, lr=0.0001
[02/24 04:54:44] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.6834, Val Loss=1.1252, lr=0.0001
[02/24 04:55:25] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.6827, Val Loss=1.1243, lr=0.0001
[02/24 04:56:06] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.6829, Val Loss=1.1233, lr=0.0001
[02/24 04:56:41] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.6839, Val Loss=1.1255, lr=0.0001
[02/24 04:57:21] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.6811, Val Loss=1.1232, lr=0.0001
[02/24 04:58:00] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.6827, Val Loss=1.1232, lr=0.0001
[02/24 04:58:39] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.6835, Val Loss=1.1232, lr=0.0001
[02/24 04:59:18] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.6837, Val Loss=1.1244, lr=0.0001
[02/24 04:59:57] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.6841, Val Loss=1.1240, lr=0.0001
[02/24 05:00:37] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.6815, Val Loss=1.1262, lr=0.0001
[02/24 05:01:09] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.6833, Val Loss=1.1258, lr=0.0001
[02/24 05:01:40] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.6816, Val Loss=1.1246, lr=0.0001
[02/24 05:02:11] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.6847, Val Loss=1.1258, lr=0.0001
[02/24 05:02:42] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.6811, Val Loss=1.1266, lr=0.0001
[02/24 05:03:14] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.6816, Val Loss=1.1239, lr=0.0001
[02/24 05:03:45] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.6833, Val Loss=1.1252, lr=0.0001
[02/24 05:04:17] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.6832, Val Loss=1.1235, lr=0.0001
[02/24 05:04:49] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.6828, Val Loss=1.1260, lr=0.0001
[02/24 05:04:49] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Best Acc=0.6847
[02/24 05:04:49] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Params: 1.18 M
[02/24 05:04:49] cifar100-global-group_norm-2.0-mobilenetv2 INFO: ops: 34.12 M
[02/24 05:04:52] cifar100-global-group_norm-2.0-mobilenetv2 INFO: Acc: 0.6828 Val Loss: 1.1260

