[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: mode: prune
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: model: resnet56
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: verbose: False
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: dataset: cifar100
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: dataroot: data
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: batch_size: 128
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: total_epochs: 100
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: lr: 0.01
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar10_resnet56.pth
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-group_norm-3.0-resnet56
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: finetune: True
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: last_epochs: 100
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: reps: 1
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: method: group_norm
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: speed_up: 3.0
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: reg: 1e-05
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: seed: 1
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: global_pruning: True
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: sl_restore: None
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: iterative_steps: 400
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: logger: <Logger cifar100-global-group_norm-3.0-resnet56 (DEBUG)>
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: device: cuda
[02/21 12:30:51] cifar100-global-group_norm-3.0-resnet56 INFO: num_classes: 100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: mode: prune
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: model: resnet56
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: verbose: False
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: dataset: cifar100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: dataroot: data
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: batch_size: 128
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: total_epochs: 100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: lr_decay_milestones: 60,80
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: lr_decay_gamma: 0.1
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: lr: 0.01
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: restore: run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: output_dir: run/cifar100/prune/cifar100-global-group_norm-3.0-resnet56
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: finetune: True
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: last_epochs: 100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: reps: 1
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: method: group_norm
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: speed_up: 3.0
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: max_pruning_ratio: 1.0
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: soft_keeping_ratio: 0.0
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: reg: 1e-05
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: delta_reg: 0.0001
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: weight_decay: 0.0005
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: seed: 1
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: global_pruning: True
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: sl_total_epochs: 100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: sl_lr: 0.01
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: sl_lr_decay_milestones: 60,80
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: sl_reg_warmup: 0
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: sl_restore: None
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: iterative_steps: 400
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: logger: <Logger cifar100-global-group_norm-3.0-resnet56 (DEBUG)>
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: device: cuda
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: num_classes: 100
[02/21 20:51:28] cifar100-global-group_norm-3.0-resnet56 INFO: Loading model from run/cifar100/pretrain/cifar100_resnet56.pth
[02/21 20:51:31] cifar100-global-group_norm-3.0-resnet56 INFO: Pruning...
[02/21 20:51:47] cifar100-global-group_norm-3.0-resnet56 INFO: ResNet(
  (conv1): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(7, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(7, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(1, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(7, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(7, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(7, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(7, 9, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(9, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(13, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(9, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(14, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(10, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(11, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(9, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(12, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(9, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(2, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(9, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(9, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): BasicBlock(
      (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): BasicBlock(
      (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): BasicBlock(
      (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (fc): Linear(in_features=64, out_features=100, bias=True)
)
[02/21 20:51:50] cifar100-global-group_norm-3.0-resnet56 INFO: Params: 0.86 M => 0.58 M (66.81%)
[02/21 20:51:50] cifar100-global-group_norm-3.0-resnet56 INFO: FLOPs: 127.12 M => 42.33 M (33.29%, 3.00X )
[02/21 20:51:50] cifar100-global-group_norm-3.0-resnet56 INFO: Acc: 0.7269 => 0.0147
[02/21 20:51:50] cifar100-global-group_norm-3.0-resnet56 INFO: Val Loss: 1.1578 => 15.9639
[02/21 20:51:50] cifar100-global-group_norm-3.0-resnet56 INFO: Finetuning...
[02/21 20:52:17] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 0/100, Acc=0.4876, Val Loss=2.0285, lr=0.0100
[02/21 20:52:44] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 1/100, Acc=0.5586, Val Loss=1.6453, lr=0.0100
[02/21 20:53:11] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 2/100, Acc=0.5551, Val Loss=1.6679, lr=0.0100
[02/21 20:53:38] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 3/100, Acc=0.5682, Val Loss=1.6645, lr=0.0100
[02/21 20:54:05] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 4/100, Acc=0.5512, Val Loss=1.7686, lr=0.0100
[02/21 20:54:32] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 5/100, Acc=0.5607, Val Loss=1.6861, lr=0.0100
[02/21 20:54:59] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 6/100, Acc=0.6037, Val Loss=1.5036, lr=0.0100
[02/21 20:55:26] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 7/100, Acc=0.5959, Val Loss=1.5352, lr=0.0100
[02/21 20:55:53] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 8/100, Acc=0.6087, Val Loss=1.4693, lr=0.0100
[02/21 20:56:21] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 9/100, Acc=0.6159, Val Loss=1.4289, lr=0.0100
[02/21 20:56:48] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 10/100, Acc=0.5850, Val Loss=1.6057, lr=0.0100
[02/21 20:57:15] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 11/100, Acc=0.6038, Val Loss=1.5035, lr=0.0100
[02/21 20:57:42] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 12/100, Acc=0.5905, Val Loss=1.5469, lr=0.0100
[02/21 20:58:09] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 13/100, Acc=0.6207, Val Loss=1.4088, lr=0.0100
[02/21 20:58:37] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 14/100, Acc=0.6085, Val Loss=1.4807, lr=0.0100
[02/21 20:59:04] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 15/100, Acc=0.6116, Val Loss=1.4787, lr=0.0100
[02/21 20:59:31] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 16/100, Acc=0.6061, Val Loss=1.5113, lr=0.0100
[02/21 20:59:58] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 17/100, Acc=0.6076, Val Loss=1.5150, lr=0.0100
[02/21 21:00:26] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 18/100, Acc=0.6126, Val Loss=1.4976, lr=0.0100
[02/21 21:00:53] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 19/100, Acc=0.6058, Val Loss=1.5412, lr=0.0100
[02/21 21:01:20] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 20/100, Acc=0.5948, Val Loss=1.5405, lr=0.0100
[02/21 21:01:47] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 21/100, Acc=0.6025, Val Loss=1.5339, lr=0.0100
[02/21 21:02:15] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 22/100, Acc=0.6274, Val Loss=1.4267, lr=0.0100
[02/21 21:02:42] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 23/100, Acc=0.5799, Val Loss=1.6924, lr=0.0100
[02/21 21:03:09] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 24/100, Acc=0.6277, Val Loss=1.4377, lr=0.0100
[02/21 21:03:37] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 25/100, Acc=0.6170, Val Loss=1.4990, lr=0.0100
[02/21 21:04:04] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 26/100, Acc=0.6246, Val Loss=1.4718, lr=0.0100
[02/21 21:04:31] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 27/100, Acc=0.6123, Val Loss=1.5011, lr=0.0100
[02/21 21:04:59] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 28/100, Acc=0.6160, Val Loss=1.4830, lr=0.0100
[02/21 21:05:26] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 29/100, Acc=0.6164, Val Loss=1.4796, lr=0.0100
[02/21 21:05:53] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 30/100, Acc=0.6159, Val Loss=1.5193, lr=0.0100
[02/21 21:06:21] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 31/100, Acc=0.6092, Val Loss=1.5351, lr=0.0100
[02/21 21:06:48] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 32/100, Acc=0.6075, Val Loss=1.5733, lr=0.0100
[02/21 21:07:16] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 33/100, Acc=0.6102, Val Loss=1.5305, lr=0.0100
[02/21 21:07:43] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 34/100, Acc=0.5945, Val Loss=1.6228, lr=0.0100
[02/21 21:08:10] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 35/100, Acc=0.6136, Val Loss=1.5132, lr=0.0100
[02/21 21:08:38] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 36/100, Acc=0.6118, Val Loss=1.5554, lr=0.0100
[02/21 21:09:05] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 37/100, Acc=0.6271, Val Loss=1.4758, lr=0.0100
[02/21 21:09:32] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 38/100, Acc=0.6302, Val Loss=1.4495, lr=0.0100
[02/21 21:10:00] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 39/100, Acc=0.6324, Val Loss=1.3955, lr=0.0100
[02/21 21:10:27] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 40/100, Acc=0.6161, Val Loss=1.4953, lr=0.0100
[02/21 21:10:54] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 41/100, Acc=0.6202, Val Loss=1.5074, lr=0.0100
[02/21 21:11:22] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 42/100, Acc=0.6320, Val Loss=1.4545, lr=0.0100
[02/21 21:11:49] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 43/100, Acc=0.6033, Val Loss=1.5764, lr=0.0100
[02/21 21:12:16] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 44/100, Acc=0.6379, Val Loss=1.3996, lr=0.0100
[02/21 21:12:43] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 45/100, Acc=0.6162, Val Loss=1.5032, lr=0.0100
[02/21 21:13:10] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 46/100, Acc=0.6274, Val Loss=1.4822, lr=0.0100
[02/21 21:13:37] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 47/100, Acc=0.6095, Val Loss=1.5593, lr=0.0100
[02/21 21:14:04] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 48/100, Acc=0.6176, Val Loss=1.5457, lr=0.0100
[02/21 21:14:32] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 49/100, Acc=0.5918, Val Loss=1.6612, lr=0.0100
[02/21 21:14:59] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 50/100, Acc=0.6265, Val Loss=1.4551, lr=0.0100
[02/21 21:15:27] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 51/100, Acc=0.6330, Val Loss=1.4278, lr=0.0100
[02/21 21:15:54] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 52/100, Acc=0.6314, Val Loss=1.4651, lr=0.0100
[02/21 21:16:22] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 53/100, Acc=0.6150, Val Loss=1.5055, lr=0.0100
[02/21 21:16:49] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 54/100, Acc=0.6073, Val Loss=1.5580, lr=0.0100
[02/21 21:17:17] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 55/100, Acc=0.6302, Val Loss=1.4369, lr=0.0100
[02/21 21:17:44] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 56/100, Acc=0.6265, Val Loss=1.4865, lr=0.0100
[02/21 21:18:12] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 57/100, Acc=0.6199, Val Loss=1.5360, lr=0.0100
[02/21 21:18:40] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 58/100, Acc=0.6211, Val Loss=1.5266, lr=0.0100
[02/21 21:19:07] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 59/100, Acc=0.6265, Val Loss=1.4657, lr=0.0100
[02/21 21:19:35] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 60/100, Acc=0.6878, Val Loss=1.1956, lr=0.0010
[02/21 21:20:02] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 61/100, Acc=0.6883, Val Loss=1.1992, lr=0.0010
[02/21 21:20:30] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 62/100, Acc=0.6881, Val Loss=1.2038, lr=0.0010
[02/21 21:20:58] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 63/100, Acc=0.6914, Val Loss=1.2132, lr=0.0010
[02/21 21:21:25] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 64/100, Acc=0.6890, Val Loss=1.2054, lr=0.0010
[02/21 21:21:53] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 65/100, Acc=0.6911, Val Loss=1.2171, lr=0.0010
[02/21 21:22:20] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 66/100, Acc=0.6896, Val Loss=1.2261, lr=0.0010
[02/21 21:22:48] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 67/100, Acc=0.6881, Val Loss=1.2305, lr=0.0010
[02/21 21:23:15] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 68/100, Acc=0.6900, Val Loss=1.2355, lr=0.0010
[02/21 21:23:42] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 69/100, Acc=0.6893, Val Loss=1.2408, lr=0.0010
[02/21 21:24:09] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 70/100, Acc=0.6916, Val Loss=1.2420, lr=0.0010
[02/21 21:24:36] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 71/100, Acc=0.6925, Val Loss=1.2509, lr=0.0010
[02/21 21:25:03] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 72/100, Acc=0.6901, Val Loss=1.2504, lr=0.0010
[02/21 21:25:30] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 73/100, Acc=0.6860, Val Loss=1.2639, lr=0.0010
[02/21 21:25:57] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 74/100, Acc=0.6890, Val Loss=1.2646, lr=0.0010
[02/21 21:26:25] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 75/100, Acc=0.6883, Val Loss=1.2691, lr=0.0010
[02/21 21:26:52] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 76/100, Acc=0.6905, Val Loss=1.2727, lr=0.0010
[02/21 21:27:19] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 77/100, Acc=0.6902, Val Loss=1.2823, lr=0.0010
[02/21 21:27:46] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 78/100, Acc=0.6867, Val Loss=1.2809, lr=0.0010
[02/21 21:28:14] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 79/100, Acc=0.6891, Val Loss=1.2863, lr=0.0010
[02/21 21:28:41] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 80/100, Acc=0.6879, Val Loss=1.2738, lr=0.0001
[02/21 21:29:09] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 81/100, Acc=0.6868, Val Loss=1.2729, lr=0.0001
[02/21 21:29:36] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 82/100, Acc=0.6883, Val Loss=1.2760, lr=0.0001
[02/21 21:30:03] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 83/100, Acc=0.6881, Val Loss=1.2758, lr=0.0001
[02/21 21:30:30] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 84/100, Acc=0.6880, Val Loss=1.2825, lr=0.0001
[02/21 21:30:58] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 85/100, Acc=0.6893, Val Loss=1.2763, lr=0.0001
[02/21 21:31:25] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 86/100, Acc=0.6872, Val Loss=1.2823, lr=0.0001
[02/21 21:31:52] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 87/100, Acc=0.6896, Val Loss=1.2804, lr=0.0001
[02/21 21:32:20] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 88/100, Acc=0.6895, Val Loss=1.2765, lr=0.0001
[02/21 21:32:47] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 89/100, Acc=0.6880, Val Loss=1.2772, lr=0.0001
[02/21 21:33:14] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 90/100, Acc=0.6895, Val Loss=1.2766, lr=0.0001
[02/21 21:33:42] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 91/100, Acc=0.6873, Val Loss=1.2853, lr=0.0001
[02/21 21:34:10] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 92/100, Acc=0.6873, Val Loss=1.2810, lr=0.0001
[02/21 21:34:37] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 93/100, Acc=0.6867, Val Loss=1.2846, lr=0.0001
[02/21 21:35:05] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 94/100, Acc=0.6869, Val Loss=1.2790, lr=0.0001
[02/21 21:35:32] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 95/100, Acc=0.6883, Val Loss=1.2834, lr=0.0001
[02/21 21:36:00] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 96/100, Acc=0.6884, Val Loss=1.2856, lr=0.0001
[02/21 21:36:27] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 97/100, Acc=0.6873, Val Loss=1.2832, lr=0.0001
[02/21 21:36:54] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 98/100, Acc=0.6871, Val Loss=1.2836, lr=0.0001
[02/21 21:37:22] cifar100-global-group_norm-3.0-resnet56 INFO: Epoch 99/100, Acc=0.6859, Val Loss=1.2861, lr=0.0001
[02/21 21:37:22] cifar100-global-group_norm-3.0-resnet56 INFO: Best Acc=0.6925
[02/21 21:37:22] cifar100-global-group_norm-3.0-resnet56 INFO: Params: 0.58 M
[02/21 21:37:22] cifar100-global-group_norm-3.0-resnet56 INFO: ops: 42.33 M
[02/21 21:37:24] cifar100-global-group_norm-3.0-resnet56 INFO: Acc: 0.6859 Val Loss: 1.2861

