[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: mode: prune
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: verbose: False
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: dataset: cifar100
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: dataroot: data
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: batch_size: 128
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: total_epochs: 100
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: lr: 0.01
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: restore: run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: output_dir: run/cifar100/prune/cifar100-global-lamp-2.0-mobilenetv2
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: finetune: True
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: last_epochs: 100
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: reps: 1
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: method: lamp
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: reg: 1e-05
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: seed: 1
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: global_pruning: True
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: sl_restore: None
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: logger: <Logger cifar100-global-lamp-2.0-mobilenetv2 (DEBUG)>
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: device: cuda
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: num_classes: 100
[02/24 01:15:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: Loading model from run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 01:15:43] cifar100-global-lamp-2.0-mobilenetv2 INFO: Pruning...
[02/24 01:16:11] cifar100-global-lamp-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 13, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(13, 15, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15)
      (4): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(15, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 82, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(82, 82, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=82)
        (4): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(82, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 116, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116)
        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(116, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 91, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(91, 91, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=91)
        (4): BatchNorm2d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(91, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 118, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(118, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=118)
        (4): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(118, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 95, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=95)
        (4): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(95, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 111, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(111, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(111, 111, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=111)
        (4): BatchNorm2d(111, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(111, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 147, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(147, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(147, 147, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=147)
        (4): BatchNorm2d(147, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(147, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 139, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(139, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(139, 139, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=139)
        (4): BatchNorm2d(139, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(139, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 113, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(113, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113)
        (4): BatchNorm2d(113, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(113, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 238, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(238, 238, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=238)
        (4): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(238, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 183, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(183, 183, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=183)
        (4): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(183, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 122, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122)
        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(122, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 269, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(269, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=269)
        (4): BatchNorm2d(269, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(269, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 356, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(356, 356, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=356)
        (4): BatchNorm2d(356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(356, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 400, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=400)
        (4): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 186, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=186)
      (4): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(186, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 100, kernel_size=(1, 1), stride=(1, 1))
)
[02/24 01:16:14] cifar100-global-lamp-2.0-mobilenetv2 INFO: Params: 2.37 M => 1.17 M (49.56%)
[02/24 01:16:14] cifar100-global-lamp-2.0-mobilenetv2 INFO: FLOPs: 68.40 M => 34.18 M (49.98%, 2.00X )
[02/24 01:16:14] cifar100-global-lamp-2.0-mobilenetv2 INFO: Acc: 0.6699 => 0.6699
[02/24 01:16:14] cifar100-global-lamp-2.0-mobilenetv2 INFO: Val Loss: 1.1637 => 1.1637
[02/24 01:16:14] cifar100-global-lamp-2.0-mobilenetv2 INFO: Finetuning...
[02/24 01:16:44] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.5896, Val Loss=1.4551, lr=0.0100
[02/24 01:17:16] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.6063, Val Loss=1.3932, lr=0.0100
[02/24 01:17:47] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.6023, Val Loss=1.4034, lr=0.0100
[02/24 01:18:22] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.5985, Val Loss=1.4197, lr=0.0100
[02/24 01:18:53] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5956, Val Loss=1.4512, lr=0.0100
[02/24 01:19:25] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.6103, Val Loss=1.3768, lr=0.0100
[02/24 01:19:57] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.5915, Val Loss=1.4709, lr=0.0100
[02/24 01:20:35] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6044, Val Loss=1.3922, lr=0.0100
[02/24 01:21:07] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.6070, Val Loss=1.3779, lr=0.0100
[02/24 01:21:39] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6021, Val Loss=1.4339, lr=0.0100
[02/24 01:22:10] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6080, Val Loss=1.3753, lr=0.0100
[02/24 01:22:43] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6088, Val Loss=1.3931, lr=0.0100
[02/24 01:23:15] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.5995, Val Loss=1.4210, lr=0.0100
[02/24 01:23:46] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.6006, Val Loss=1.4272, lr=0.0100
[02/24 01:24:18] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.6056, Val Loss=1.4024, lr=0.0100
[02/24 01:24:50] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.6149, Val Loss=1.3765, lr=0.0100
[02/24 01:25:26] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.6049, Val Loss=1.4345, lr=0.0100
[02/24 01:26:02] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.5948, Val Loss=1.4483, lr=0.0100
[02/24 01:26:37] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6187, Val Loss=1.3525, lr=0.0100
[02/24 01:27:08] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.5962, Val Loss=1.4515, lr=0.0100
[02/24 01:27:40] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.6067, Val Loss=1.3931, lr=0.0100
[02/24 01:28:12] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.5960, Val Loss=1.4355, lr=0.0100
[02/24 01:28:43] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.5961, Val Loss=1.4510, lr=0.0100
[02/24 01:29:15] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.6155, Val Loss=1.3741, lr=0.0100
[02/24 01:29:47] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.6042, Val Loss=1.4221, lr=0.0100
[02/24 01:30:19] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.5912, Val Loss=1.4554, lr=0.0100
[02/24 01:30:50] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.6087, Val Loss=1.3663, lr=0.0100
[02/24 01:31:22] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.5859, Val Loss=1.4696, lr=0.0100
[02/24 01:31:53] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.6179, Val Loss=1.3349, lr=0.0100
[02/24 01:32:24] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.6067, Val Loss=1.4018, lr=0.0100
[02/24 01:32:55] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.5982, Val Loss=1.4440, lr=0.0100
[02/24 01:33:26] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.6098, Val Loss=1.3749, lr=0.0100
[02/24 01:33:57] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.6122, Val Loss=1.3675, lr=0.0100
[02/24 01:34:29] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.6053, Val Loss=1.3925, lr=0.0100
[02/24 01:35:04] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.6104, Val Loss=1.3991, lr=0.0100
[02/24 01:35:42] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.6235, Val Loss=1.3599, lr=0.0100
[02/24 01:36:13] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.5990, Val Loss=1.4286, lr=0.0100
[02/24 01:36:44] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.5940, Val Loss=1.4599, lr=0.0100
[02/24 01:37:17] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.6199, Val Loss=1.3390, lr=0.0100
[02/24 01:37:48] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.6131, Val Loss=1.3896, lr=0.0100
[02/24 01:38:19] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.6067, Val Loss=1.4147, lr=0.0100
[02/24 01:38:51] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.6259, Val Loss=1.3334, lr=0.0100
[02/24 01:39:22] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.6133, Val Loss=1.3832, lr=0.0100
[02/24 01:39:53] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.6198, Val Loss=1.3316, lr=0.0100
[02/24 01:40:24] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.6139, Val Loss=1.3723, lr=0.0100
[02/24 01:40:55] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.6236, Val Loss=1.3494, lr=0.0100
[02/24 01:41:27] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.5972, Val Loss=1.4519, lr=0.0100
[02/24 01:41:58] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.5997, Val Loss=1.4614, lr=0.0100
[02/24 01:42:30] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.6188, Val Loss=1.3471, lr=0.0100
[02/24 01:43:02] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.6084, Val Loss=1.3910, lr=0.0100
[02/24 01:43:34] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.6180, Val Loss=1.3553, lr=0.0100
[02/24 01:44:05] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.6221, Val Loss=1.3189, lr=0.0100
[02/24 01:44:37] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.6147, Val Loss=1.3717, lr=0.0100
[02/24 01:45:09] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.6125, Val Loss=1.4015, lr=0.0100
[02/24 01:45:41] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.6071, Val Loss=1.3989, lr=0.0100
[02/24 01:46:13] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.6049, Val Loss=1.4197, lr=0.0100
[02/24 01:46:46] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.6227, Val Loss=1.3347, lr=0.0100
[02/24 01:47:18] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.6221, Val Loss=1.3274, lr=0.0100
[02/24 01:47:57] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.5996, Val Loss=1.4309, lr=0.0100
[02/24 01:48:35] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.6079, Val Loss=1.3887, lr=0.0100
[02/24 01:49:13] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.6683, Val Loss=1.1471, lr=0.0010
[02/24 01:49:46] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.6695, Val Loss=1.1453, lr=0.0010
[02/24 01:50:18] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.6759, Val Loss=1.1320, lr=0.0010
[02/24 01:50:50] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.6773, Val Loss=1.1324, lr=0.0010
[02/24 01:51:22] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.6794, Val Loss=1.1332, lr=0.0010
[02/24 01:51:54] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.6767, Val Loss=1.1345, lr=0.0010
[02/24 01:52:32] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.6771, Val Loss=1.1271, lr=0.0010
[02/24 01:53:10] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.6792, Val Loss=1.1304, lr=0.0010
[02/24 01:53:48] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.6768, Val Loss=1.1349, lr=0.0010
[02/24 01:54:26] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.6765, Val Loss=1.1329, lr=0.0010
[02/24 01:55:04] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.6783, Val Loss=1.1324, lr=0.0010
[02/24 01:55:42] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.6787, Val Loss=1.1347, lr=0.0010
[02/24 01:56:21] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.6800, Val Loss=1.1375, lr=0.0010
[02/24 01:57:01] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.6789, Val Loss=1.1382, lr=0.0010
[02/24 01:57:42] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.6763, Val Loss=1.1409, lr=0.0010
[02/24 01:58:22] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.6773, Val Loss=1.1400, lr=0.0010
[02/24 01:59:02] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.6795, Val Loss=1.1378, lr=0.0010
[02/24 01:59:43] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.6752, Val Loss=1.1414, lr=0.0010
[02/24 02:00:24] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.6765, Val Loss=1.1414, lr=0.0010
[02/24 02:00:58] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.6756, Val Loss=1.1410, lr=0.0010
[02/24 02:01:31] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.6797, Val Loss=1.1349, lr=0.0001
[02/24 02:02:04] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.6809, Val Loss=1.1318, lr=0.0001
[02/24 02:02:37] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.6788, Val Loss=1.1334, lr=0.0001
[02/24 02:03:09] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.6789, Val Loss=1.1330, lr=0.0001
[02/24 02:03:42] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.6795, Val Loss=1.1316, lr=0.0001
[02/24 02:04:15] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.6807, Val Loss=1.1327, lr=0.0001
[02/24 02:04:49] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.6786, Val Loss=1.1323, lr=0.0001
[02/24 02:05:23] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.6795, Val Loss=1.1322, lr=0.0001
[02/24 02:05:56] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.6787, Val Loss=1.1339, lr=0.0001
[02/24 02:06:30] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.6800, Val Loss=1.1336, lr=0.0001
[02/24 02:07:02] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.6823, Val Loss=1.1338, lr=0.0001
[02/24 02:07:34] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.6810, Val Loss=1.1338, lr=0.0001
[02/24 02:08:06] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.6820, Val Loss=1.1349, lr=0.0001
[02/24 02:08:41] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.6824, Val Loss=1.1340, lr=0.0001
[02/24 02:09:13] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.6819, Val Loss=1.1352, lr=0.0001
[02/24 02:09:45] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.6815, Val Loss=1.1344, lr=0.0001
[02/24 02:10:16] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.6816, Val Loss=1.1338, lr=0.0001
[02/24 02:10:48] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.6796, Val Loss=1.1357, lr=0.0001
[02/24 02:11:20] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.6819, Val Loss=1.1341, lr=0.0001
[02/24 02:11:52] cifar100-global-lamp-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.6800, Val Loss=1.1357, lr=0.0001
[02/24 02:11:52] cifar100-global-lamp-2.0-mobilenetv2 INFO: Best Acc=0.6824
[02/24 02:11:52] cifar100-global-lamp-2.0-mobilenetv2 INFO: Params: 1.17 M
[02/24 02:11:52] cifar100-global-lamp-2.0-mobilenetv2 INFO: ops: 34.18 M
[02/24 02:11:55] cifar100-global-lamp-2.0-mobilenetv2 INFO: Acc: 0.6800 Val Loss: 1.1357

