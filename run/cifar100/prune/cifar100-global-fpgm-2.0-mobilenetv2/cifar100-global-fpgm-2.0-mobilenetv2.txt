[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: mode: prune
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: model: mobilenetv2
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: verbose: False
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: dataset: cifar100
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: dataroot: data
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: batch_size: 128
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: total_epochs: 100
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: lr_decay_milestones: 60,80
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: lr_decay_gamma: 0.1
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: lr: 0.01
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: restore: run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: output_dir: run/cifar100/prune/cifar100-global-fpgm-2.0-mobilenetv2
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: finetune: True
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: last_epochs: 100
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: reps: 1
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: method: fpgm
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: speed_up: 2.0
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: max_pruning_ratio: 1.0
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: soft_keeping_ratio: 0.0
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: reg: 1e-05
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: delta_reg: 0.0001
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: weight_decay: 0.0005
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: seed: 1
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: global_pruning: True
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: sl_total_epochs: 100
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: sl_lr: 0.01
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: sl_lr_decay_milestones: 60,80
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: sl_reg_warmup: 0
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: sl_restore: None
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: iterative_steps: 400
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: logger: <Logger cifar100-global-fpgm-2.0-mobilenetv2 (DEBUG)>
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: device: cuda
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: num_classes: 100
[02/24 00:20:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Loading model from run/cifar100/pretrain/cifar100_mobilenetv2.pth
[02/24 00:20:41] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Pruning...
[02/24 00:21:02] cifar100-global-fpgm-2.0-mobilenetv2 INFO: MobileNetV2(
  (pre): Sequential(
    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (stage1): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 61, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(61, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=61)
        (4): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(61, 32, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 58, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58)
        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(58, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 37, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(37, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=37)
        (4): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(37, 64, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage5): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 70, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=70)
        (4): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(70, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 50, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50)
        (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(50, 96, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage6): Sequential(
    (0): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 130, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(130, 130, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=130)
        (4): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(130, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): LinearBottleNeck(
      (residual): Sequential(
        (0): Conv2d(160, 114, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(114, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=114)
        (4): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(114, 160, kernel_size=(1, 1), stride=(1, 1))
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage7): LinearBottleNeck(
    (residual): Sequential(
      (0): Conv2d(160, 110, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
      (3): Conv2d(110, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=110)
      (4): BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU6(inplace=True)
      (6): Conv2d(110, 320, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (conv2): Conv2d(1280, 100, kernel_size=(1, 1), stride=(1, 1))
)
[02/24 00:21:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Params: 2.37 M => 1.02 M (42.86%)
[02/24 00:21:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: FLOPs: 68.40 M => 33.72 M (49.30%, 2.03X )
[02/24 00:21:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Acc: 0.6699 => 0.6699
[02/24 00:21:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Val Loss: 1.1637 => 1.1637
[02/24 00:21:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Finetuning...
[02/24 00:21:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 0/100, Acc=0.5899, Val Loss=1.4738, lr=0.0100
[02/24 00:22:09] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 1/100, Acc=0.6034, Val Loss=1.3921, lr=0.0100
[02/24 00:22:42] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 2/100, Acc=0.5556, Val Loss=1.6395, lr=0.0100
[02/24 00:23:15] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 3/100, Acc=0.5980, Val Loss=1.4161, lr=0.0100
[02/24 00:23:50] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 4/100, Acc=0.5955, Val Loss=1.4421, lr=0.0100
[02/24 00:24:24] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 5/100, Acc=0.6107, Val Loss=1.3793, lr=0.0100
[02/24 00:24:55] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 6/100, Acc=0.5962, Val Loss=1.4445, lr=0.0100
[02/24 00:25:27] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 7/100, Acc=0.6087, Val Loss=1.3916, lr=0.0100
[02/24 00:25:58] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 8/100, Acc=0.5920, Val Loss=1.4385, lr=0.0100
[02/24 00:26:31] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 9/100, Acc=0.6102, Val Loss=1.3809, lr=0.0100
[02/24 00:27:02] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 10/100, Acc=0.6063, Val Loss=1.3924, lr=0.0100
[02/24 00:27:34] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 11/100, Acc=0.6173, Val Loss=1.3601, lr=0.0100
[02/24 00:28:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 12/100, Acc=0.6018, Val Loss=1.4123, lr=0.0100
[02/24 00:28:36] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 13/100, Acc=0.6088, Val Loss=1.3949, lr=0.0100
[02/24 00:29:07] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 14/100, Acc=0.5778, Val Loss=1.5296, lr=0.0100
[02/24 00:29:38] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 15/100, Acc=0.5985, Val Loss=1.4235, lr=0.0100
[02/24 00:30:09] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 16/100, Acc=0.5995, Val Loss=1.4345, lr=0.0100
[02/24 00:30:40] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 17/100, Acc=0.5934, Val Loss=1.4376, lr=0.0100
[02/24 00:31:11] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 18/100, Acc=0.6190, Val Loss=1.3565, lr=0.0100
[02/24 00:31:43] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 19/100, Acc=0.6018, Val Loss=1.4040, lr=0.0100
[02/24 00:32:14] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 20/100, Acc=0.6143, Val Loss=1.3561, lr=0.0100
[02/24 00:32:45] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 21/100, Acc=0.6026, Val Loss=1.4127, lr=0.0100
[02/24 00:33:17] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 22/100, Acc=0.6014, Val Loss=1.4301, lr=0.0100
[02/24 00:33:49] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 23/100, Acc=0.6035, Val Loss=1.3950, lr=0.0100
[02/24 00:34:20] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 24/100, Acc=0.6087, Val Loss=1.3979, lr=0.0100
[02/24 00:34:51] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 25/100, Acc=0.5855, Val Loss=1.4978, lr=0.0100
[02/24 00:35:24] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 26/100, Acc=0.6034, Val Loss=1.4175, lr=0.0100
[02/24 00:35:58] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 27/100, Acc=0.6081, Val Loss=1.3970, lr=0.0100
[02/24 00:36:29] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 28/100, Acc=0.6116, Val Loss=1.3635, lr=0.0100
[02/24 00:37:02] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 29/100, Acc=0.6026, Val Loss=1.4373, lr=0.0100
[02/24 00:37:33] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 30/100, Acc=0.6021, Val Loss=1.4247, lr=0.0100
[02/24 00:38:08] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 31/100, Acc=0.6109, Val Loss=1.4039, lr=0.0100
[02/24 00:38:38] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 32/100, Acc=0.6114, Val Loss=1.3846, lr=0.0100
[02/24 00:39:09] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 33/100, Acc=0.5781, Val Loss=1.5176, lr=0.0100
[02/24 00:39:42] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 34/100, Acc=0.6091, Val Loss=1.3917, lr=0.0100
[02/24 00:40:15] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 35/100, Acc=0.6195, Val Loss=1.3682, lr=0.0100
[02/24 00:40:46] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 36/100, Acc=0.5792, Val Loss=1.5233, lr=0.0100
[02/24 00:41:16] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 37/100, Acc=0.6061, Val Loss=1.4031, lr=0.0100
[02/24 00:41:47] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 38/100, Acc=0.6141, Val Loss=1.3525, lr=0.0100
[02/24 00:42:22] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 39/100, Acc=0.6131, Val Loss=1.3674, lr=0.0100
[02/24 00:42:54] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 40/100, Acc=0.6200, Val Loss=1.3478, lr=0.0100
[02/24 00:43:26] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 41/100, Acc=0.6157, Val Loss=1.3609, lr=0.0100
[02/24 00:43:57] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 42/100, Acc=0.6283, Val Loss=1.3292, lr=0.0100
[02/24 00:44:29] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 43/100, Acc=0.6059, Val Loss=1.4209, lr=0.0100
[02/24 00:45:00] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 44/100, Acc=0.5944, Val Loss=1.4696, lr=0.0100
[02/24 00:45:32] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 45/100, Acc=0.6123, Val Loss=1.3762, lr=0.0100
[02/24 00:46:04] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 46/100, Acc=0.5889, Val Loss=1.4749, lr=0.0100
[02/24 00:46:36] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 47/100, Acc=0.6278, Val Loss=1.3147, lr=0.0100
[02/24 00:47:08] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 48/100, Acc=0.6050, Val Loss=1.4004, lr=0.0100
[02/24 00:47:40] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 49/100, Acc=0.6184, Val Loss=1.3482, lr=0.0100
[02/24 00:48:11] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 50/100, Acc=0.6075, Val Loss=1.4094, lr=0.0100
[02/24 00:48:43] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 51/100, Acc=0.6098, Val Loss=1.3931, lr=0.0100
[02/24 00:49:15] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 52/100, Acc=0.6108, Val Loss=1.3882, lr=0.0100
[02/24 00:49:47] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 53/100, Acc=0.6040, Val Loss=1.4466, lr=0.0100
[02/24 00:50:19] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 54/100, Acc=0.5667, Val Loss=1.5970, lr=0.0100
[02/24 00:50:50] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 55/100, Acc=0.6136, Val Loss=1.3820, lr=0.0100
[02/24 00:51:21] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 56/100, Acc=0.6109, Val Loss=1.3835, lr=0.0100
[02/24 00:51:53] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 57/100, Acc=0.6320, Val Loss=1.3071, lr=0.0100
[02/24 00:52:28] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 58/100, Acc=0.6154, Val Loss=1.3876, lr=0.0100
[02/24 00:53:00] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 59/100, Acc=0.6061, Val Loss=1.4203, lr=0.0100
[02/24 00:53:33] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 60/100, Acc=0.6702, Val Loss=1.1332, lr=0.0010
[02/24 00:54:07] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 61/100, Acc=0.6768, Val Loss=1.1258, lr=0.0010
[02/24 00:54:41] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 62/100, Acc=0.6791, Val Loss=1.1142, lr=0.0010
[02/24 00:55:14] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 63/100, Acc=0.6800, Val Loss=1.1190, lr=0.0010
[02/24 00:55:50] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 64/100, Acc=0.6787, Val Loss=1.1218, lr=0.0010
[02/24 00:56:24] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 65/100, Acc=0.6791, Val Loss=1.1204, lr=0.0010
[02/24 00:57:03] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 66/100, Acc=0.6813, Val Loss=1.1115, lr=0.0010
[02/24 00:57:36] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 67/100, Acc=0.6797, Val Loss=1.1214, lr=0.0010
[02/24 00:58:09] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 68/100, Acc=0.6811, Val Loss=1.1217, lr=0.0010
[02/24 00:58:42] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 69/100, Acc=0.6787, Val Loss=1.1196, lr=0.0010
[02/24 00:59:14] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 70/100, Acc=0.6798, Val Loss=1.1229, lr=0.0010
[02/24 00:59:49] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 71/100, Acc=0.6811, Val Loss=1.1219, lr=0.0010
[02/24 01:00:25] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 72/100, Acc=0.6813, Val Loss=1.1229, lr=0.0010
[02/24 01:00:57] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 73/100, Acc=0.6813, Val Loss=1.1230, lr=0.0010
[02/24 01:01:31] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 74/100, Acc=0.6792, Val Loss=1.1288, lr=0.0010
[02/24 01:02:04] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 75/100, Acc=0.6766, Val Loss=1.1305, lr=0.0010
[02/24 01:02:41] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 76/100, Acc=0.6851, Val Loss=1.1201, lr=0.0010
[02/24 01:03:16] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 77/100, Acc=0.6808, Val Loss=1.1269, lr=0.0010
[02/24 01:03:49] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 78/100, Acc=0.6825, Val Loss=1.1286, lr=0.0010
[02/24 01:04:27] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 79/100, Acc=0.6787, Val Loss=1.1304, lr=0.0010
[02/24 01:05:02] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 80/100, Acc=0.6830, Val Loss=1.1203, lr=0.0001
[02/24 01:05:39] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 81/100, Acc=0.6852, Val Loss=1.1180, lr=0.0001
[02/24 01:06:14] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 82/100, Acc=0.6848, Val Loss=1.1195, lr=0.0001
[02/24 01:06:47] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 83/100, Acc=0.6818, Val Loss=1.1178, lr=0.0001
[02/24 01:07:18] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 84/100, Acc=0.6833, Val Loss=1.1167, lr=0.0001
[02/24 01:07:50] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 85/100, Acc=0.6823, Val Loss=1.1179, lr=0.0001
[02/24 01:08:24] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 86/100, Acc=0.6856, Val Loss=1.1162, lr=0.0001
[02/24 01:08:57] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 87/100, Acc=0.6814, Val Loss=1.1173, lr=0.0001
[02/24 01:09:29] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 88/100, Acc=0.6831, Val Loss=1.1185, lr=0.0001
[02/24 01:10:00] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 89/100, Acc=0.6835, Val Loss=1.1188, lr=0.0001
[02/24 01:10:32] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 90/100, Acc=0.6820, Val Loss=1.1185, lr=0.0001
[02/24 01:11:05] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 91/100, Acc=0.6826, Val Loss=1.1194, lr=0.0001
[02/24 01:11:37] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 92/100, Acc=0.6826, Val Loss=1.1197, lr=0.0001
[02/24 01:12:10] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 93/100, Acc=0.6822, Val Loss=1.1192, lr=0.0001
[02/24 01:12:42] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 94/100, Acc=0.6843, Val Loss=1.1203, lr=0.0001
[02/24 01:13:13] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 95/100, Acc=0.6820, Val Loss=1.1200, lr=0.0001
[02/24 01:13:44] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 96/100, Acc=0.6810, Val Loss=1.1172, lr=0.0001
[02/24 01:14:15] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 97/100, Acc=0.6827, Val Loss=1.1218, lr=0.0001
[02/24 01:14:46] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 98/100, Acc=0.6824, Val Loss=1.1183, lr=0.0001
[02/24 01:15:17] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Epoch 99/100, Acc=0.6832, Val Loss=1.1204, lr=0.0001
[02/24 01:15:17] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Best Acc=0.6856
[02/24 01:15:17] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Params: 1.02 M
[02/24 01:15:17] cifar100-global-fpgm-2.0-mobilenetv2 INFO: ops: 33.72 M
[02/24 01:15:20] cifar100-global-fpgm-2.0-mobilenetv2 INFO: Acc: 0.6832 Val Loss: 1.1204

